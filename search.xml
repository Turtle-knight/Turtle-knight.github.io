<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Ubuntu环境]]></title>
    <url>%2F2019%2F02%2F25%2FUbuntu%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Ubuntu工作环境快速配置首先更新一下 1sudo apt update &amp;&amp; sudo apt upgrade 更换软件源详情https://blog.csdn.net/JRRRJ/article/details/81082444 将阿里源添加到sources.list中 1deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 保存退出，然后更新。 安装显卡驱动在「软件和更新」-「附加驱动」选项卡中进行选择 基础软件安装VIM1sudo apt install vim vim 个人配置.vimrc (保存在个人百度网盘快速配置Ubuntu环境文件夹) 搜狗输入法https://blog.csdn.net/fx_yzjy101/article/details/80243710 Git1sudo apt install git PyCharmhttps://blog.csdn.net/qq_15192373/article/details/81091278 ipython1sudo apt install ipython3 flask安装详情见flask官网 Typora(Markdown编辑)安装详情见Typora官网 Shutter(截图软件)详情见https://blog.csdn.net/qq_19339041/article/details/80058892 WPS先卸载LibreOffice 1sudo apt-get remove --purge libreoffice* 下载安装访问WPS官网 MySQL &amp;&amp; Redis12sudo apt install mysql-serversudo apt install redis-server WechatUbuntu 18.04 安装微信（Linux通用）]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu环境]]></title>
    <url>%2F2019%2F02%2F25%2FApache_Kafka%2F</url>
    <content type="text"><![CDATA[Apache Kafka(学习笔记)Kafka简介Kafka是一款由美国领英公司（LinkedIn）开源出来的高性能消息引擎系统（Messaging system）,其核心功能是——高性能的消息发送与高性能的消息消费。但随着Kafka的不断演进，在Kafka 0.10.0.0版本正式推出了Kafka Streams，即流式处理组件。自此Kafka正式成为了一个流式处理框架。 前置知识背景消息引擎系统消息引擎，又叫消息队列，消息中间件等。 根据维基百科的定义，企业消息引擎系统（EMS）是企业发布的一组规范。公司使用这组规范实现在不同系统之间传递语义准确的消息。在实际使用场景中，消息引擎系统通常以软件接口为主要形式，实现了松耦合的异步式数据传递语义。 消息引擎范型根据维基百科定义，一个消息引擎范型是一个基于网络的架构范型，描述了消息引擎系统的两个不同的子部分是如何互连且交互的。如果把消息引擎系统的这两个子系统比喻成两座城市，那么传输协议就是需要铺设的沥青公路，而引擎范型决定了来往穿梭与这两座城市的路线。 最常见的两种消息引擎范型是消息队列模型和发布/订阅模型。 消息队列（message queue）模型是基于队列提供消息传输服务的，多用于进程间通信以及线程间通信。该模型定义了消息队列、发送者和接收者，提供了一种点对点的消息传递方式，即发送者发送每条消息到队列的指定位置，接收者从指定位置获取消息。每条消息由一个发送者生产出来，且只被一个消费者处理。 发布/订阅模型(publish/subscribe),它有主题（topic）的概念：一个topic可以理解为逻辑语义相近的消息的容器。这种模型定义了类似于生产者/消费者这样的角色，即发布者和订阅者。发布者将消息生产出来发送到指定的topic中，所有订阅了该topic的订阅者都可以接收到该topic下的所有消息。 Kafka术语消息既然Kafka的核心功能就是消息引擎，那么对消息的设计日然是首当其冲的事情。Kafka在消息设计时特意避开了繁重的Java堆上内存分配，直接使用紧凑二进制字节数组ByteBuffer而不是独立的对象，因此至少能够访问多一倍的可用内存。 省去padding，java对对象保存的大开销以及可能的页缓存。 topic和partiiton从概念上来说，topic只是一个逻辑概念，代表了一类消息，也可以认为是消息被发送到的地方。通常可以使用topic来区分实际业务，比如业务A使用一个topic，业务B使用另一个topic。 Kafka中的topic通常都会被多个消费者订阅，出于性能的考量，Kafka并不是topic-message的两级结构，而是采取了topic-partition-message的三级结构来分散负载。从本质上来说，每个Kafka topic都由若干个partition组成。 topic是由多个partition组成的，而Kafka的partition是不可修改的有序消息队列，也可以说是有序的消息日志。每个partition都有自己专属的partition号。用户对partition唯一能做的操作就是在消息序列的尾部追加写入消息。partition上的每条消息都会被分配一个唯一的序列号-该序列号被称为位移（offset）。位移信息可以唯一定位到某partition下的一条消息 offset实际上，Kafka消费者也有位移（offset）的概念，但这两个offset属于不同的概念。 每条消息在某个partition的位移是固定的，但消费该partition的消费者的位移会随着消费进度不断前移，但不能超过该分区最新一条消息的位移。 从本质上看，Kafka中的一条消息其实就是一个&lt;topic,partition,offset&gt;三元组（tuple），通过该元组，可以在Kafka集群中找到位移对应的那条消息。 replica为了实现高可靠性，通过冗余机制——备份多份日志。这些备份日志在Kafka中被称为副本（replica），它们存在的唯一目的就是防止数据丢失。 副本分为两类：领导者副本（leader replica）和追随者副本（follower replica）。follower replica是不能提供服务给客户端的，它只是被动地向领导者副本（leader replica）获取数据，一旦leader replica所在的broker宕机，Kafka会从剩余的replica中选举出新的leader继续提供服务。 ISRISR的全称是 in-sync replica，就是与leader replica保持同步的replica集合。 Kafka为partition动态维护一个replica集合。该集合中的所有replica保存的消息日志都与leader replica保护同步状态。只有这个集合中的replica才能被选举为leader，也只有该集合中所有replica都接收到了同一条消息，Kafka才会将该消息置于“已提交”状态，即认为这条消息发送成功。Kafka承诺只要这个集合中至少存在一个replica，那些”已提交“状态的消息就不会丢失。 Kafka使用场景 消息传输 网站行为日志追踪 审计数据收集 日志收集 Event Sourcing 流式处理 Kafka设计原理broker端设计架构broker是Apache Kafka最重要的组件，本质上它是一个功能载体（或服务载体），承载了绝大多数的Kafka服务。事实上，大多数的消息队列框架都有broker或已知类似的角色。一个broker通常是以服务器的形式出现的。 消息设计 消息格式 V2版本分为消息和消息集合两个维度，不过消息集合的提法被消息批次所取代。V2版本中，它有一个专门的属于：RecordBatch。 V2版本消息格式 “可变长度”表示Kafka会根据具体的值来确定到底需要几字节保存。为了在序列化时降低使用的字节数，V2版本借鉴了Google ProtoBuffer中的Zig-zag编码方式，使得绝对值较小的整数占用字节数较少的字节。 消息batch CRC值从消息层面被移除，放入batch这一层 PID、producer epoch和序列号等消息都是0.11.0.0版本为了实现幂等性producer和支持事务而一如的。 通过使用mirco-batch，批次地发送消息，能大幅度地提高Kafka的吞吐量。 集群管理Kafka是分布式的消息引擎集群环境，支持自动化的服务发现与成员管理。依赖于Apache Zookeeper实现，每当一个broker启动，它会将自己注册到Zookeeper下的一个节点。 首先，每个broker在Zookeper下注册节点的路径是chroot/brokers/ids/&lt;broker.id&gt;。如果没有配置chroot，则路径是/broker/ids/&lt;broker.id&gt;。 其次，broker向Zookeeper中的注册消息以JSON格式保存。 12345678910111213141516&#123; "version": 4, "host": "loacalhost", "port": 9092, "jmx_port": 9999, "timestamp": 1499737197, "endpoints": [ "CLIENT"://host1:9092", "REPLICATION://HOST1:9093" ], "listener_security_protocol_map": &#123; "CLIENT": "SSL", "REPLICATION": "PLAINTEXT" &#125;, "rack": "dc1"&#125; 最后，Zookeeper临时节点的生命周期和客户端会话绑定。如果客户端会话失效，该临时节点就会自动被清除掉。Kafka正是利用Zookeeper临时节点来管理broker生命周期的。broker启动时在Zookeeper中创建对应的临时节点，同时还会创建一个监听器（listener）监听该临时节点的状态；一旦broker启动后，监听器会自动同步整个集群消息到该broker上；而一旦broker崩溃，它与Zookeeper的会话就会失效，导致临时节点被删除，监听器被触发，然后处理broker崩溃的后续事宜。这就是Kafka管理集群及其成员的主要流程。 副本与ISR设计一个Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在Kafka中被称为副本（replica）。 follower副本同步 起始位移（base offset）：表示该副本当前所含第一条消息的位移 高水印值（high watermark，HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader分区的HW值决定了副本中已提交消息的范围，也确定了consumer能够获取消息的消息上限。任何一个副本对象的HW值一定不大于其LEO值。Kafka对leader副本和follower副本的HW值更新机制是不同的。 日志末端位移（log end offset，LEO）：副本日志中下一条待写入消息的offset。所有副本都需要维护自己的LEO信息。只有ISR中的所有副本都更新了对应的LEO之后，leader副本才会向右移动HW值表明消息写入成功。Kafka对leader副本和follower副本的LEO值更新机制也是不同的。 水印（watermark）和leader epoch 水印被称为高水印或高水位，通常被用在流水式处理领域，以表征元素或时间在基于时间层面上的进度。在Kafka中，水印的概念与时间无关，而与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。 LEO更新机制 follower follower副本不停地向leader副本所在broker发送FETCH请求，一旦获取消息，便写入自己的日志中进行备份。 Kafka设计了两套follower副本LEO属性：一套LEO属性保存在follower副本所在broker的缓存上；另一套LEO值保存在leader副本所在broker的缓存上。换句话说，leader副本所在broker的缓存上保存了该分区下所有follower副本的LEO属性值。 follower副本端LEO更新 每当在底层日志新写入一条消息，其LEO值就会加1. leader副本端的follower副本LEO更新 一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO。 leader 每当在底层日志新写入一条消息，其LEO值就会加1. HW更新机制 前面说过，leader broker上保存了一套follower副本的LEO以及它自己的LEO。当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO，并选择最小的LEO值作为HW值。 图解Kafka备份原理 基于水印机制的缺陷 数据丢失：使用HW值来确定备份进度时其值的更新是在下一轮RPC中完成的。延迟一轮FETCH请求更新HW的值的设计使得followerHW值是异步延迟更新的，若在这个过程中leader发生变更，那么称为新leader的follower的HW值就有可能是过期的，使得clients端认为成功提交的消息被删除了。 数据不一致/数据离散：leader端log和follower端的log数据不一致 leader epoch 上述两个问题的根本原因在于HW值被用于衡量副本备份的成功与否，以及在出现崩溃时作为日志截断的依据，但HW值的更新是异步延迟的，特别是需要额外的FETCH请求处理流程才能更新，这中间发生的任何崩溃都可能导致HW值的过期 leader epoch，实际上是一对值(epoch，offset)。epoch表示leader的版本号，从0开始，当leader变更过1次时，epoch就会+1，而offset则对应于该epoch版本的leadre写入第一条消息的位移。 通信协议 协议设计 所谓通信协议，就是实现client-server间或server-server间数据传输的一套规范。Kafka通信协议是基于TCP之上的二进制协议，这套协议提供的API表现为服务于不同功能的多种请求类型以及对应的相应。所有类型的请求和响应都是结构化的，有不同的初始类型构成。 常见请求类型 PRODUCE请求 FETCH请求 METADATA请求 请求处理流程 clients端 broker端 controller设计 controller概览 在一个Kafka集群中，某一个broker会被选举出来承担特殊的角色，即控制器。一如controller就是用来管理和协调Kafka集群的。具体来说，就是管理集群中所有分区的状态并执行相应的管理操作。 controller管理状态 controller维护的状态分为两类：每台broker上的分区副本和每个分区的leader副本信息。从维度上看，这些状态可分为副本状态和分区状态。 副本状态机 分区状态机 controller职责 更新集群元数据信息 创建topic 删除topic 分区重分配 preferred leader副本选举 topic分区扩展 broker加入集群 broker崩溃 受控关闭 controller leader选举 broker请求处理 Reactor模式 Kafka broker处理请求的模式就是Reactor设计模式。Reactor设计模式是一种事件处理模式，旨在处理多个输入源同时发送过来的请求。Reactor模式中的服务处理器或分发器将入站请求按照多路复用的方式分发到对应的请求处理器。 Kafka broker请求处理 Kafka broker请求处理实现了Reactor模式。在Kafka中，每个broker都有一个acceptor线程和若干个processor线程。processor线程的数量是可以配置的。 producer端设计架构producer端基本数据结构 ProducerRecord 一个ProducerRecord封装了一条待发送的消息（或称为记录）。 ProducerRecord由5个字段构成: topic：该消息所属的topic partition：该消息所属的分区 key：消息key value：消息体 timestamp：消息时间戳 RecordMetadata 该数据结构表示Kafka服务器端返回给客户端的消息的元数据 offset：消息在 分区日志中的位移信息 timesstamp：消息时间戳 topic/partition checksum：消息CRC32码 serializedKeySize：序列化后消息的key字节数 serializedValueSize：序列化后消息value字节数 工作流程如果把producer统一看成一个盒子，那么整个producer端的工作原理便如图所示。大体来说，用户首先构建待发送的消息对象ProducerRecord，然后调用KafkaProducer#send方法进行发送。KafkaProducer接收到消息后首先对其进行序列化，然后结合本地缓存的元数据信息一起发送给partitioner去确定目标分区，最后追加写入内存中的消息缓冲池。 调用KafkaProducer.send执行的操作： 序列化+计算目标分区 追加写入消息缓冲区 Sender线程预处理及消息发送 consumer端设计架构consumer group 状态机新版本consumer依赖于broker端的组协调者coordinator来管理组内的所有consumer实例并负责把分配方案发到每个consumer上。分配方案由组内的leader consumer根据指定的分区分配策略指定的。 分区分配的操作在consumer端执行而非broker端的好处： 便于维护与升级：如果在broker端实现，那么分配策略的变动势必要重启整个Kafka集群。生产环境中重启服务器的代价是很高的。 便于实现自定义策略：不同的策略由不同的逻辑实现。coordinator端代码不容易实现灵活可定制的分配逻辑 解耦了组管理与分区分配，coordinator负责组管理工作，而consumer程序负责分区分配。 Kafka为每个consumer group定义了5个状态： Empty：表明group下没有任何active consumer，但可能包含位移信息。 PreparingRebalance：该状态表明group正在准备进行group rebalance。 AwaitingSync：该状态表明所有成员都已经加入组并等待leader consumer发送分区分配方案。 Stable：该状态表明group开始正常消费。此时group必须响应clients发送过来的任何请求。 Dead：该状态表明group已经彻底废弃，group内没有任何成员并且group的所有元数据都已被删除。 实现精确一次处理语义(exactly-once semanties, EOS)clients端常见的3种消息交付语义： 最多一次（ai most once）：消息可能丢失也可能被处理，但最多只会被处理一次 至少一次（at last once）：消息不会丢失，但可能被多次处理 精确一次（exactly once）：消息被处理且只会被处理一次。 幂等性producer（idempotent producer）幂等性producer是Apache Kafka 0.11.0.0版本用于实现EOS的一个利器。若一个操作执行多次的结果与只运行一次的结果是相同的，那么称该操作为幂等操作。引入幂等producer表示它的发送操作是幂等。瞬时的发送错可能导致produecer端出现重试，同一个消息被producer发送多次，但在broker端这条消息只会被写入日志一次。 幂等性producer的设计思路类似于TCP的工作方式。发送到broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和TCP不同的是，这个序列号不会被丢弃，相反Kafka会把它们保存在底层日志中，这样即使分区的leader副本挂掉，新选出来的leader broker也能执行消息去重工作。 事务（transaction）对事务的支持是Kafka实现EOS的第二个利器。引入事务使得clients端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。 处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中。重要的是不论是发送还是消费，Kafka都能保证它们是原子性，即所有的写入操作幺妹全部成功，要么全部失败。 Kafka为实现事务要求应用程序必须提供一个唯一的id来表征事务。这个id被称为事务id，它必须在应用程序所有的会话上是唯一的。 PS：未完待续，后续深入学习再做补充]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
</search>
