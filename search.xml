<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flask学习笔记]]></title>
    <url>%2F2019%2F04%2F11%2FFlask_Web%2F</url>
    <content type="text"><![CDATA[FlaskFlask是使用Python编写的Web微框架，Web框架可以让开发者不用关心底层的请求响应处理，更方便更高效地编写Web程序。Flask有两个主要依赖，一个是WSGI（Web Server Gateway Interface，Web服务器网关接口）工具集——Werkzeug，另一个是Jinja2模板引擎。 搭建开发环境 安装pip和pipenv 1$ pip install pipenv 创建虚拟环境 在Python中虚拟环境（virtual environment）就是隔离的Python解释器环境。通过创建虚拟环境，你可以拥有一个独立的Python解释器环境。这样做的好处是可以为每一个项目创建独立的Python解释器环境，因为不同的项目常常会话依赖不同版本的库或Python版本。使用虚拟环境可以保持全局Python解释器环境的干净，避免包和版本的混乱，并且可以方便地区分和记录每个项目的依赖，以便在新环境下复现依赖环境。 123$ pipenv install # 为当前目录的项目创建虚拟环境$ pipenv shell # 显式激活虚拟环境 安装Flask 1$ pipenv install flask # 在虚拟环境中安装Flask 注册路由在一个Web应用里，客户端和服务器上的Flask程序的交互可以简单概括为以下几步： 1）用户在浏览器中输入URL访问某个资源 2）Flask接收用户请求并分析请求的URL 3）为这个URL找到对应的处理函数 4）执行函数并生成响应，返回给浏览器 5）浏览器接收并解析响应，将信息显示在页面中 在以上步骤中，大部分都由Flask完成，开发者要做的只是建立处理请求的函数，并定义对应的URL规则。只需为函数附加app.route()装饰器，并传入URL规则作为参数，就可以让URL与函数建立联系。这个过程称为注册路由（route），路由负责管理URL和函数之间的映射，而这个函数则被称为视图函数（view function）。 例如： 123@app.route('/')def index(): return '&lt;h1&gt;Hello, World&lt;/h1&gt;' 在这个程序里，app.route()装饰器把根地址/和index()函数绑定起来，当用户访问这个URL时就会触发index()函数。这个视图函数可以像其他普通函数一样执行任意操作，最后，视图函数返回的值作为响应的主体。 为视图绑定多个URL 一个视图函数可以绑定多个URL。 例： 1234@app.route('/hi')@app.route('/hello')def say_hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt;' 动态URL 123@app.route('/greet/&lt;name&gt;')def greet(name): return '&lt;h1&gt;Hello, %s!&lt;/h1&gt;' % name 启动开发服务器1$ flask run flask run命令启动内置的开发服务器。 自动发现程序实例 一般来说，在执行flask run命令运行程序前，需要提供程序实例所在模块的位置。若无提供，Flask会自动探测程序实例，自动探测存在以下规则： 从当前目录寻找app.py和wsgi.py模块，并从中寻找名为app或application的程序实例。 从环境变量FLASK_APP对应的值寻找名为app或application的程序实例。 管理环境变量 Flask的自动发现程序实例机制还有第三条规则：如果安装了python-dotenv，那么在使用flask run或其他命令时会使用它自动从.flaskenv文件和.env文件中加载环境变量。 为了避免频繁设置环境变量，可以使用python-dotenv管理项目的环境变量。 1$ pipenv install python-dotenv .flaskenv文件用来存储和Flask相关的公开环境变量，比如FLASK_APP; .env文件用来存储包含敏感信息的环境变量，比如账户名和密码。 环境变量以键值对的形式定义。 Flask与HTTP请求响应循环 HTTP请求Request对象这个请求对象封装了从客户端发来的请求报文，能从它获取请求报文中的所有数据。 在Flask中处理请求 设置监听的HTTP方法 123@app.route('/hello', method=['GET', 'POST'])def hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt; 请求钩子有时需要对请求进行预处理（preprocessing）和后处理（postprocessing）。这时可以使用Flask提供的一些请求钩子（Hook），它们可以用来注册在请求处理的不同阶段执行的处理函数。这些请求钩子用装饰器实现，通过程序实例app调用。 ​ 请求钩子 钩子 说明 before_first_request 注册一个函数，在处理第一个请求前运行 before_request 注册一个函数，在处理每个请求前运行 after_request 注册一个函数，如果没有未处理的异常抛出，会在每个请求结束后运行 teardown_request 注册一个函数，即使有未处理的异常抛出，会在每个请求结束后运行 after_this_request 在视图函数内注册一个函数，会在这个请求结束后运行 HTTP响应响应格式在HTTP响应中，数据可以通过多种格式传输。大多数情况下，我们会使用HTML格式，这是Flask中的默认设置。在特定的情况下，也会使用其他格式。不同的响应数据格式需要设置不同的MIME类型。 纯文本 MIME类型： text/plain HTML MIME类型：text/html XML MIME类型：application/xml JSON MIME类型：application/json CookieHTTP是无状态协议。在一次响应结束后，服务器不会留下任何关于对方状态的信息。 Cookie是Web服务器为了存储某些数据（比如用户信息）而保存在浏览器上的小型数据。浏览器会在一定时间内保存它，并在下一次向同一个服务器发送请求时附带这些数据。Cookie通常被用来进行用户会话管理（比如登录状态），保存用户的个性化信息以及记录和收集用户浏览数据以用来分析用户行为等。 在Flask中，想要在响应中添加一个cookie，最方便的方法是使用Response类提供的set_cookie() 方法。 1234567from flask import Flask, make_response...@app.route('/set/&lt;name&gt;')def set_cookie(name): response = make_response(redirect(url_for('hello'))) response.set_cookie('name', name) return response Session：安全的Cookie在编程中，session指用户会话，又称为对话，即服务器和客户端/浏览器之间或桌面程序和用户之间建立的交互活动。而在Flask中，session对象用来加密Cookie。默认情况下，它会把数据存储在浏览器上一个名为session的cookie里。 session通过密钥对数据进行签名以加密数据。因此，得先社会一个密钥。 1234567# 程序的密钥可以通过Flask.secret_key属性或配置变量SECRET_KEY设置app.secret_key = 'secret string'# 更安全的做法是把密钥写进系统环境变量或是保存在.env文件中SECRET_KEY = secret string# 然后在陈旭脚本中使用os模块提供的getenv()方法获取app.secret_key = os.getenv('SECRET_KEY', ‘secret string') HTTP进阶重定向回上一个页面要重定向回上一个页面，最关键的是获取上一个页面的URL。上一个页面的URL一般可以通过两种方法获取。 HTTP referer HTTP referer是一个用来记录请求发源地的HTTP首部字段，即访问来源。当用户在某个站点单击链接，浏览器向新链接所在的服务器发起请求，请求的数据中包含的HTTP_REFERER字段记录了用户所在的原站点URL。 1return redirect(request.referrer) 查询参数 在URL中手动加入包含当前URL的查询参数，这个查询参数一般命名为next。 12345@app.route('/foo')def foo(): return '&lt;h1&gt;Foo page&lt;/h1&gt;&lt;a href="%s"&gt;Do somthing and redirect&lt;/a&gt;' % url_for('do something', next=request.full_path) return redirect(request.args.get('next')) Ajax技术发送异步请求AJAX指异步JavaScript和XML，它不是编程语言或通信协议，而是一系列技术的组合体。简单来说，Ajax基于XMLHttpRequest让我们可以在不重载页面的情况下和服务器进行数据交换。加上JavaScript和DOM，就可以在接收到数据后局部更新页面。 使用JQuery发送Ajax请求 jQuery是流行的JavaScript库，它包装了JavaScript，让我们可以通过更简单的方式编写JavaScript代码。对于Ajax，它提供了多个相关的方法，使用它可以很方便的实现Ajax操作。更重要的是，jQuery处理了不同浏览器的Ajax兼容问题，只需要编写一套代码，就可以在所有主流的浏览器正常运行。 JQuery中和Ajax相关的方法及具体用法访问http://api.jquery.com/category/ajax/ 模板在动态Web程序中，视图函数返回的HTML数据往往需要根据相应的变量（比如查询函数）动态生成。当HTML代码保存到单独的文件中时，没法再使用字符串格式化或拼接字符串的方式来在HTML代码中插入变量，这时，需要使用模板引擎（template engine），借助模板引擎，可以在HTML文件中使用特殊的语法来标记处变量，这类包含固定内容和动态部分的可重用文件称为模板（template）。 模板引擎的作用就是读取并执行模板中的特殊语法标记，并根据传入的数据将变量替换为实际值，输出最终的HTML页面，这个过程被称为渲染（rendering）。 模板基本用法（1）语句 比如 if 判断、for 循环等： {/% for %/}注：因为hexo缘故，实际使用不需要斜杠。 （2）表达式 比如字符串、变量、函数调用等 {/{ xxx.xx }/}注：因为hexo缘故，实际使用不需要斜杠。 （3）注释 {/# xxx #/}注：因为hexo缘故，实际使用不需要斜杠。 模板语法渲染模板在视图函数中，不直接使用Jinja2提供的函数，而是使用Flask提供的渲染函数render_template()。 123@app.route('/example')def example_for_render(): return render_templae('example.html', arg1=xxx, arg2=yyy) 在render_template() 函数中，首先传入模板的文件名作为参数，以关键字参数的形式传入模板中使用的变量值。其他类型的变量通过相同的方式传入。传入Jinja2中的变量值可以使字符串、列表、和字典，也可以是函数、类和类实例。 模板辅助工具上下文 内置上下文变量 Flask在模板上下文中提供了一些内置变两个，可以在模板中直接使用 ​ 标准模板全局变量 变量 说明 config 当前的配置对象 request 当前的请求对象，在已激活的请求环境下可用 session 当前的会话对象，在已激活的请求环境下可用 g 与请求绑定的全局变量，在已激活的请求环境下可用 自定义上下文 如果多个模板都需要使用同一变量，那么较好的方法是能够设置一个模板全局变量。Flask提供了一个app.context_processor()装饰器，可以用来注册模板上下文处理函数，它可以完成统一传入变量的工作。 1234567@app.context_processo()def inject_foo(): foo = 'I am foo.' return dict(foo=foo) # 等同于return &#123;'foo': foo&#125;# 直接将app.context_processor作为方法调用app.context_processor(inject_foo) 当调用render_template()函数渲染任意一个模板时，所有使用app.context_processor装饰器注册的模板上下文处理函数（包括Flask内置的上下文处理函数）都会被执行，这些函数的返回值会被添加到模板中，因此可以在模板中直接使用变量。 全局对象全局对象是指在所有的模板中都可以直接使用的对象，包括在模板中导入的模板。 内置全局函数 ​ Jinja2内置模板全局函数(部分) | 函数 | 说明 || ————————————– | ————————— || range([start,]stop[, step]) | 和python中的range()用法相同 || lipsum(n=5, html=True, min=20,max=100) | 生成随机文本（lorem ipsum） || dict(**items) | 和python中的dict()用法相同 | ​ Flask内置模板全局函数 | 函数 | 说明 || ———————- | ———————– || url_for() | 用于生成URL的函数 || get_flashed_message(0) | 用于获取flash消息的函数 | 自定义全局函数 使用app.template_global()装饰器直接将函数注册为模板全局函数 123@app.template_global()def bar(): return 'I am bar' 过滤器在Jinja2中，过滤器（filter）是一些可以用来修改和过滤变量值的特殊函数，过滤器和变量用一个竖线（管道符号）隔开，需要参数的过滤器可以像函数一样使用括号传递。 例如： 内置过滤器 Jinja2提过了许多内置过滤器，访问http://jinjia.pocoo.org/docs/2.10/template/#builtin-filters 自定义过滤器 使用app.template_filter()装饰器可以自定义过滤器 12345from flask import Markup@app.template_filter()def miscal(s): return s + Markup(' &amp;#9835;') 测试器在Jinja中，测试器（Test）是一些用来测试变量或表达式，返回值（True或False）的特殊函数。比如，number测试器用来判断一个变量或变大时是否数字。使用 is 连接变量和测试器 12345&#123;% if age is number %&#125; &#123;&#123; age * 365&#125;&#125;&#123;% else %&#125; 无效数字&#123;% endif %&#125; 内置测试器 Jinja2提供了许多内置测试器，访问http://jinjia.pocoo.org/docs/2.10/template/#list-of-builtin-tests 自定义测试器 使用app.template_test()装饰器自定义测试器 12345@app.template_test()def baz(n): if n == 'baz': return True return False 模板环境对象在jinja2中，渲染行为有jinja2.Environment类控制，所有的配置选项，上下文变量、全局函数、过滤器和测试器都存储在Environment实例上。当与Flask结合后，我们并不单独创建Environment对象，而是使用Flask创建的Environment对象，它存储在app.jinja_env属性上。 在程序中，可以使用app.jinja_env更改Jinja2设置。 模板环境中的全局函数、过滤器和测试器分别存储在Environment对象的globals、filters和tests属性中，这三个属性都是字典对象。可以直接操作这三个字典来添加相应的函数或变量。 添加自定义全局对象 123456def bar(): return 'I am bar'foo = 'I am foo'app.jinja_env.globals['bar'] = barapp.jinja_env.globals['foo'] = foo 添加自定义过滤器 1234def smiling(s): return s + ':)' app.jinja_env.filters['smiling'] = smiling 添加自定义测试器 123456def baz(n): if n == 'baz': return True return False app.jinja_env.tests['baz'] = baz 模板结构组织 局部模板 当多个独立模板总都会使用同一块HTML代码时，可以把这部分代码抽离出来，存储到局部模板中。这样一方面可以避免重复，另一方面也可以方便统一管理。 1&#123;% include &apos;xxx.html&apos; %&#125; 模板继承 Jinja2的模板继承允许定义一个基模板，把网页上的导航栏、页脚等通用内容放在基模板中，而每一个继承基模板的子模板在被渲染时都会自动包含这些部分。 为了能够让子模板方便地覆盖或插入内容到基模板中，需要在基模板中定义块(block)，在子模板中可以通过定义同名的块来执行继承操作。 模板进阶加载静态文件一个Web项目不仅需要HTML模板，还需要虚度静态文件，比如CSS、JavaScript文件、图片及音频等。在Flask程序中，默认需要将静态文件存储在与主脚本（包含程序实例的脚本）同级目录的static文件夹中。 为了在HTML文件中引用静态文件，需要使用url_for() 函数获取静态URL。Flask内置了用于获取静态文件的试图函数，端点值为static， 默认URL规则为 static/path:filename，URL变量filename是相对于static文件夹根目录的文件路径。 例如： 123&lt;img src="&#123;&#123; url_for('static', filename='xxx.jpg') &#125;&#125;" &gt;&lt;link rel="stylesheet" type="text/css" href="&#123;&#123; url_for('static', filename='styles.css') &#125;&#125;" &gt; 使用CSS框架在编写Web程序时，手动编写CSS比较麻烦，常见的做法是使用CSS框架来为程序添加样式。CSS框架内置了大量可以直接使用的CSS样式类和JavaScript函数，使用它们可以非常快速地让程序页面变得美观和易用，同时也可以定义自己的CSS文件来进行补充和调整。 12345678&#123;% block sysles %&#125; &lt;link ref="stylesheet" href="&#123;&#123; url_for('static', filename='css/bootstrap.min.css') &#125;&#125;" &gt;&#123;% endblock %&#125;...&#123;% block script %&#125; &lt;script scr="&#123;&#123; url_for('static', filename='js/jquery.min.js') &#125;&#125;"&gt;&lt;/script&gt; &lt;script src="&#123;&#123; url_fro('static', filename='js/popper.min.js') &#125;&#125;"&gt;&lt;/script&gt;&#123;% endblock %&#125; 消息闪现Flask提供了一个非常有用的flash() 函数，它可以用来“闪现”需要显示给用户的消息。在视图函数中调用flash()函数，传入消息内容即可“闪现”一条消息。发送的消息会存储在session中，需要在模板中使用全局函数get_flashed_messages() 获取消息并将其显示出来。 123456from flask import flash@app.route('/') def just_flash(): flash('I am flash, who is looking for me.') return redirect(url_for('index')) 表单HTML表单HTML表单的具体定义和用法访问http://www.w3.org/TR/html401/interact/forms.html 使用Flask-WTF处理表单在模板中渲染表单提交表单出于安全考虑，一般使用POST方法提交表单。使用POST方法时，按照默认的编码类型，表单数据会被存储在请求主体中。 为了支持接收表单提交发送的POST请求，必须在app.route()装饰器里使用methods关键字为路由指定HTTP方法。 1234@app.route('/', methods=['GET', 'POST'])def basic(): form = LoginForm() return render_template('basic.html', form=form) 验证表单数据 客户端验证和服务器端验证 客户端验证 指在客户端（比如Web浏览器）对用户的输入值进行验证。客户端方式可以实时动态提示用户输入是否正确，只有用户输入正确后才会将表单数据发送到服务器。客户端验证可以增强用户体验，降低服务器负载。 服务器端验证 指用户把输入的数据提交到服务器，在服务器端对数据进行验证。如果验证出错，就在返回的响应中加入错误信息。 客户端验证和服务器端验证都是必不可少的。 WTForms验证机制 WTForms验证表单字段的方式是在实例化表单类时传去表单数据，然后对表单实例调用validate() 方法。 表单进阶自定义验证器在WTForms中，验证器是指在定义字段时传入validators参数列表的可调用对象。 行内验证器 12345678910from wtforms import IntegerField, SubmitFieldfrom wtforms.validators import ValidationErrorclass FortyTwoForm(FlaskForm): answer = IntegerField('The Number') submit = SubmitField() def validate_answer(form, field): # 验证器在表单类中定义 if field.data != 42: raise ValidationError('Must be 42') 当表单类总包含以“validate_字段属性名“形式命名的方法时，在验证字段数据时会同时调用这个方法来验证对应的字段，这也是为什么表单类的字段属性名不能以validate开头。 全局验证器 123456789from wtforms.validators import ValidationErrordef is_42(form, field): # 验证器在表单类外定义 if filed.data != 42: raise ValidationError('Must be 42') class FortyTwoForm(FlaskForm): answer = IntegerField('The Number', validators=[is_42]) submit = SubmitField() 文件上传在HTML中，渲染一个文件上传字段只需要将标签的type属性设为file，即。这会在浏览器中渲染陈一个文件上传字段，单机文件选择按钮会打开文件选择窗口，选择对应的文件后，被选择的文件名会显示在文件选择按钮旁边。 定义上传表单 在Python表单类中创建文件上传字段时，使用扩展Flask-WTF提供的FileField类，它继承了WTForm提供的上传字段FileField，添加了对Flask的集成。 例： 1234from flask wtf.file import FileField, FileRequired, FileAllowedclass UploadForm(FlaskForm): photo = FileField('Upload Image', validators=[FileRequired(), FileAllowed(['jpg', 'jpeg', 'png', 'gif'])]) submit = SubmitField() 渲染上传表单 在创建的upload视图里，实例化表单类UploadForm，然后传入模板： 12345@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() ... return render_template('upload.html, form=form) 12345&lt;form method="post" enctype="multipart/form-data"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.photo) &#125;&#125; &#123;&#123; form.submit() &#125;&#125;&lt;/form&gt; 处理上传文件 和普通的表单数据不同，当包含上传文件字段的表单提交后，上传的文件需要在请求对象的files属性（reuqest.files）中获取。 当使用Flask-WTF时，它会自动帮我们获取对应的文件对象。这里使用表单类属性的data属性获取上传文件。 123456789101112131415import osapp.config['UPLOAD_PATH'] = os.path.join(app.root_path, 'uploads')@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() if form.validate_on_submit(): f = form.photo.data filename = random_filename(f.filename) f.save(os.path.join(app.config['UPLOAD)PATH'], filename)) flash('Upload success.') session['filenames'] = [filename] return redirect(url_for('show_images')) return render_template('upload.html', form=form) 使用Flask-CKEditor集成富文本编辑器1$ pipenv install flask-ckeditor # 安装 1）实例化Flask-CkEditor提供的CkEditor类，传入程序实例 123from flask_ckeditor import CKEditorckeditor = CKEditor() 2）渲染富文本编辑器 123456789from flask_wtf import FlaskFormFrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequired, Lengthfrom flask_ckeditor import CKEditorFieldclass RichTextForm(FlaskForm): title = StringField('Title', validators=[DataRequired(), Length[1. 50]]) body = CKEditorField('Body', validators=[DataRequeired()]) submit= SubmitField('Publish') 123456789&#123;% block content %&#125;&lt;h1&gt;Integrate CKEditor with Flask-CKEditor&lt;/h1&gt;&lt;form method="post"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.title) &#125;&#125; &#123;&#123; form_field(form.body) &#125;&#125; &#123;&#123; form.submit &#125;&#125;&lt;/form&gt;&#123;% endblock %&#125; 单个表单多个提交按钮1234567891011121314class NewPostForm(FlaskForm): title = String('Title') ... save = SubmitField('Save') publish = SubmitField('Publish') @app.route('/xxx', methods=['GET', 'POST'])def two_submits(): form = NewPostForm() if form.validate_on_submit(): if form.save.data: .... elif form.publish.data: .... 数据库电子邮件Flask程序的自动化测试Flask程序性能优化部署FLask程序Flask的一些设计理念后续补充]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Web开发</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量PATH]]></title>
    <url>%2F2019%2F02%2F25%2FLinux_%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8FPATH%2F</url>
    <content type="text"><![CDATA[环境变量$PATH在Linux中，执行命令时，系统会按照PATH的设置，去每个PATH定义的路径下搜索执行文件，先搜索到的文件先执行。（From：《鸟哥的LINUX私房菜》） 改变PATH直接修改$PATH值：12echo $PATH //查看当前PATH的配置路径export PATH=$PATH:/xxx1:/xxx2 //将需要的配置路径加入$PATH 等号两边没有空格，path之间用':'间隔 生效方法：立即生效 有效期限：临时改变，只对当前终端有效，关闭后恢复原来的PATH 用户局限：仅当前用户 通过修改.bashrc文件：（.bashrc文件在根目录下）12345vim .bashrc // 编辑.bashrc文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx // /xxx/xxx为需要加入的环境变量地址，等号两边无空格 生效方法：（有一下两种） 关闭当前终端窗口，重新打开一个新的终端窗口即可 输入 1source .bashrc 命令，立即生效。 有效期限：永久有效 用户局限：仅当前用户 通过修改profile文件：（profile文件在/etc目录下）12345vim /etc/profile // 编辑profile文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户 通过修改environment文件：（environment文件在/etc目录下）123vim /etc/environment //编辑environment文件在PATH=/.......中加入“:/xxx/xxx” 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu环境]]></title>
    <url>%2F2019%2F02%2F25%2FUbuntu%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Ubuntu工作环境快速配置首先更新一下 1sudo apt update &amp;&amp; sudo apt upgrade 更换软件源详情https://blog.csdn.net/JRRRJ/article/details/81082444 将阿里源添加到sources.list中 1deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 保存退出，然后更新。 安装显卡驱动在「软件和更新」-「附加驱动」选项卡中进行选择 基础软件安装VIM1sudo apt install vim vim 个人配置.vimrc (保存在个人百度网盘快速配置Ubuntu环境文件夹) 搜狗输入法https://blog.csdn.net/fx_yzjy101/article/details/80243710 Git1sudo apt install git PyCharmhttps://blog.csdn.net/qq_15192373/article/details/81091278 ipython1sudo apt install ipython3 flask安装详情见flask官网 Typora(Markdown编辑)安装详情见Typora官网 Shutter(截图软件)详情见https://blog.csdn.net/qq_19339041/article/details/80058892 WPS先卸载LibreOffice 1sudo apt-get remove --purge libreoffice* 下载安装访问WPS官网 MySQL &amp;&amp; Redis12sudo apt install mysql-serversudo apt install redis-server WechatUbuntu 18.04 安装微信（Linux通用）]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发问题整理]]></title>
    <url>%2F2019%2F02%2F25%2Fdjango_web_%E5%BC%80%E5%8F%91%E9%94%99%E8%AF%AF%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[在使用Django2.0进行Web开发过程中遇到的问题Django在根据models生成数据库表时报 _ init _()missing 1 required positional argument: ‘on_delete’ 原因 在django2.0后，定义外键和一对一关系的时候需要加on_delete选项，此参数为了避免两个表里的数据不一致问题，不然会报错：TypeError: _ init _() missing 1 required positional argument: ‘on_delete’ 解决方法 1234567# 以下代码报错user = models.OneToOneField(User)owner = models.ForeignKey(UserProfile)# 以下代码正确user = models.OneToOneField(User, on_delete=models.CASCADE)owner = models.ForergnKey(UserProfile, on_delete=models.CASCADE) 参数说明 on_delete有CASCADE、PROTECT、SET_NULL、SET_DEFAULT、SET()五个可选择的值。CASCADE：此值设置，是级联删除。PROTECT：此值设置，是会报完整性错误。SET_NULL：此值设置，会把外键设置为null，前提是允许为null。SET_DEFAULT：此值设置，会把设置为外键的默认值。SET()：此值设置，会调用外面的值，可以是一个函数。一般情况下使用CASCADE就可以了。 Django2.0配置Mysql数据库后执行数据迁移时报错： 报错 1django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11.None 原因 MySQLclient目前只支持到python3.4 解决方法 因为要使用python3.6，所以修改下面路径的文件： 1$ vim /home/utur/.local/lib/python3.6/site-packages/django/db/backends/mysql 将以下代码注释即可： 12if version &lt; (1, 3, 3): raise ImproperlyConfigured("mysqlclient 1.3.3 or newer is required; you have %s" % Database.__version__) MySQL: django.db.utils.OperationalError:( 1698, “Access denied for user ‘roo‘@’localhost’”) with correct username and pw 详情见：https://stackoverflow.com/questions/41542045/mysql-django-db-utils-operationalerror-1698-access-denied-for-user-root 解决方法 123create user &apos;django&apos;@&apos;localhost&apos; identified by &apos;django-user-password&apos;;grant usage on *.* to &apos;django&apos;@&apos;localhost&apos;;grant all privileges on django-database-1.* to &apos;django&apos;@&apos;localhost&apos;; AttributeError: ‘str’ object has no attribute ‘decode’ 报错 执行 1python3 manage.py makemigrations 报错 123 File "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/Django-2.2-py3.7.egg/django/db/backends/mysql/operations.py", line 146, in last_executed_query query = query.decode(errors='replace')AttributeError: 'str' object has no attribute 'decode' 原因 python在bytes和str两种类型转换，所需要的函数依次是encode(),decode() 解决方法 在报错路径下 1vim operations.py 找到错误代码 1query = query.decode(errors='replace') 修改为 12query = query.encode(errors='replace')# 保存并退出 include() got an unexpected keyword argument ‘app_name’ 原因 在Django2.0版本使用url()导致，推荐使用path() 解决方法 在xxx应用下的urls.py添加app_name变量 12345678910from django.contrib import adminfrom django.conf.urls import url,includeapp_name = xxxurlpatterns = [ # 路由规则 ...]]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫基本知识]]></title>
    <url>%2F2019%2F02%2F25%2F%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[HTTP基本原理 URL:Uniform Resource Identifier,统一资源标志符 URL:Universal Resource Locator,统一资源定位符 网页基础网页的组成网页可以分为三大部分——HTML、CSS和JavaScript。 HTML: HTML是用来描述网页的一种语言，全称叫作 Hyper Text Markup Language，即超文本标记语言。网页包括文字、按钮、图片和视频等各种复杂的元素，其基础=架构就是HTML。不同类型的文字通过不同类型的标签来表示。 CSS：全称叫作Cascading Style Sheets，即层叠样式表。”层叠”是指当在HTML中引用了数个样式文件，并且样式发生冲突时，浏览器能依据层叠顺序处理。”样式”指网页中文字大小、颜色、元素间距、排列等格式。 JavaScript：简称JS，是一种脚本语言。HTML和CSS配合使用，提供给用户的只是一种静态信息，缺乏交互性。我们在网页里可能会看到一些交互和动画效果，如下载进度条、提示框、轮播图等，这通常是JavaScript的功劳。它的出现使得用户与信息之间不只是浏览与显示的关系，而是实现了一种实时、动态、交互的页面功能。 爬虫的基本原理 爬取网页 爬虫首先要做的工作就是获取网页，这里就是获取网页的源代码。源代码里包含了网页的部分有用信息，所以只要把源代码获取下来，就可以从中提取想要的信息。 提取信息 获取网页源代码后，接下来就是分析网页源代码，从中提取想要的数据。 保存数据 提取信息后，一般会将提取到的数据和保存到某处以便后续使用。这里保存形式有多种多样，如可以简单保存为TXT文本或JSON文本，也可以保存到数据库，如MySQL和MongoDB等。 自动化程序 会话和Cookies 无状态HTTP：HTTP的无状态是指HTTP协议对事务处理是没有一个记忆能力的，也就是说服务器不知道客户端是什么状态。当像服务器发送请求后，服务器解析词请求，然后返回对应的响应，服务器负责完成这个过程，而且这个过程是完全独立的，服务器不会记录前后状态的变化，也就是缺乏状态记录。 会话：在Web中，会话对象用来存储特定用户会话所需要的属性及配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在会话对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当用户请求来自应用程序的Web页时，如果该用户还没有会话，则Web服务器讲自动创建一个会话对象。当会话过期或被放弃后，服务器讲终止该会话。 Cookies：Cookies指某些网站为了辨别用户身份、进行会话跟踪而存储在 用户本地终端上的数据。 Cookies字段： Name：Cookies的名称，一旦创建，名称便不可更改 Value： Cookies的值。如果值为Unicode字符，需要为字符编码。如果值为二进制数据，则需要使用BASE64编码。 Domain：可以访问该Cookies的域名 Max Age：Cookies失效的时间，单位为秒，常和Expires一起使用，通过它可以计算出其有效时间 Path：Cookies的使用路径 Size：Cookies的大小 HTTP：Cookies的httponly属性。若此属性为true，则只有在HTTP头中会带有此Cookie的信息，而不能通过document.cookie来访问Cookie。 Secure：该Cookie是否被使用安全协议传输。安全协议有HTTPS和SSL等、、 会话Cookie和持久Cookie 会话Cookie：就是把Cookie放在浏览器内存里，浏览器在关闭之后该Cookie即失效 持久Cookie：Cookie会保存到客户端的硬盘中，下次还可以继续使用，用于长久保持用户登录状态。本质是Cookie的Max Age活Expires字段决定了过期的时间。 Cookies和会话需要配合，一个处于客户端，一个处于服务端，二者共同协作，就实现了登录会话控制。 代理的基本原理 基本原理 实际上就是在本机和服务器之间搭建了一个桥，此时本机不是直接像Web服务器发起请求，而是向代理服务器发出请求，请求会发送给代理服务器，然后由代理服务器再发送给Web服务器，接着由代理服务器再把Web服务器返回的响应转发给本机。这个过程中Web服务器识别出的真实IP就不再是我们本机的IP了，成功实现了IP伪装，这就是代理的基本原理。 代理的作用 突破自身IP访问限制，访问一些平时不能访问的站点 访问一些单位或内部资源 2,提高访问速度：通常代理服务器都设置一个较大的硬盘缓冲去，当有外界的信息通过时，同时也将其保存到缓冲区，当其他用户再访问相同的信息时，则直接由缓冲区中取出信息，传给用户，以提高访问速度。 隐藏真实IP：上网者可以通过这种方法隐藏自己的IP，免受攻击。对应爬虫来说，我们代理就是为了隐藏自身的IP，防止自身的IP被封锁。 Ajax数据爬取Ajax，全称为Asynchronous JavaScript and XML，即异步的JavaScript和XML。它不是一门编程语言，而是利用JavaScript在保证页面不被刷新、页面链接不改变的情况下与服务器变换数据并更新部分网页的技术。 基本原理 发送请求 实际上就是新建了XMLHttp&amp;Request对象，然后调用onreadystatechange属性设置了监听，然后调用open()和send()方法向某个链接（也就是服务器）发送了请求。 解析内容 得到响应之后，onreadystatechange属性对应的方法便会被触发，此时利用xmlhttp的responseText属性便可取到响应内容。 渲染网页 JavaScript有改变网页内容的能力，解析完响应内容之后，就可以调用JavaScript来针对解析玩的内容对网页进行下一步处理。 验证码的识别 图形验证码（利用tesserocr库） 极验滑动验证码 模拟点击验证按钮 识别滑动缺口的位置 模拟拖动滑块 点触验证码（12306） 利用验证码服务平台辅助验证 微博宫格验证码]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列Kafka学习笔记]]></title>
    <url>%2F2019%2F02%2F25%2FApache_Kafka%2F</url>
    <content type="text"><![CDATA[Kafka简介Kafka是一款由美国领英公司（LinkedIn）开源出来的高性能消息引擎系统（Messaging system）,其核心功能是——高性能的消息发送与高性能的消息消费。但随着Kafka的不断演进，在Kafka 0.10.0.0版本正式推出了Kafka Streams，即流式处理组件。自此Kafka正式成为了一个流式处理框架。 前置知识背景消息引擎系统消息引擎，又叫消息队列，消息中间件等。 根据维基百科的定义，企业消息引擎系统（EMS）是企业发布的一组规范。公司使用这组规范实现在不同系统之间传递语义准确的消息。在实际使用场景中，消息引擎系统通常以软件接口为主要形式，实现了松耦合的异步式数据传递语义。 消息引擎范型根据维基百科定义，一个消息引擎范型是一个基于网络的架构范型，描述了消息引擎系统的两个不同的子部分是如何互连且交互的。如果把消息引擎系统的这两个子系统比喻成两座城市，那么传输协议就是需要铺设的沥青公路，而引擎范型决定了来往穿梭与这两座城市的路线。 最常见的两种消息引擎范型是消息队列模型和发布/订阅模型。 消息队列（message queue）模型是基于队列提供消息传输服务的，多用于进程间通信以及线程间通信。该模型定义了消息队列、发送者和接收者，提供了一种点对点的消息传递方式，即发送者发送每条消息到队列的指定位置，接收者从指定位置获取消息。每条消息由一个发送者生产出来，且只被一个消费者处理。 发布/订阅模型(publish/subscribe),它有主题（topic）的概念：一个topic可以理解为逻辑语义相近的消息的容器。这种模型定义了类似于生产者/消费者这样的角色，即发布者和订阅者。发布者将消息生产出来发送到指定的topic中，所有订阅了该topic的订阅者都可以接收到该topic下的所有消息。 Kafka术语消息既然Kafka的核心功能就是消息引擎，那么对消息的设计日然是首当其冲的事情。Kafka在消息设计时特意避开了繁重的Java堆上内存分配，直接使用紧凑二进制字节数组ByteBuffer而不是独立的对象，因此至少能够访问多一倍的可用内存。 省去padding，java对对象保存的大开销以及可能的页缓存。 topic和partiiton从概念上来说，topic只是一个逻辑概念，代表了一类消息，也可以认为是消息被发送到的地方。通常可以使用topic来区分实际业务，比如业务A使用一个topic，业务B使用另一个topic。 Kafka中的topic通常都会被多个消费者订阅，出于性能的考量，Kafka并不是topic-message的两级结构，而是采取了topic-partition-message的三级结构来分散负载。从本质上来说，每个Kafka topic都由若干个partition组成。 topic是由多个partition组成的，而Kafka的partition是不可修改的有序消息队列，也可以说是有序的消息日志。每个partition都有自己专属的partition号。用户对partition唯一能做的操作就是在消息序列的尾部追加写入消息。partition上的每条消息都会被分配一个唯一的序列号-该序列号被称为位移（offset）。位移信息可以唯一定位到某partition下的一条消息 offset实际上，Kafka消费者也有位移（offset）的概念，但这两个offset属于不同的概念。 每条消息在某个partition的位移是固定的，但消费该partition的消费者的位移会随着消费进度不断前移，但不能超过该分区最新一条消息的位移。 从本质上看，Kafka中的一条消息其实就是一个&lt;topic,partition,offset&gt;三元组（tuple），通过该元组，可以在Kafka集群中找到位移对应的那条消息。 replica为了实现高可靠性，通过冗余机制——备份多份日志。这些备份日志在Kafka中被称为副本（replica），它们存在的唯一目的就是防止数据丢失。 副本分为两类：领导者副本（leader replica）和追随者副本（follower replica）。follower replica是不能提供服务给客户端的，它只是被动地向领导者副本（leader replica）获取数据，一旦leader replica所在的broker宕机，Kafka会从剩余的replica中选举出新的leader继续提供服务。 ISRISR的全称是 in-sync replica，就是与leader replica保持同步的replica集合。 Kafka为partition动态维护一个replica集合。该集合中的所有replica保存的消息日志都与leader replica保护同步状态。只有这个集合中的replica才能被选举为leader，也只有该集合中所有replica都接收到了同一条消息，Kafka才会将该消息置于“已提交”状态，即认为这条消息发送成功。Kafka承诺只要这个集合中至少存在一个replica，那些”已提交“状态的消息就不会丢失。 Kafka使用场景 消息传输 网站行为日志追踪 审计数据收集 日志收集 Event Sourcing 流式处理 Kafka设计原理broker端设计架构broker是Apache Kafka最重要的组件，本质上它是一个功能载体（或服务载体），承载了绝大多数的Kafka服务。事实上，大多数的消息队列框架都有broker或已知类似的角色。一个broker通常是以服务器的形式出现的。 消息设计 消息格式 V2版本分为消息和消息集合两个维度，不过消息集合的提法被消息批次所取代。V2版本中，它有一个专门的属于：RecordBatch。 V2版本消息格式 “可变长度”表示Kafka会根据具体的值来确定到底需要几字节保存。为了在序列化时降低使用的字节数，V2版本借鉴了Google ProtoBuffer中的Zig-zag编码方式，使得绝对值较小的整数占用字节数较少的字节。 消息batch CRC值从消息层面被移除，放入batch这一层 PID、producer epoch和序列号等消息都是0.11.0.0版本为了实现幂等性producer和支持事务而一如的。 通过使用mirco-batch，批次地发送消息，能大幅度地提高Kafka的吞吐量。 集群管理Kafka是分布式的消息引擎集群环境，支持自动化的服务发现与成员管理。依赖于Apache Zookeeper实现，每当一个broker启动，它会将自己注册到Zookeeper下的一个节点。 首先，每个broker在Zookeper下注册节点的路径是chroot/brokers/ids/&lt;broker.id&gt;。如果没有配置chroot，则路径是/broker/ids/&lt;broker.id&gt;。 其次，broker向Zookeeper中的注册消息以JSON格式保存。 12345678910111213141516&#123; "version": 4, "host": "loacalhost", "port": 9092, "jmx_port": 9999, "timestamp": 1499737197, "endpoints": [ "CLIENT"://host1:9092", "REPLICATION://HOST1:9093" ], "listener_security_protocol_map": &#123; "CLIENT": "SSL", "REPLICATION": "PLAINTEXT" &#125;, "rack": "dc1"&#125; 最后，Zookeeper临时节点的生命周期和客户端会话绑定。如果客户端会话失效，该临时节点就会自动被清除掉。Kafka正是利用Zookeeper临时节点来管理broker生命周期的。broker启动时在Zookeeper中创建对应的临时节点，同时还会创建一个监听器（listener）监听该临时节点的状态；一旦broker启动后，监听器会自动同步整个集群消息到该broker上；而一旦broker崩溃，它与Zookeeper的会话就会失效，导致临时节点被删除，监听器被触发，然后处理broker崩溃的后续事宜。这就是Kafka管理集群及其成员的主要流程。 副本与ISR设计一个Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在Kafka中被称为副本（replica）。 follower副本同步 起始位移（base offset）：表示该副本当前所含第一条消息的位移 高水印值（high watermark，HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader分区的HW值决定了副本中已提交消息的范围，也确定了consumer能够获取消息的消息上限。任何一个副本对象的HW值一定不大于其LEO值。Kafka对leader副本和follower副本的HW值更新机制是不同的。 日志末端位移（log end offset，LEO）：副本日志中下一条待写入消息的offset。所有副本都需要维护自己的LEO信息。只有ISR中的所有副本都更新了对应的LEO之后，leader副本才会向右移动HW值表明消息写入成功。Kafka对leader副本和follower副本的LEO值更新机制也是不同的。 水印（watermark）和leader epoch 水印被称为高水印或高水位，通常被用在流水式处理领域，以表征元素或时间在基于时间层面上的进度。在Kafka中，水印的概念与时间无关，而与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。 LEO更新机制 follower follower副本不停地向leader副本所在broker发送FETCH请求，一旦获取消息，便写入自己的日志中进行备份。 Kafka设计了两套follower副本LEO属性：一套LEO属性保存在follower副本所在broker的缓存上；另一套LEO值保存在leader副本所在broker的缓存上。换句话说，leader副本所在broker的缓存上保存了该分区下所有follower副本的LEO属性值。 follower副本端LEO更新 每当在底层日志新写入一条消息，其LEO值就会加1. leader副本端的follower副本LEO更新 一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO。 leader 每当在底层日志新写入一条消息，其LEO值就会加1. HW更新机制 前面说过，leader broker上保存了一套follower副本的LEO以及它自己的LEO。当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO，并选择最小的LEO值作为HW值。 图解Kafka备份原理 基于水印机制的缺陷 数据丢失：使用HW值来确定备份进度时其值的更新是在下一轮RPC中完成的。延迟一轮FETCH请求更新HW的值的设计使得followerHW值是异步延迟更新的，若在这个过程中leader发生变更，那么称为新leader的follower的HW值就有可能是过期的，使得clients端认为成功提交的消息被删除了。 数据不一致/数据离散：leader端log和follower端的log数据不一致 leader epoch 上述两个问题的根本原因在于HW值被用于衡量副本备份的成功与否，以及在出现崩溃时作为日志截断的依据，但HW值的更新是异步延迟的，特别是需要额外的FETCH请求处理流程才能更新，这中间发生的任何崩溃都可能导致HW值的过期 leader epoch，实际上是一对值(epoch，offset)。epoch表示leader的版本号，从0开始，当leader变更过1次时，epoch就会+1，而offset则对应于该epoch版本的leadre写入第一条消息的位移。 通信协议 协议设计 所谓通信协议，就是实现client-server间或server-server间数据传输的一套规范。Kafka通信协议是基于TCP之上的二进制协议，这套协议提供的API表现为服务于不同功能的多种请求类型以及对应的相应。所有类型的请求和响应都是结构化的，有不同的初始类型构成。 常见请求类型 PRODUCE请求 FETCH请求 METADATA请求 请求处理流程 clients端 broker端 controller设计 controller概览 在一个Kafka集群中，某一个broker会被选举出来承担特殊的角色，即控制器。一如controller就是用来管理和协调Kafka集群的。具体来说，就是管理集群中所有分区的状态并执行相应的管理操作。 controller管理状态 controller维护的状态分为两类：每台broker上的分区副本和每个分区的leader副本信息。从维度上看，这些状态可分为副本状态和分区状态。 副本状态机 分区状态机 controller职责 更新集群元数据信息 创建topic 删除topic 分区重分配 preferred leader副本选举 topic分区扩展 broker加入集群 broker崩溃 受控关闭 controller leader选举 broker请求处理 Reactor模式 Kafka broker处理请求的模式就是Reactor设计模式。Reactor设计模式是一种事件处理模式，旨在处理多个输入源同时发送过来的请求。Reactor模式中的服务处理器或分发器将入站请求按照多路复用的方式分发到对应的请求处理器。 Kafka broker请求处理 Kafka broker请求处理实现了Reactor模式。在Kafka中，每个broker都有一个acceptor线程和若干个processor线程。processor线程的数量是可以配置的。 producer端设计架构producer端基本数据结构 ProducerRecord 一个ProducerRecord封装了一条待发送的消息（或称为记录）。 ProducerRecord由5个字段构成: topic：该消息所属的topic partition：该消息所属的分区 key：消息key value：消息体 timestamp：消息时间戳 RecordMetadata 该数据结构表示Kafka服务器端返回给客户端的消息的元数据 offset：消息在 分区日志中的位移信息 timesstamp：消息时间戳 topic/partition checksum：消息CRC32码 serializedKeySize：序列化后消息的key字节数 serializedValueSize：序列化后消息value字节数 工作流程如果把producer统一看成一个盒子，那么整个producer端的工作原理便如图所示。大体来说，用户首先构建待发送的消息对象ProducerRecord，然后调用KafkaProducer#send方法进行发送。KafkaProducer接收到消息后首先对其进行序列化，然后结合本地缓存的元数据信息一起发送给partitioner去确定目标分区，最后追加写入内存中的消息缓冲池。 调用KafkaProducer.send执行的操作： 序列化+计算目标分区 追加写入消息缓冲区 Sender线程预处理及消息发送 consumer端设计架构consumer group 状态机新版本consumer依赖于broker端的组协调者coordinator来管理组内的所有consumer实例并负责把分配方案发到每个consumer上。分配方案由组内的leader consumer根据指定的分区分配策略指定的。 分区分配的操作在consumer端执行而非broker端的好处： 便于维护与升级：如果在broker端实现，那么分配策略的变动势必要重启整个Kafka集群。生产环境中重启服务器的代价是很高的。 便于实现自定义策略：不同的策略由不同的逻辑实现。coordinator端代码不容易实现灵活可定制的分配逻辑 解耦了组管理与分区分配，coordinator负责组管理工作，而consumer程序负责分区分配。 Kafka为每个consumer group定义了5个状态： Empty：表明group下没有任何active consumer，但可能包含位移信息。 PreparingRebalance：该状态表明group正在准备进行group rebalance。 AwaitingSync：该状态表明所有成员都已经加入组并等待leader consumer发送分区分配方案。 Stable：该状态表明group开始正常消费。此时group必须响应clients发送过来的任何请求。 Dead：该状态表明group已经彻底废弃，group内没有任何成员并且group的所有元数据都已被删除。 实现精确一次处理语义(exactly-once semanties, EOS)clients端常见的3种消息交付语义： 最多一次（ai most once）：消息可能丢失也可能被处理，但最多只会被处理一次 至少一次（at last once）：消息不会丢失，但可能被多次处理 精确一次（exactly once）：消息被处理且只会被处理一次。 幂等性producer（idempotent producer）幂等性producer是Apache Kafka 0.11.0.0版本用于实现EOS的一个利器。若一个操作执行多次的结果与只运行一次的结果是相同的，那么称该操作为幂等操作。引入幂等producer表示它的发送操作是幂等。瞬时的发送错可能导致produecer端出现重试，同一个消息被producer发送多次，但在broker端这条消息只会被写入日志一次。 幂等性producer的设计思路类似于TCP的工作方式。发送到broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和TCP不同的是，这个序列号不会被丢弃，相反Kafka会把它们保存在底层日志中，这样即使分区的leader副本挂掉，新选出来的leader broker也能执行消息去重工作。 事务（transaction）对事务的支持是Kafka实现EOS的第二个利器。引入事务使得clients端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。 处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中。重要的是不论是发送还是消费，Kafka都能保证它们是原子性，即所有的写入操作幺妹全部成功，要么全部失败。 Kafka为实现事务要求应用程序必须提供一个唯一的id来表征事务。这个id被称为事务id，它必须在应用程序所有的会话上是唯一的。 PS：未完待续，后续深入学习再做补充]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis设计与实现（笔记）]]></title>
    <url>%2F2019%2F02%2F25%2FRedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%88%E7%AC%94%E8%AE%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Redis总体认识Redis是一个速度非常快的非关系远程内存数据库，它不仅性能强劲，而且具有复制特性以及为解决问题而省的独一无二的数据模型。 数据结构与对象简单动态字符串（SDS）Redis没有直接使用C语言传统的字符串表示（以空字符结尾的字符数组），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将SDS用作Redis的默认字符串表示。 SDS的定义每个sds.h/shshdr结构表示一个SDS值： 1234567891011struct sdshdr&#123; //记录buf数组中已使用字节的数量 //等于SDS所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[];&#125;; SDS遵循C字符串以空字符结尾的惯例，保存空字符串的1字节空间不计算在SDS的len属性里面，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由SDS函数自动完成的，所以这个空字符对于SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS可以直接重用一部分C字函数库里面的函数 SDS与Ｃ字符串的区别 常数复杂度获取字符串长度 获取一个Ｃ字符串的长度，操作复杂度为Ｏ(N)。 获取一个SDS的长度复杂度为O(1)，因为SDS在len属性中记录了SDS本身的长度。 通过使用SDS而不是C字符串，确保了获取字符串长度的工作不会成为Redis的性能瓶颈。 杜绝缓冲区溢出 与C字符串不同，SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当SDS API需要对SDS进行修改时，API会先检查SDS的空间是否满足修改的需求，如果不满足的话，API会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作。 减少修改字符串时带来的内存重新分配次数 空间预分配，用于优化SDS的字符串增长操作：当需要进行空间扩展时，程序不仅会为SDS分配修改时所必须要的空间，还会为SDS分配额外的未使用空间。 如果对SDS进行修改之后，SDS的长度将小于1MB，那么程序分配和len属性同样大小的未使用空间，这时SDS len属性将和free属性的值相同。 如果对SDS进行修改之后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间.。 惰性空间释放，用于优化SDS的字符串缩短操作：当API需要缩短SDS保存的字符串时，程序并不立即使用内存重新分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。与此同时，SDS也提供了相应的API，可以在有需要时真正地释放SDS的未使用空间。所以不用担心惰性空间释放策略会造成内存浪费。通过使用惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。 二进制安全 所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。 通过使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。 兼容部分C字符串 链表链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。Redis构建了自己的链表实现。链表在Redis中的应用非常广泛，比如列表键的底层实现之一就是链表。除了链表键之外，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还是用了链表来保存多个客户端的状态信息，以及使用链表来构建客户端输出缓冲区。 链表和链表节点的实现每个链表节点使用一个adlist.h/listNode结构来表示 12345678typedef struct listNode&#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;&#125;listNode; 多个listNode可以通过prev和next指针组成双端链表。 使用adlist.h/list来持有链表的话，操作起来会更方便： 1234567891011121314typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含的节点数量 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值对比函数 int (*match)(void *ptr, void *key);&#125;list; Redis的链表实现的特性可以总结如下； 双端 无环 带表头指针和表尾指针 带链表长度计数器 多态：链表节点使用void *指针来保存节点值，并且可以通过list结构的dup、match、free三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。 字典字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。 字典在Redis中的应用相当广泛，比如Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。除了用来表示数据库之外，字典还是哈希键的底层实现之一。 字典的实现哈希表Redis字典使用的哈希表有dict.h/dictht结构定义： 1234567891011typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size； //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //哈希表已有节点的数量 unsigned long used;&#125;dictht; 哈希表节点哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对： 123456789101112typedef struct dictEntry&#123; //键 void *key; //值 union( void *val; uint64_t u64; int64_t s64; )v; //指向下个哈希表节点，形成链表 struct dictEntry *next;&#125;dictEntry; 字典Redis中的字典由dict.h/dict结构来表示： 123456789101112typedef struct dict&#123; //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx; /*rehashing not in progress if rehashidx == -1 */&#125;dict; type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数。 privdata属性则保存了需要传给那些类型特定函数的可选参数。 1234567891011121314typedef struct dictType&#123; //计算哈细致的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(keyDup)（void *privdata, const void *key); //复制值的函数 void *(valueDup)（void *privdata, const void *obj); //对比键的函数 int (*keyCompare)（void *privdata, const void *key1, const void *key2); //销毁键的函数 void (*keyDestructor)（void *privdata, void *key); //销毁值的函数 void (*valDestructor)（void *privdata, void *obj);&#125;dictType; ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。 哈希算法当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis使用MurmurHash2算法来计算键的哈希值。 解决键冲突Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接骑起来，这就要解决了键冲突的问题。 渐进式rehash为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。 扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成。最终结果是将ht[0]包含所有键值对都迁移到ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。 但是为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。 渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作摊到对字典的每个添加、删除、查找和更新操作之上，从而避免了集中式rehash而带来的庞大计算量。 跳跃表跳跃表（skiplist)是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表支持平均O(logN)，最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树媲美，并且因为跳跃表的实现比平衡树更为简单，所以有不少程序都用跳跃表来代替平衡树。 Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。 每个跳跃表节点的层高都是1至32之间的随机数 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。 跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。 整数集合整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。 每个intset.h/inttset结构表示一个整数集合： 12345678typedef struct intset&#123; //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];&#125; contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。 contents数组的真正类型取决于encoding属性的值 升级当新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要进行升级（upgrade)，然后才能将新元素添加到整数集合里面。 升级分为三部进行： 根据新元素的类型，扩展整数集合底层数组的孔家你大小，并为新元素分配空间 将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素继续放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性不变。 将新元素添加到底层数组里面。 升级的好处： 提升整数集合的灵活性，因为C语言是静态类型语言，为了避免类型错误，通常不会将两种不同类型的值放在同一个数据结构里面。 尽可能地节约内存，只在有需要的时候进行升级。 压缩列表压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是是小整数值，要么就是长度比较长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。 压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含 任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 压缩列表和压缩列表节点的构成 对象Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每个对象都用到了至少一种数据结构。 通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，可以针对不同的使用场景，为对像设置多种不同的数据结构实现，从而优化对象在不同场景的使用效率。 Redis的对象系统还实现了基于引用技术技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被释放；另外，Redis还通过引用技术技术实现了对象共享机制，在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。 Redis的对象带有访问时间记录信息。 Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据结构有关的三个属性分别是type属性、encoding属性和ptr属性： 12345678910typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4' //指向底层实现数据结构的指针 void *ptr: //... &#125;robj; 编码转换 字符串对象 列表对象 哈希对象 集合对象 有序集合对象 内存回收因为C语言并不具备自动内存回收功能，所以Redis在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制，通过这一机制，程序可以 通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。 对象共享对象的引用计数属性还带有对象共享的作用。目前来说，Redis会在初始化服务器时，创建一万个字符串对象，这些对象 包含了从0到9999的所有整数值，当需要用到这些字符串对象时，服务器就会使用这些共享对象，而不是新创建对象。 单机数据库的实现数据库Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库： 1234567struct redisServer&#123; //.. //服务器的数据库数量 int dbnum； //一个数组，保存着服务器中的所有数据库 redisDb *Db;&#125;; 在服务器内部，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个指向redisDb结构的指针。 123456typedef struct redisClient&#123; //... //记录客户端当前正在使用的数据库 redisDb *db； //...&#125;redisClient redisClient.db指针指向redisServer.db数组的其中一个元素，而被指向的元素就是客户端的目标数据库。 数据库键空间Redis是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个redis.h/redisDb结构表示，其中redisDb结构中的dict字典保存了数据库中的所有键值对，这个字典被称为键空间（key space）： 12345678typedef struct redisDb&#123; //... //数据库键空间，保存着数据库中的所有键值对 dict *dict; //过期字典，保存着键的过期时间 dict *expores; //...&#125;redicDb; 键空间和用户所见的数据库是直接对应的： 键空间的键也就是数据库的键，每个键都是一个字符串对象。 键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种对象。 所有针对数据库的操作，增删改查，实际上都是对键空间字典进行操作来实现的。 其他键空间操作 维护操作 读取键之后，服务器会更新键空间的命中（hit）次数或键空间不命中（miss）次数。 更新键的LRU（最后一次使用）时间。 键过期，删除 键被WATCH命令监视，修改后将键标记为脏（dirty），进行通知 键修改后，按配置发送相应的数据库通知 设置键的生存时间或过期时间 过期键删除策略惰性删除+定期删除 惰性删除惰性删除策略对CPU时间来说是友好的：程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行 ，并且删除的目标仅限与当前处理的键，这个策略不会在删除其他无关的过期键上花费任何CPU时间。 惰性删除的缺点是：它对内存是最不友好的，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会被释放。有内存泄露的危险。 定期删除定期删除策略每隔一段时间执行一次过期键操作，并通过限制删除键执行的时长和频率来减少删除操作对CPU时间的影响。 惰性删除策略的实现过期键的惰性删除策略由db.c/expirIfNeeded函数实现。 定期删除策略的实现过期键的定期删除策略由redis.c/activeExpireCycle函数实现，每当Redis服务器周期性操作redis.c/serverCron函数执行时，activeExpireCycle就会被调用，它在规定时间内，分多次遍历服务器中的多个数据库，从数据库的expires字典中随机检查一部分建的过期时间，并删除其中的过期键。 其余重点 执 行SAVE命令或者BGSAVE命令所产生的新RDB未见不会包含已经过期的键 执行BGREWRITEAOF命令所产生的重写AOF未见不会包含已经过期的键 当一个过期键被删除之后，服务器会追加一条DEL命令到现有AOF文件的末尾 当主服务器删除一个过期键之后，它会向所有从服务器发送一条DEL命令，显式地删除过期键 从服务器及时发现过期键也不会自作主张地删除它，而是等待主节点发来DEL命令，这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。 当Redis命令对数据库进行修改之后，服务器会根据配置向客户端发送数据库通知。 RDB持久化因为Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。 为了解决这个为题，Redis提供了RDB持久化功能，这个功能可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失。 RDB持久化既可以手动执行，也可以根据服务器配置选项定期执行。 RDB文件的创建与载入 SAVE命令：阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求： 12redis&gt; SAVE //等待直到RDB文件创建完毕OK BGSAVE命令：派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求： 12redis&gt; BGSAVE //派生子进程，并由子进程创建RDB文件Background saving started RDB文件是一个经过压缩的二进制文件，由多个部分组成 对不同类型的键值对，RDB文件会使用不同的方式来保存它们 AOF持久化除了RDB持久化功能之外，Redis还提供了AOF（Append Only FIle）持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据状态的。 #### AOF持久化的实现分为三步 命令追加 当AOF持久化功能处于打开时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾 AOF文件的写入与同步 Redis的服务器进程就是一个事件循环（loop），这个循环中的文件时间负责接收客户端的命令请求，以及客户端发送命令回复，而时间事件则负责执行serverCron函数这样需要定时运行的函数。 因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲去里面，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面。 AOF文件的载入与数据还原因为AOF文件里包含了重建数据库状态所需的所有写命令，所以服务器只要读入并重新执行一遍AOF文件里面保存的命令，就可以还原服务器关闭之前的数据库状态。 AOF后台重写为了解决数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。 事件Redis服务器是一个事件驱动程序，服务器需要处理以下两类事件： 文件事件（fileevent）：Redis服务器通过套接字与客户端（或者其他Redis服务器）进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端（或者其他服务器）的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列网络通信操作。 时间事件（time event）：Redis服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。 文件事件Redis基于Reactor模式开发了自己的网络事件处理其器：这个处理器被称为文件事件处理器（flie event handler）： 文件事件处理器使用I/O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应到（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作像相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 文件事件处理器既实现了高性能的网络通信模型，又可以很好地与Redis服务器中其他同样以单线程方式运行的模块进行对接，这保持了Redis内部单线程设计的简单性 时间事件Redis的时间事件分为以下两类： 定时事件：让一段程序在指定的时间之后执行一次。 周期性事件：让一段程序每隔指定时间就执行一次。 服务器将所有时间事件都放在一个无序链表（不按when属性的大小排序）中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。 事件的调度与执行因为服务器中同时存在文件事件和时间事件两种事件类型，所以服务器必须对这两种事件进行调度。 客户端 服务器状态结构使用clients链表链接多个客户端状态，新添加的客户端状态会被放到链表的末尾 客户端状态的flags属性使用不同标志来表示客户端的角色，以及客户端当前所处的状态 输入缓冲区记录了客户端发送的命令请求，这个缓冲去的大小不能超过1GB 命令的参数和参数个数会被记录在客户端状态的argv和argc属性里面，而cmd属性则记录了客户端要执行命令的实现函数 客户端有固定大小缓冲和可变大小缓冲区两种缓冲区可用，其中固定大小缓冲区的最大大小为16KB，而可变大小缓冲去的最大大小不能超过服务器设置的硬性限制值。 输出缓冲区限制值有两种，如果输出缓冲区的大小超过了服务器设置的硬性设置，那么客户端会被立即关闭；除此之外，客户端在一定时间内，一直超过服务器设置的软性限制，那么客户端也会被关闭 当一个客户端通过网络连接连上服务器时，服务器会为这个客户端创建相应的客户端状态。网络连接关闭、发送了不合协议格式的命令请求、成为CLIENT KILL命令的目标、空转时间超时、输出缓冲区的大小超出限制，以上这些原因都会造成客户端被关闭 处理Lua脚本的伪客户端在服务器初始化时创建，这个客户端会一直存在，直到服务器关闭 载入AOF文件时使用的为2客户端在载入工作开始时动态创建，载入工作完毕之后关闭 服务器 一个命令请求从发送到完成主要包括以下步骤： 客户端将命令请求发送给服务器； 服务器读取命令请求，并分析出命令参数 命令执行器根据参数查找命令的实现函数，然后执行实现函数并得出命令回复 服务器将命令回复返回给客户端 serverCron函数默认每隔100毫秒执行一次，它的工作主要包括更新服务器状态信息，处理服务器接收的SIGTERN信号，管理客户端资源和数据库状态，检查并执行持久化操作等等 服务器从启动到能够处理客户端的命令请求需要执行以下步骤： 初始化服务器状态 载入服务器配置 初始化服务器数据结构 还原数据库状态 执行事件循环 多机数据库的实现SentinelSentinel（哨岗、哨兵）是Redis的高可用性（high availability）解决方案：由一个或多个Sentinel实例（instance）组成的Sentinel系统（system)可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。 后续深入学习再作补充]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Linux内核]]></title>
    <url>%2F2019%2F02%2F25%2FLinux%E5%86%85%E6%A0%B8%EF%BC%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Linux 的优势 Linux是免费的。除硬件之外，无需任何花费就能安装一套玩整的Linux系统 Linux的所有成分都可以充分地定制。通过内核编译选项，你可以选择自己真正需要的特征来定制内核。 Linux可以运行在低档、便宜的硬件平台上。 Linux是强大的，由于充分挖掘了硬件部分的特点，使得Linux系统速度非常块，Linux的主要目标是效率 Linux的开发者都是非常出色的程序员。 Linux内核非常小，而且紧凑。 Linux与很多通用操作系统高度兼容。 Linux有很好的技术支持 内核控制路径（Kernel control path）表示内核处理系统调用、异常或中断所执行的指令序列。 最简单的情况下，CPU从第一条指令到最后一条指令顺序地执行内核控制路径。然而当下述事件之一发生时，CPU交错执行内核控制路径： 运行在用户态的进程调用一个系统调用。 当运行一个内核控制路径时，CPU检测到一个异常（例如，访问一个不在RAM中的页）。 当CPU正在运行一个启用了中断的内核控制路径时，一个硬件中断发生。 在支持抢占式调度的内核中，CPU正在运行，而一个更高优先级的进程加入就绪队列，则中断发生。 同步内核路径 非抢占式内核，当进程在内核态执行时，它不能被任意挂起，也不能被另一个进程代替。因此，在单处理器系统上，中断或异常处理程序不能修改的所有内核数据结构，内核对它们讷的访问都是安全的 禁止中断，单处理器系统上的另一种同步机制是：在进入一个临界区之前禁止所有硬件中断，离开时再重新启动中断。 信号量,信号量仅仅是与一个数据结构相关的计数器。所有内核线程在试图访问这个数据结构之前，都要检查这个信号量。可以把每个信号量看成一个对象，其组成如下： 一个整数变量 一个等待进程的链表 两个原子方法：down()和up() 自旋锁,如果修改数据结构所需的时间比较段，那么，信号量可能是低效的。为了检查信号量，内核必须把进程插入到信号量链表中，然后挂起它。因为这两种操作比较费时，完成这些操作时，其他的内核控制路径可能已经释放了信号量。在这些情况下，多处理器操作系统使用了自旋锁（spin lock）。自旋锁与信号量非常相似，但没有进程链表，当一个进程发现锁被另一个进程锁着时，它就不停地“旋转”，执行一个紧凑的循环指令直到锁打开。当然，自旋锁在单处理器环境下是无效的。 内存寻址随机访问存储器（RAM）的使用 所有的Unix操作系统都将RAM毫无疑义地划分为两部分，其中若干兆字节专门用于存放内核映像（也就是内核代码和内核静态数据结构）。RAM的其余部分通常有虚拟内存系统来处理，并且用在以下三种可能的方面： 满足内核对缓冲去、描述符及其他动态内核数据结构的请求 满足进程对一般内存区的请求及对文件内存映射的请求 借助于高速缓存从磁盘及其他缓冲设备获得较好的性能 内核内存分配器 内存内核分配其（Kernel Memory Allocator, KMA）是一个子系统，它试图满足系统中所有部分对内存的请求。 基于各种不同的算法技术，已经提出了集中KMA，包括： 资源图分配算法（allocator） 2的幂次方空间链表 McKusick-Karels分配算法 伙伴（Buddy）系统 Mach的区域（Zone）分配算法 Dynix分配算法 Solaris的Slab分配算法 物理内存布局 在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用（或者因为它们映射硬件设备I/O的共享内存，或者因为相应的页框含有BIOS数据）。 内核将下列页框记为保留： 在不可用的物理地址范围内的页框。 含有内核代码和已初始化的数据结构的页框 保留页框中的页绝不嫩被动态分配或交换到磁盘上。 进程进程链表 Linux的进程链表是一个双向链表，进程链表把所有进程的描述符链接起来。每个task_struct结构都包含一个list_head类型的tasks字段，这个类型的prev和next字段分别指向前面和后面的task_struct元素。 进程链表的头是init_task描述符，它是所谓的0进程（process 0）或swapper进程的进程描述符。init_task的tasks.prev字段指向链表中最后插入的进程描述符tasks字段。 TASK_RUNNING状态的进程链表 当内核寻找一个新进程在CPU上运行时，必须只考虑可运行进程（即处在TASK_RUNNING状态的进程）。 早期的Linux版本把所有的可运行进程都放在同一个叫作运行队列（runqueue）的链表中，由于维持链表中的进程按优先级排序开销过大，因此，早期的调度程序不得不为选择“最佳”可运行进程而扫描整个队列。 Linux 2.6实现的运行队列有所不同。其目的是让点读程序能在固定的时间内选出“最佳”可运行程序，与队列中可运行的进程数无关。提高调度程序运行速度的诀窍是建立多个可运行进程链表，每种进程优先权对应一个不同的链表。这是一个通过使数据结构更复杂来改善性能的典型例子：调度程序的操作效率的确更高了，但运行队列的链表却为此而被拆分成140(0-139）个不同的队列。——空间换时间 进程间的关系 程序创建的进程具有父/子关系。如果一个进程创建多个子进程时，则子进程之间具有兄弟关系。 图3-4显示了一组进程间的亲属关系。进程P0接连创建了P1，P2，和P3。进程P3又创建了P4。 pidhash表及链表 在几种情况下，内核必须能从进程的PID到处对应的进程描述符指针。 顺序扫描进程链表并检查进程描述符的pid字段是可行但相当低效的。为了加速查找，引入了4个散列表。需要4个散列表是因为进程描述符包含了表示不同类型pid的字段，而且每种类型的PID需要它自己的散列表。 正如计算机科学的基础课程所阐述的那样，散列（hash）函数并不总能确保PID与表的索引一一对应。两个不同的PID散列（hash）到相同的表索引称为冲突（colliding） Linux利用链表来处理冲突的PID：每一个表项是由冲突的进程描述符组成的双向链表。 具有链表的散列法比从PID到表索引的线性转换更优越，这是因为在任何给定的实例中，系统中的进程数总是远远小于32768（所允许的进程PID的最大数）。如果在任何给定的实例中大部分表项都不使用的话，那么把表定义为32768项会是一种存储浪费。 由于需要跟踪进程间的关系，PID散列表中使用的数据结构非常复杂。 PID散列表的数据结构解决了所有这些难题，因为他们可以为包含在一个散列表中任意PID号定义进程链表。 等待队列 等待队列在内核中有很多用途，尤其用在中断处理、进程同步及定时。等待队列表示一组睡眠的进程，当某一条件变为真时，由内核唤醒它们。 等待队列由双向链表实现，其元素包括指向进程描述符的指针。因为等待队列是由中断处理和主要内核函数修改的，因此必须对其双向链表进行保护以免对其进行同事访问，因为同事访问会导致不可预测的后果。 注：雷鸣般兽群问题：即唤醒多个进程只为了竞争一个资源，而这个资源只能有一个进程访问，结果是其他进程必须再次回去睡眠。 非互斥进程插入等待队列链表的第一个位置。互斥进程插入等待队列链表的最后一个位置。 因为所有的非互斥进程总是在双向链表的开始位置，而所有的互斥进程在双向链表的尾部，所以函数总是先唤醒非互斥进程然后再唤醒互斥进程，如果有进程存在的话。 进程切换 硬件上下文 进程恢复执行前必须转股寄存器的一组数据称为硬件上下文（hardware context)。硬件上下文是进程可执行上下文的一个子集。在Linux中，进程硬件上下文的一部分存放在TSS段，而剩余部分存放在内核太堆栈中。 任务状态段(TSS) 80x86体系结构包括了一个特殊的段类型，叫任务状态段（Task State Segment, TSS)来存放硬件上下文。尽管Linux并不使用硬件上下文切换，但是强制它为系统中每个不同的CPU创建一个TSS。 thread字段 在每次进程切换时，被替换进程的硬件上下文必须保存在别处。不能像Intel原始设计那样把它保存在TSS中，因为Linux为每个处理器而不是为每个进程使用TSS。 因此，每个进程描述符包含一个类型为thread_struct的thread字段，只要进程被切换出去，内核就把其硬件上下文保存在这个结构中。 执行进程切换 从本质上说，每个进程切换由两步组成： 切换页全局目录以安装一个新的地址空间 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包括CPU寄存器。 创建进程 Unix操作系统紧紧依赖进程创建来满足用户的需求。 传统的Unix操作系统以统一的方式对待所有的进程：子进程复制父进程所拥有的资源。这种方法使进程的创建非常慢且效率低，因为子进程需要拷贝父进程的整个个、地址空间。 现代Unix内核通过引入三种不同的机制解决了这个问题： 写时复制技术允许父子进程读相同的物理页。只要两者中有一个试图写一个物理页，内核就把这个页的内容拷贝到一个新的物理页，并把这个新的物理页分配给正在写的进程。 轻量级进程允许父子进程共享进程在内核的很多数据结构，如页表、打开文件表及信号处理。 vfork()系统调用创建的进程能共享其父进程的内存地址空间。为了防止父进程重写子进程需要的数据，阻塞父进程的执行，一直到到子进程退出或执行一个新的程序为止。 clone()、fork()及vfork()系统调用 在Linux中、轻量级进程是由名为clone()的函数创建的。 实际上，clone()是在C语言库中定义的一个封装（wrapper）函数，它负责建立新轻量级进程的堆栈并且调用对编程者隐藏的clone()系统调用。 传统的fork()系统调用和vfork()系统调用在Linux中也是用clone()实现的。 内核线程 因为一些系统进程只运行在内核太，所以现代操作系统把它们的函数委托给内核线程（kernel thread），内核线程不受不必要的用户态上下文的拖累。 进程 0 所有进程的祖先叫作进程0，idle进程，或因为历史的原因叫作swapper进程，它是在Linux的初始化阶段从无到有创建的一个内核线程。这个祖先进程使用下列静态分配的数据结构（所有其他进程的数据结构都是动态分配的）： 存放在init_task变量中的进程描述符，由INIT_TASK宏完成对它的初始化 存放在init_thread_union变量中的thread__info描述符和内核堆栈，由INIT_THREAD_INFO宏完成对它们的初始化。。 由进程描述符指向的下列表： init_mm init_fs init_files init_signals init_sighand 主内核页全局目录存放在swapper_pg_dir中。 start_kernel()函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程（一般叫作init进程）。新创建内核线程的PID为1，并与进程0共享每个进程所有的内核数据结构。此外，当调度程序选择到它时，init进程开始执行init（）函数。 在多处理器系统中，每个CPU都有一个进程0.只要打开机器电源，计算机的BIOS就启动某一个CPU，同时禁用其他CPU。运行在CPU0还是上的swapper进程初始化内核数据结构，然后激活其他的CPU，并通过copy_process()函数创建另外的swapper进程，把 0 传递给新创建的swapper进程作为它们的新PID。 进程 1 由进程 0 创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init。结果，init内核线程变为一个普通进程，且拥有自己的每进程（per-process）内核数据结构。在系统关闭之前，init进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。 其他内核线程 Linux使用很多其他内核线程。其中一些在初始化阶段创建，一直运行奥系统关闭，而其他一些在内核必须执行一个任务时“按需”创建，这种任务在内核的执行上下文中得到很好的执行。 进程删除Unix允许进程查询内核以获得其父进程的PID，或者其任何子进程的执行状态。 为了遵循这些设计选择，不允许Unix内核在进程一终止后就丢弃包含在进程描述符字段中的数据。只有父进程发出了与被终止的进程相关的wait（）类系统调用之后，才允许这样做。这就是引入僵死状态的原因：尽管从技术上来说进程已死，但必须保存它的描述符，直到父进程得到通知。 如果父进程在子进程结束之前结束会发生什么情况呢？在这种情况下，系统中会到处是僵死的进程，而且它们的进程描述符永久占据这RAM。所以这必须强迫所有的孤儿进程成为init进程的子进程来解决这个问题。这样，init进程在用wait（）类系统调用检查其合法的子进程终止时，就会撤销僵死的进程。 对僵死进程的处理有两种可能的方式： 如果父进程不需要接收来自子进程的信号，就调用do_exit()。 如果已经给父进程发送了一个信号，就调用wait4（）或waitpid（）系统调用。 中断和异常中断通常分为同步（synchronous）中断和异步（asynchronous）中断： 同步中断是指当指令执行时有CPU控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后CPU才会发出中断。 异步中断是由其他硬件设备依照CPU时钟信号随机产生的。 在Intel微处理器手册中，把同步和异步中断分别称为异常（exception）和中断（interrupt）。 中断 可屏蔽中断（maskable interrupt） 非屏蔽中断（nonmaskable interrupt） 异常 故障（fault） 陷阱（trap） 异常中止（abort） 编程异常（programmed exception) 中断描述符表 中断描述符表（Interrupt Descriptor Table, IDT）是一个系统表，它与灭一个中断或异常向量相联系，每一个向量在表中有相应的中断或异常处理程序的入口地址。 IDT包含三种类型的描述符。 这些描述符是： 任务门（task_gate) ​ 当中断信号发生时，必须取代当前进程的那个进程的TSS选择符存放在任务门中。 中断门（interrupt gate) ​ 包含段选择符和中断或异常处理程序的段内偏移量。当控制权转移到一个适当的段时， 处理器清IF标志，从而关闭将来会发生的可屏蔽中断。 陷阱门（Trap gate） ​ 与中断门相似，只是控制权传递到一个适当的段时处理器不修改IF标志。 Linux利用中断门处理中断，利用陷阱门处理异常 中断和异常处理程序的嵌套执行 每个中断或异常都会引起一个内核控制路径，或者说代表当前进程在内核态执行单独的指令序列。内核控制路径可以任意嵌套：一个中断处理程序可以被另一个中断处理程序“中断”，因此引起内核控制路径的嵌套执行。如图所示。 允许内核控制路径嵌套执行必须付出代价，那就是中断处理程序必须永不阻塞，换句话说，中断处理程序运行期间不能发生进程切换。事实上，嵌套的内核控制路径恢复执行时需要的所有数据都存放在内核态堆栈栈中，这个栈毫无疑义的属于当前进程。 一个中断处理程序既可以抢占其他的中断处理程序，也可以抢占异常处理程序。相反，异常处理程序从不抢占中断处理程序。 基于以下两个主要原因，Linux交错执行内核控制路径： 为了提高可编程中断控制器和设备控制器的吞吐量。 为了实现一种没有优先级的中断模型。简化了内核代码，提高了内核的可移植性。 IRQ在多处理器系统上的分发 Linux遵循对称多处理模型（SMP），这意味着，内核从内本质上对任何一个CPU都不应该有 偏爱。因而，内核试图以轮转的方式把来自硬件设备的IRQ信号在所有CPU之间分发。因此，所有CPU服务于I/O中断的执行时间片几乎相同。 在系统启动的过程中，引导CPU执行setup_IO_APIC_irqs()函数来初始化I/O APIC芯片。芯片的中断重定向表的24项被填充，以便根据“最低优先级”模式把来自I/O硬件设备的所有信号都传递给系统中的每个CPU。此外，在系统启动期间，所有的CPU都执行setup_local_APIC()函数，该函数处理本地APIC的初始化。特别是，每个芯片的任务优先级寄存器（TPR）都初始化为一个固定的值，这就意味着CPU愿意处理任何类型的IRQ信号，而不管优先级。Linux内核启动后再也不修改这个值。 因为所有的任务优先级寄存器都包含相同的值，因此，有所CPU总是具有相同的优先级。为了突破这种约束，多APIC系统使用本地APIC仲裁优先级寄存器中的值。因为这样的值在每次中断后都自动改变，因此，IRQ信号就公平地在所有CPU之间分发。 简而言之，当硬件设备发生了一个中断信号时，多APIC系统就选择其中的一个CPU，并把该信号传递给相应的本地APIC，本地APIC又依次中断它的CPU。这个事件不通报给其他所有的CPU。 内核同步可以把内核看作是不断对请求进行响应的服务器，这些请求可能来自在CPU上执行的进程，也可能来自发出中断请求的外部设备。这个类比强调内核的各个部分并不是严格按照顺序依次执行的，而是采用交错执行的方式。因此，这些请求可能引起竞争条件,而我们必须采用适当的同步机制对这种情况进行控制。 内核抢占 如果进程执行内核函数时，即它在内核态运行时，允许发生内核切换（被替换的进程是正执行内核函数的进程），这个内核就是抢占的。 使内核可抢占的目的是减少用户态进程的分派延迟（dispatch latency），即从进程变为可执行状态到它实际开始运行之间的时间间隔。 内核使用的各种同步技术 每CPU变量 最好的同步技术是把设计不需要同步的内核放在首位。最简单也是最最重要的同步技术包括把内核变量声明为每CPU变量（per-cpu variable)。每CPU变量主要是数据结构的数组，系统的每个CPU对应数组的一个元素。 一个CPU不应该访问与其它CPU对应的数组元素，另外，它可以随意读或修改它自己的元素而不用担心出现竞争条件。但是，这也意味着每CPU变量基本上只能在特殊情况下使用，也就是当它确定在系统的CPU上的数据在逻辑上是独立的时候。 每CPU的数组元素在主存中被排列以使每个数据结构存放在硬件高速缓存的不同行，因此，对每CPU数组的并发访问不会导致高速缓存行的窃用和失效。 此外，在单处理器和多处理器系统中，内核抢占都可能使每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。 原子操作 若干汇编语言指令具有“读—修改—写”类型——也就是说，它们访问内存单元两次，第一次读原值，第二次写新值。 避免由于“读—修改—写”指令引起的竞争条件的最容易的方法，就是确保这样的操作在芯片级是原子的。任何一个这样 的操作都必须以单个指令执行，中间不嫩中断，且避免其他的CPU访问同一存储器单元。这些很小的原子操作（atomic opreations)可以建立在其他更灵活机制的基础之上以创建临界区。 操作码前缀是lock字节（0xf0）的“读—修改—写”汇编语言指令即使在多处理器系统中也是原子的。当控制大暖检测到这个前缀时，就“锁定”内存总线，直到这条指令执行完成为止。因此，当枷锁的指令执行时，其他处理器不能访问这个内存单元。 优化和内存屏障 当使用优化的编译器时，编译器可能重新安排汇编语言指令以使寄存器以最优的方式使用。此外，现代CPU通常并行地执行若干条指令，且可能重新安排内存访问。这种重新排序可以极大地加速程序的执行。 然而，当处理同步时，必须避免指令重新排序。如果发放在同步原语之后的一条指令在同步原语本身之前执行，事情很快就会变得失控。事实上，所有的同步原语起优化和内存屏障的作用。 优化屏障（memory barrier）原语保证编译程序不会混淆放在原语操作之前的汇编语言指令和放在原语操作之后的汇编语言指令。在Linux中，优化屏障就是barrier（）宏，它展开为asm volatile(“:::”memory”)。volatile关键字禁止编译器把asm指令与程序中的其他指令重新组合。memory关键字强制编译器假定RAM中的所有内存单元已经被汇编语言指令修改。因此，编译器不能使用存放在CPU寄存器中的内存单元的值来优化asm指令前的代码。 内存屏障（memory barrier）原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，内存屏障类似于防火墙，让任何汇编语言指令都不能通过。 Linux使用六个内存屏障原语： rm() rmb() wmb() smp_mb() smp_rmb() smp_wmb() 这些原语也被当做优化屏障，因为我们必须保证编译程序不在屏障前后移动汇编语言指令。内存屏障原语的实现依赖与系统的体系机构。在80x86微处理器上，如果CPU支持lfence汇编语言指令，就把rmb（）宏展开为asm volatile（”lfence”)，否则就展开为asm volatile（”lock;addl $0,0(%%esp)”:::”memory”)。 自旋锁 一种广泛使用的同步技术是加锁（locking）。当内核控制路径必须访问共享数据结构或进入临界区时，就需要为自己获取一把”锁“。 自旋锁（spin lock）是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁”开着“，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径”锁着“，就在周围”旋转“，反复执行一条紧凑的循环指令，直到锁被释放。 自旋锁的循环指令表示”忙等“。及时等待的内核控制路径无事可做（除了浪费时间），它也在CPU上保持运行。不过自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时间片段。 一般来说，由自旋锁所保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这种锁本身不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。在自旋锁忙等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进程替代。 在Linux中，每个自旋锁都用spin_lock_t结构表示，其中包含两个字段： slock：该字段表示自旋锁的状态，值为1表示”未加锁“状态，而任何负数和0都表示”加锁“状态。 break_lock：表示进程正在忙等自旋锁（只在内核支持SMP和内核抢占的情况下使用该标志）。 读/写自旋锁 读/写自旋锁的引入是为了增加内核的并发能力。只要没有内核控制路径对数据结构进行修改，读/写自旋锁就允许多个内核控制路径同时读同一数据结构。如果一个内核控制路径想对这个结构进行写操作，那么它必须首先获取读/写锁的写锁，写锁授权独占访问这个资源。当然，允许对数据结构并发读可以提高系统性能。 顺序锁 Linux2.6中引入了顺序锁（seqlock），它与读/写自旋锁非常相似，只是它为写着赋予了较高的优先级：事实上，即使在读者正在读的时候也允许写者继续运行。这种策略的好处是写者永远不会等待（除非另一个写者正在写），缺点是有些时候读者不等不反复多次读相同的数据直到它获得有效的副本。 每个顺序所都是包括两个字段seqlock_t结构：一个类型为spin_lock_t的lock字段和一个整型的sequence字段，第二个字段是一个顺序计数器。**每个读者都必须在读数据前后两次读顺序计数器，并检查两次读到的值是否相同，如果不相同，说明新的写者已经开始写并增加了顺序计数器，因此暗示读者刚读到的数据是无效的。 读—拷贝—更新（RCU） 读—拷贝—更新（RCU）是为了保护在多数情况下被多个CPU读的数据结构而设计的另一种同步技术。RCU允许多个读者和写者并发执行。而且，RCU是不适用锁的，就是说，它不适用被所有CPU共享的锁或计数器，在这一点上与读/写自旋锁和顺序锁（由于高速缓存行窃用和失效而有很高的开销）相比，RCU具有更大的优势。 其关键思想包括限制RCU的范围： RCU只保护被动态分配并通过指针引用的数据结构 在被RCU保护的临界区中，任何内核控制路径都不能失眠。 信号量 实际上，Linux提供两种信号量： 内核信号量，由内核控制路径使用 System V IPC信号量，由用户态进程使用 内核信号量类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。然而，当内核控制路径试图获取内核信号量所保护的忙资源时，相应的进程被挂起。只有在资源被释放时，进程才再次变为可运行的。因此，只有可以睡眠的的函数才能获取内核信号量，中断处理程序和可延迟函数都不能使用内核信号量。 禁止本地中断 确保一组内核语句被当做一个临界区处理的主要机制之一就是中断禁止。即使当硬件设备产生了一个IRQ信号时，中断禁止也让内核控制路径继续执行，因此，这就提供了一中有效的方式 ，确保中断处理程序访问的数据结构也受到保护。然而禁止本地中断并不保护运行在另一个CPU上的中断处理程序对数据结构的并发访问，因此，在多处理器系统上，禁止本地中断经常与自旋锁结合使用。 禁止和激活可延迟函数 禁止可延迟函数在一个CPU上执行的一种简单方式就是禁止在那个CPU上的中断。因为没有中断处理程序被激活，因此，软中断操作就不能异步地开始。 总结 技术 说明 使用范围 每CPU变量 在CPU之间复制数结构 所有CPU 原子操作 对一个计数器原子地”读—修改—写“的指令 所有CPU 内存屏障 避免指令重新排序 本地CPU或所有CPU 自旋锁 加锁时忙等 所有CPU 信号量 加锁时阻塞等待（睡眠） 所有CPU 顺序锁 基于访问计数器的锁 所有CPU 本地中断的禁止 禁止单个CPU上的中断处理 本地CPU 本地软中断的禁止 禁止单个CPU上的可延迟函数处理 本地CPU 读—拷贝—更新（RCU) 通过指针而不是锁来访问共享数据结构 所有CPU 定时测量 Linux计时体系结构 Linux必定执行于定时相关的操作。例如，内核周期性地： 更新自系统启动以来所经过的时间 更新时间和日期 确定当前进程在每个CPU上已运行了多长时间，如果已经超过了分配给它的时间，则抢占它。 更新资源使用统计数 检查每个软定时器的时间间隔是否已到。 进程调度Linux与任何分时系统一样，通过一个进程到另一个进程的快速切换，达到表面上看来多个进程同时执行的神奇效果。 Linux的调度基于分时技术：多个进程以”时间多路服用“方式运行，因为CPU的时间被分成片”（slice）”，给每个可运行进程分配一片。如果当前运行进程的时间片或时限到期时，该进程还没有运行完毕，进程切换就可以发生。 传统上把进程分类为“I/O受限（I/O-bound）“或”CPU受限（CPU-bound）“。前者频繁地使用I/O设备，并花费很多时间等待I/O操作的完成；而后者则需要大量CPU时间的数据计算应用程序。 另一种分类法把进程分为三类： 交互式进程（interactive process） 这些进程经常与用户进行交互，因此，要花很多时间等待键盘和鼠标操作。当接受了输入后，进程必须被很快唤醒，否则用户将发现系统反应迟钝。典型的交互式程序是命令shell、文本编辑程序及图形应用程序。 批处理进程（batch process) 这些进程不必与用户交互，因此经常在后台运行。典型的批处理进程是程序设计语言的编译程序、数据库搜索引擎及科学计算。 实时进程（real-time process） 这些进程有很强的调度需要。这样的进程绝不会被低优先级的进程阻塞，它们应该有一个很短的响应时间，更重要的是，响应时间的变化应该很小。典型的实时程序有视频和音频应用程序、机器人控制程序及从物理传感器上收集数据的程序。 调度算法每个Linux进程总是按照下面的调度类型被调度： SCHED_FIFO 先进先出的实时进程 SCHED_RR 时间片轮转的实时进程 SCHED_NORMAL 普通的分时进程 普通进程的调度每个普通进程都有它自己的静态优先级，调度程序使用静态优先级来估计系统中这个进程与其他普通进程之间调度的程度。内核用从100（最高优先级）到139（最低优先级）的数表示普通进程的静态优先级。 基本时间片： 与优先级低的进程相比，通常优先级较高的进程获得更长额CPU时间片。 实时进程的调度每个实时进程都与一个实时优先级相关，实时优先级是一个范围从1（最高优先级）～99（最低优先级）的值。调度程序总是让优先级高的进程运行，换句话说，实时进程运行的过程中，禁止低优先级进程的执行。与普通进程相反，实时进程总是被当成活动进程。 只有在下述事件之一发生时，实时进程才会被另外一个进程取代： 进程被另外一个具有更高实时优先级的实时进程抢占 进程执行了阻塞操作并进入睡眠 进程停止或被杀死 进程通过调用系统调用sched_yield()自愿放弃CPU 进程是基于时间片轮转的实时进程，而且用完了它的时间片。 内存管理​]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>内核</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构学习]]></title>
    <url>%2F2019%2F02%2F25%2F%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[定义架构软件架构指软件系统的顶层结构 相关概念 系统是一群关联个体组成，这些“个体”可以是“子系统”、”模块“、”组件“等；架构需要明确系统包含哪些”个体“。 系统中的个体需要根据某种规则运作，架构需要明确个体运作和协作的规则。 架构是顶层设计；框架是面向编程或配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体。 架构设计的真正目的整个软件技术发展的历史，其实就是一部与”复杂度“斗争的历史，架构的出现也不例外。简而言之，架构是为了应对软件系统负责度而提出的一个解决方案。架构设计的主要目的是为了解决软件系统复杂度带来的问题。 架构是为了应对软件系统复杂度而提出的一个解决方案。架构即（重要）决策，是在一个有约束的盒子里去求解或接近最合适的解。这个有约束的盒子是团队经验、成本、资源、进度、业务所处阶段等所编织、掺杂在一起的综合体（人、财、物、时间、事情等）。架构各有千秋，但是存在恰当的架构用在合适的软件系统中，而这些就是决策的结果。 需求驱动架构。在分析设计阶段，需要考虑一定的人力与时间去”跳出代码，总揽全局“，为业务和IT技术之间搭建一座”桥梁”。 架构设计处于软件研制的前期，一方面，越是前期，就越早发现问题，修改的代价也就越低；另一方面，软件实施后期若有架构上的修改，也需要付出更多的代价。 复杂度的来源复杂度的来源主要有6个。 高性能 对性能孜孜不倦的追求是整个人类技术不断发展的根本驱动力。软件系统中高性能带来的复杂度主要体现在两个方面，一方面是单台计算机内部为了高性能带来的复杂度；另一方面是多态计算机集群为了高性能带来的复杂度。 单机复杂度 计算机内部复杂度最关键的地方就是操作系统，操作系统是软件系统的运行环境，操作系统的复杂度决定了软件系统的复杂度。 操作系统和性能最相关的是进程和线程。 集群的复杂度 通过大量机器来提升性能，并不仅仅是增加机器这么简单，让多台机器配合起来达到高性能的目的，是一个复杂的任务。 任务分配 任务分配的意思是指每台机器都可以处理完成的业务任务，不同的任务分配到不同的机器上执行。 需要增加任务分配器 任务分配器和真正的业务服务器之间有连接和交互 任务分配器需要增加分配算法。例如，轮询算法、按权重分配、或按照负载进行分配。 任务分解 简单的系统更加容易做到高性能 可以针对单个任务进行扩展 高可用 维基百科的定义 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。 这个定义的关键在于“无中断”，但恰好难点也在“无中断”上面，因为无论是单个硬件还是单个软件，都不可能做到无中断，硬件会出故障，软件会老化；硬件会逐渐老化，软件会越来越复杂的庞大。 除了硬件和软件本质上无法做到”无中断“，外部环境导致的不可用更加不可避免、不受控制。例如、断点、水灾、的证。 系统的高可用方案五花八门，但万变不离其宗，本质上都是通过“ 冗余 ”来实现高可用。通俗点来讲，就是一台机器不够就两台，两台不够就四台;一个机房可能断电，那就部署两个机房;一条通道可能故障，那就用两条，两条不够那就用三条(移动、电信、联通一起上)。高可用的 “ 冗余 ” 解决方案，单纯从形式上来看，和之前的高性能是一样的，都是通过增加更多机器来达到目的，但其实本质上是有根本区别的: 高性能增加机器目的在于“扩展”处理性能;高可用增加机器目的在于“冗余”处理单元 。 通过冗余增强了可用性，但同事也带来了复杂性。 计算高可用 存储高可用 对于需要存储数据的系统来说，整个系统的高可用设计关键点和难点就在于“存储高可用”。存储与计算相比，有一个本质上的区别: 将数据从一台机器搬到到另一台机器，需要经过线路进行传输 。线路传输的速度是毫秒级别，同一机房内部能够做到几毫秒;分布在不同地方的机房，传输耗时需要几十甚至上百毫秒。例如，从广州机房到北京机房，稳定情况下 ping 延时大约是 50ms ，不稳定情况下可能达到 1s 甚至更多。 综合分析，无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题;但如果完全不做冗余，系统的整体高可用又无法保证，所以存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响 。 高可用状态决策 无论是计算高可用还是存储高可用，其基础都是“ 状态决策 ”，即系统需要能够判断当前的状态是正常还是异常，如果出现了异常就要采取行动来保证高可用。如果状态决策本身都是有错误或者有偏差的，那么后续的任何行动和处理无论多么完美也都没有意义和价值。但在具体实践的过程中，恰好存在一个本质的矛盾: 通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确。 独裁式 协商式 民主式 可扩展性 可扩展性指系统为了应对将来需求变化而提供的一种扩展能力，当有新的需求出现时，系统不需要或者仅需要少量修改就可以支持，无须整个系统重构或者重建。由于软件系统固有的多变性，新的需求总会不断提出来，因此可扩展性显得尤其重要。在软件开发领域，面向对象思想的提出，就是为了解决可扩展性带来的问题;后来的设计模式，更是将可扩展性做到了极致。得益于设计模式的巨大影响力，几乎所有的技术人员对于可扩展性都特别重视。设计具备良好可扩展性的系统，有两个基本条件: 正确预测变化 、 完美封装变化 。但要达成这两个条件，本身也是一件复杂的事情。 预测变化 不能对每个设计点都考虑可扩展性 不能完全不考虑可扩展性 所有的预测都存在出错的可能性 应对变化 将”变化“封装在一个”变化层”，将不变的部分封装在一个独立的“稳定层”。无论是变化层依赖稳定层，还是稳定层依赖变化层都是可以的，需要根据具体业务情况来设计。 系统需要拆分出变化层和稳定层 需要设计变化层和稳定层之间的接口 设计模式的核心就是，封装变化，隔离可变性。 低成本 低成本给架构设计带来的复杂度主要体现在，往往只有“创新”才能达到低成本的目标。。这里的“创新”既包括开创一个全新的技术领域(这个要求对绝大部分公司太高)，也包括引入新技术，如果没有找到能够解决自己问题的新技术，那么就真的需要自己创造新技术了。 安全 安全本身是一个庞大而又复杂的技术领域，并且一旦出问题，对业务和企业形象影响非常大。 功能安全 从实现的角度来看，功能安全更多地是和具体的编码相关，与架构关系不大。 架构安全 如果说功能安全是“防小偷”，那么 架构安全就是“防强盗” 。强盗会直接用大锤将门砸开，或者用炸药将围墙炸倒;小偷是偷东西，而强盗很多时候就是故意搞破坏，对系统的影响也大得多。因此架构设计时需要特别关注架构安全，尤其是互联网时代，理论上来说系统部署在互联网上时，全球任何地方都可以发起攻击。 规模 规模带来复杂度的主要原因就是“量变引起质变” ，当数量超过一定的阈值后，复杂度会发生质的变化。 功能越来越多，导致复杂度指数级上升 数据越来越多，系统复杂度发生质变 架构设计三原则 合适原则 合适原则宣言：“合适优于业界领先”。 真正优秀的架构都是在企业当前人力、条件、业务等各种约束下设计出来的，能够合理地将资源整合在一起并发挥出最大功效，并且能够快速落地。这也是很多 BAT 出来的架构师到了小公司或者创业团队反而做不出成绩的原因，因为没有了大公司的平台、资源、积累，只是生搬硬套大公司的做法，失败的概率非常高。 简单原则 简单原则宣言：“简单优于复杂”。 软件领域的复杂性体现在两个方面： 结构的复杂性 结构复杂的系统几乎毫无例外具备两个特点： 1）组成复杂系统的组件数量更多 2）同时这些组件之间的关系也更加复杂 逻辑的复杂性 演化原则 演化原则宣言：“演化优于一步到位”。 首先 ，设计出来的架构要满足当时的业务需要。 其次，架构要不断地在实际应用过程中迭代，保留优秀的设计，修复有缺陷的设计，改正错误的设计，去掉无用的设计，使得架构逐渐晚上。 第三，当业务发生变化时，架构需要扩展、重构，甚至重写；代码也许会重写，但有价值的经验、教训、逻辑、设计等却可以在新架构中延续。 架构师在进行架构设计时需要牢记这个原则，时刻提醒自己不要贪大求全，或者盲目照搬大公司的做法。应该认真分析当前业务的特点，明确业务面临的主要问题，设计合理的架构，快速落地以满足业务需要，然后在运行过程中不断完善架构，不断随着业务演化架构。即使是大公司的团队，在设计一个新系统的架构时，也需要遵循演化的原则，而不应该认为团队人员多、资源多，不管什么系统上来就要一步到位，因为业务的发展和变化是很快的，不管多牛的团队，也不可能完美预测所有的业务发展和变化路径。 合适优于先进&gt;演化优于一步到位&gt;简单优于复杂。 架构设计流程 识别复杂度 设计备选方案 评估和选择备选方案 详细方案设计 架构模式在具体的实践过程中，为了更快、更好地设计出优秀的架构，除了掌握这些基础知识外，还需要掌握业界已经成熟的各种架构模式。大部分情况下，我们做架构设计主要都是基于已有的成熟模式，结合业务和团队的具体情况，进行一定的优化或者调整;即使少部分情况我们需要进行较大的创新，前提也是需要对已有的各种架构模式和技术非常熟悉。 高性能架构模式高性能数据库集群高性能数据库集群的第一种方式是 “ 读写分离 ” ，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力;第二种方式是“分库分表”，既可以分散访问压力，又可以分散存储压力。 读写分离读写分离原理 读写分离的基本原理是将数据库读写操作分散到不同的节点上 ，下面是其基本架构图。 读写分离的基本实现是： 数据库服务器搭建主从集群，一主一从、一主多从都可以。 数据库主机负责读写操作，从机只负责读操作 数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。 业务服务器将写操作发给数据库主机，将读操作发给数据库从机。 读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度: 主从复制延迟和分配机制 。 复制延迟 主从复制延迟会带来一个问题:如果业务服务器将数据写入到数据库主服务器后立刻( 1 秒内)进行读取，此时读操作访问的是从机，主机还没有将数据复制过来，到从机读取数据是读不到最新数据的，业务上就可能出现问题。 解决主从复制延迟的集中常见的方法： 写操作后的读操作指定发给数据库主服务器 读从机失败后再读一次主机 关键业务读写操作全部指向主机，非关键业务采用读写分离。 分配机制 将读写操作区分开来，然后访问不同的数据库服务器，一般有两种方式：程序代码封装和中间件封装。 程序代码封装 程序代码封装指在代码中抽象一个数据访问层，实现读写操作分离和数据库服务器连接的管理 中间件封装 中间件封装指的是独立一套系统出来，实现读写操作和数据库服务器连接的管理。中间件对业务服务器提供SQL兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。 读写分离分散了数据库读写操作的压力，但没有分散存储压力，当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在以下几个方面： 数据量太大，读写的性能会下降，即使有索引，索引也会变得恨到，性能同样会下将。 数据文件会变得很大，数据库备份和恢复费需要耗费很长时间。 数据文件越大，极端情况下丢失数的风险越高。 分库分表业务分库 业务分库指的是按照业务模块将数据分散到不同的数据库服务器。 例如，一个简单的电商网站，包括用户、商品、订单三个业务模块，我们可以将用户数据、商品数据、订单数据分开放到三台不同的数据库服务器上，而不是将所有数据都放在一台数据库服务器上。 虽然业务分库能够分散存储和访问压力，但同时也带来了新的问题。 join操作问题 业务分库后，原本在同一个数据库中的表分散到不同的数据库表中，导致无法使用SQL的join查询。 事务问题 原本在同一个数据库中不同的表可以在用一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改。虽然数据库厂商提供了一些分布式事务的解决方案，但性能实在太低，与高性能存储的目标是相违背的。 成本问题 业务分库同时也带来了成本的代价，本来 1 台服务器搞定的事情，现在要 3 台，如果考虑备份，那就是 2 台变成了 6 台。 分表 将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。 单表数据拆分有两种方式：垂直分表和水平分表 高性能NoSQL关系数据库存在以下缺点： 关系数据库存储的是行为记录，无法存储数据结构 关系数据库的schema扩展很不方便 关系数据库在大数据场景下I/O较高 关系数据库的全文搜索功能较弱 针对上述问题，分别 针对上述问题，分别诞生了不同的 NoSQL 解决方案，这些方案与关系数据库相比，在某些应用场景下表现更好。但世上没有免费的午餐， NoSQL 方案带来的优势，本质上是牺牲ACID中的某个或者某几个特性， 因此我们不能盲目地迷信NoSQL是银弹，而应该将NoSQL作为SQL的一个有力补充 ，NoSQL != No SQL，而是NoSQL = Not Only SQL。常见的 NoSQL 方案分为 4 类。 K-V存储:解决关系数据库无法存储数据结构的问题，以Redis为代表。 文档数据库:解决关系数据库强schema约束的问题，以MongoDB为代表。 列式数据库:解决关系数据库大数据场景下的I/O问题，以HBase为代表。 全文搜索引擎:解决关系数据库的全文搜索性能问题，以Elasticsearch为代表。 高性能缓存架构缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理是将可能重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统。 缓存的架构设计要点： 缓存穿透 缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据。 缓存雪崩 缓存雪崩是指当缓存失效（过期）后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算,这个处理步骤耗时几十毫秒甚至上百毫秒。而对于一个高并发的业务系统来说,几百毫秒内可能会接到几百上千个请求。由于旧的缓存已经被清除,新的缓存还未生成,并且处理这些请求的线程都不知道另外有一个线程正在生成缓存,因此所有的请求都会去重新生成缓存,都会去访问存储系统,从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统,严重的会造成数据库宕机,从而形成一系列连锁反应,造成整个系统崩溃。 缓存热点 虽然缓存系统本身的性能比较高,但对于一些特别热点的数据,如果大部分甚至所有的业务请求都命中同一份缓存数据,则这份数据所在的缓存服务器的压力也很大。例如,某明星微博发布 “ 我们 ” 来宣告恋爱了,短时间内上千万的用户都会来观。缓存热点的解决方案就是复制多份缓存副本,将请求分散到多个缓存服务器上,减轻缓存热点导致的单台缓存服务器压力 。 单服务器高性能模式站在架构师的角度，需要特别关注高性能架构的设计。高性能架构设计主要集中在两方面： 尽量提升单服务器的性能，将单服务器的性能发挥到极致 如果单服务器无法支撑性能，设计服务器集群方案 除了以上两点，最终系统能否实现高性能，还和具体的实现及编码相关。但架构设计是高性能的基础，如果架构设计没有做到高性能，则后面的具体实现和编码能提升的空间是有限的。形象地说，架构设计决定了系统性能的上限，实现细节决定了系统性能的下限。 单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点： 服务器如何管理连接 服务器如何处理请求。 以上两个设计点最终都和操作系统的I/O模型及进程模型相关。 I/O模型：阻塞、非阻塞、同步、异步 进程模型：单进程、多进程、多线程 PPC与TPCPPC是Process Per Connection的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的UNIX网络服务器所采用的模型。基本的流程图是： TPC 是 Thread Per Connection 的缩写,其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。与进程相比,线程更轻量级,创建线程的消耗比进程要少得多;同时多线程是共享进程内存空间的,线程通信相比进程通信更简单。因此, TPC 实际上是解决或者弱化了 PPC fork 代价高的问题和父子进程通信复杂的问题。 Reactor与Proactor单服务器高性能的PPC和TPC模式，它们的优点是实现简单，缺点是都无法支撑高并发的场景。 Reactor PPC 模式最主要的问题就是每个连接都要创建进程(为了描述简洁,这里只以 PPC 和进程为例,实际上换成 TPC 和线程,原理是一样的),连接结束后进程就销毁了,这样做其实是很大的浪费。为了解决这个问题,一个自然而然的想法就是资源复用,即不再单独为每个连接创建进程,而是创建一个进程池,将连接分配给进程,一个进程可以处理多个连接的业务。引入资源池的处理方式后,会引出一个新的问题:进程如何才能高效地处理多个连接的业务?当一个连接一个进程时,进程可以采用 “read -&gt; 业务处理 -&gt; write” 的处理流程,如果当前连接没有数据可以读,则进程就阻塞在 read 操作上。这种阻塞的方式在一个连接一个进程的场景下没有问题,但如果一个进程处理多个连接,进程阻塞在某个连接的 read 操作上,此时即使其他连接有数据可读,进程也无法去处理,很显然这样是无法做到高性能的。解决这个问题的最简单的方式是将 read 操作改为非阻塞,然后进程不断地轮询多个连接。这种方式能够解决阻塞的问题,但解决的方式并不优雅。首先,轮询是要消耗 CPU 的;其次,如果一个进程处理几千上万的连接,则轮询的效率是很低的。为了能够更好地解决上述问题,很容易可以想到,只有当连接上有数据的时候进程才去处理,这就是 I/O 多路复用技术的来源。 I/O多路复用技术归纳起来有两个关键实现点： 当多条链接共用一个阻塞对象后，进程只需要在一个是阻塞对象上等待，而无序再轮询所连接，常见的实现方式有select、epoll、kqueue等。 当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。 I/O 多路复用结合线程池,完美地解决了 PPC 和 TPC 的问题,而且 “ 大神们 ” 给它取了一个很牛的名字: Reactor ,中文是 “ 反应堆 ” 。联想到 “ 核反应堆 ” ,听起来就很吓人,实际上这里的“反应”不是聚变、裂变反应的意思,而是“ 事件反应 ”的意思,可以通俗地理解为“ 来了一个事件我就有相应的反应 ”,这里的“我”就是Reactor,具体的反应就是我们写的代码, Reactor 会根据事件类型来调用相应的代码进行处理。 Reactor 模式也叫 Dispatcher 模式(在很多开源的系统里面会看到这个名称的类,其实就是实现 Reactor 模式的),更加贴近模式本身的含义,即 I/O 多路复用统一监听事件,收到事件后分配( Dispatch )给某个进程。Reactor 模式的核心组成部分包括 Reactor 和处理资源池(进程池或线程池),其中 Reactor 负责监听和分配事件,处理资源池负责处理事件。 Proactor Reactor 是非阻塞同步网络模型,因为真正的 read 和 send 操作都需要用户进程同步操作。这里的 “ 同步 ” 指用户进程在执行 read 和 send 这类 I/O 操作的时候是同步的,如果把 I/O 操作改为异步就能够进一步提升性能,这就是异步网络模型 Proactor 。Proactor 中文翻译为 “ 前摄器 ” 比较难理解,与其类似的单词是 proactive ,含义为 “ 主动的 ” ,因此我们照猫画虎翻译为 “ 主动器 ” 反而更好理解。 Reactor 可以理解为 “ 来了事件我通知你,你来处理”,而Proactor可以理解为“ 来了事件我来处理,处理完了我通知你 ”。这里的“我”就是操作系统内核,“事件”就是有新连接、有数据可读、有数据可写的这些I/O事件, “ 你 ” 就是我们的程序代码。 高性能负载均衡单服务器无论如何优化,无论采用多好的硬件,总会有一个性能天花板,当单服务器的性能无法满足业务需求时,就需要设计高性能集群来提升系统整体的处理性能。高性能集群的本质很简单,通过增加更多的服务器来提升系统整体的计算能力。由于计算本身存在一个特点:同样的输入数据和逻辑,无论在哪台服务器上执行,都应该得到相同的输出。因此高性能集群设计的复杂度主要体现在任务分配这部分,需要设计合理的任务分配策略,将计算任务分配到多台服务器上执行。高性能集群的复杂性主要体现在需要增加一个任务分配器,以及为任务选择一个合适的任务分配算法 。对于任务分配器,现在更流行的通用叫法是“负载均衡器”。但这个名称有一定的误导性,会让人潜意识里认为任务分配的目的是要保持各个计算单元的负载达到均衡状态。而实际上任务分配并不只是考虑计算单元的负载均衡,不同的任务分配算法目标是不一样的,有的基于负载考虑,有的基于性能(吞吐量、响应时间)考虑,有的基于业务考虑。考虑到 “ 负载均衡 ” 已经成为了事实上的标准术语,这里我也用 “ 负载均衡 ” 来代替 “ 任务分配 ” ,但请你时刻记住, 负载均衡不只是为了计算单元的负载达到均衡状态 。 分类及架构常见的负载均衡系统包括3种：DNS负载均衡、硬件负载均衡和软件负载均衡。 DNS负载均衡 DNS 是最简单也是最常见的负载均衡方式,一般用来实现地理级别的均衡。例如,北方的用户访问北京的机房,南方的用户访问深圳的机房。 DNS 负载均衡的本质是 DNS 解析同一个域名可以返回不同的 IP 地址。例如,同样是 www.baidu.com ,北方用户解析后获取的地址是 61.135.165.224 (这是北京机房的 IP ),南方用户解析后获取的地址是 14.215.177.38 (这是深圳机房的 IP )。 硬件负载均衡 硬件负载均衡是通过单独的硬件设备来实现负载均衡功能,这类设备和路由器、交换机类似,可以理解为一个用于负载均衡的基础网络设备。目前业界典型的硬件负载均衡设备有两款: F5 和 A10 。这类设备性能强劲、功能强大,但价格都不便宜,一般只有 “ 土豪 ” 公司才会考虑使用此类设备。普通业务量级的公司一是负担不起,二是业务量没那么大,用这些设备也是浪费。 软件负载均衡 软件负载均衡通过负载均衡软件来实现负载均衡功能,常见的有Nginx和LVS,其中Nginx是软件的7层负载均衡,LVS是Linux内核的4层负载均衡。4层和7层的区别就在于 协议 和 灵活性 ,Nginx支持HTTP、E-mail协议;而LVS是4层负载均衡,和协议无关,几乎所有应用都可以做,例如,聊天、数据库等。 算法负载均衡算法数量较多,而且可以根据一些业务特性进行定制开发,抛开细节上的差异,根据算法期望达到的目的,大体上可以分为下面几类。 任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理,这里的“平均”可以是绝对数量的平均,也可以是比例或者权重上的平均。 轮询 加权轮询 负载均衡类：负载均衡系统根据服务器的负载来进行分配,这里的负载并不一定是通常意义上我们说的“CPU负载”,而是系统当前的压力,可以用CPU负载来衡量,也可以用连接数、 I/O 使用率、网卡吞吐量等来衡量系统的压力。 负载最低优先 性能最优类：负载最低优先类算法是站在服务器的角度来进行分配的,而性能最优优先类算法则是站在客户端的角度来进行分配的,优先将任务分配给处理速度最快的服务器,通过这种方式达到最快响应客户端的目的。 Hash类：负载均衡系统根据任务中的某些关键信息进行 Hash 运算,将相同 Hash 值的请求分配到同一台服务器上,这样做的目的主要是为了满足特定的业务需求。 源地址Hash ID Hash 高可用架构模式高可用存储架构存储高可用方案的本质都是通过将数据复制到多个存储设备,通过数据冗余的方式来实现高可用,其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。 双机架构常见的高可用存储架构有主备、主从、主主、集群、分区,每一种又可以根据业务的需求进行一些特殊的定制化功能,由此衍生出更多的变种。 主备复制 主备复制是最常见也是最简单的一种存储高可用方案,几乎所有的存储系统都提供了主备复制的功能,例如 MySQL 、Redis 、 MongoDB 等。 主从复制 主从复制和主备复制只有一字之差, “ 从 ” 意思是 “ 随从、仆从 ” , “ 备 ” 的意思是备份。我们可以理解为仆从是要帮主人干活的,这里的干活就是承担 “ 读 ” 的操作。也就是说,主机负责读写操作,从机只负责读操作,不负责写操作。 双机切换 主备复制和主从复制方案存在两个共性的问题： 主机故障后，无法进行写操作 如果主机无法恢复，需要人工指定新的主机角色 双机切换就是为了解决这两个问题而产生的,包括主备切换和主从切换两种方案。简单来说,这两个方案就是在原有方案的基础上增加 “ 切换 ” 功能,即系统自动决定主机角色,并完成角色切换。 主主复制 主主复制指的是两台机器都是主机,互相将数据复制给对方,客户端可以任意挑选其中一台机器进行读写操作, 集群和分区数据集群 主备、主从、主主架构本质上都有一个隐含的假设:主机能够存储所有数据,但主机本身的存储和处理能力肯定是有极限的。 简单来说,集群就是多台机器组合在一起形成一个统一的系统,这里的 “ 多台 ” ,数量上至少是 3 台;相比而言,主备、主从都是 2 台机器。根据集群中机器承担的不同角色来划分,集群可以分为两类:数据集中集群、数据分散集群。 数据集中集群 数据集中集群与主备、主从这类架构相似,我们也可以称数据集中集群为 1 主多备或者 1 主多从。无论是 1 主 1 从、 1 主 1 备,还是 1 主多备、 1 主多从,数据都只能往主机中写,而读操作可以参考主备、主从架构进行灵活多变。 数据分散集群 数据分散集群指多个服务器组成一个集群,每台服务器都会负责存储一部分数据;同时,为了提升硬件利用率,每台服务器又会备份一部分数据。 数据分区 前面我们讨论的存储高可用架构都是基于硬件故障的场景去考虑和设计的,主要考虑当部分硬件可能损坏的情况下系统应该如何处理,但对于一些影响非常大的灾难或者事故来说,有可能所有的硬件全部故障。例如,新奥尔良水灾、美加大停电、洛杉矶大地震等这些极端灾害或者事故,可能会导致一个城市甚至一个地区的所有基础设施瘫痪,这种情况下基于硬件故障而设计的高可用架构不再适用,我们需要基于地理级别的故障来设计高可用架构,这就是数据分区架构产生的背景。 数据分区指将数据按照一定的规则进行分区,不同分区分布在不同的地理位置上,每个分区存储一部分数据,通过这种方式来规避地理级别的故障所造成的巨大影响。采用了数据分区的架构后,即使某个地区发生严重的自然灾害或者事故,受影响的也只是一部分数据,而不是全部数据都不可用;当故障恢复后,其他地区备份的数据也可以帮助故障地区快速恢复业务。 设计一个良好的数据分区架构，需要从多个方面去考虑。 数据量 分区规则 复制规则 业务高可用的保障：异地多活架构无论是高可用计算架构,还是高可用存储架构,其本质的设计目的都是为了解决部分服务器故障的场景下,如何保证系统能够继续提供服务。但在一些极端场景下,有可能所有服务器都出现故障。例如,典型的有机房断电、机房火灾、地震、水灾 …… 这些极端情况会导致某个系统所有服务器都故障,或者业务整体瘫痪,而且即使有其他地区的备份,把备份业务系统全部恢复到能够正常提供业务,花费的时间也比较长,可能是半小时,也可能是 12 小时。因为备份系统平时不对外提供服务,可能会存在很多隐藏的问题没有发现。如果业务期望达到即使在此类灾难性故障的情况下,业务也不受影响,或者在几分钟内就能够很快恢复,那么就需要设计异地多活架构。 应用场景 顾名思义,异地多活架构的关键点就是异地、多活,其中异地就是指地理位置上不同的地方,类似于 “ 不要把鸡蛋都放在同一篮子里 ” ;多活就是指不同地理位置上的系统都能够提供业务服务,这里的 “ 活 ” 是活动、活跃的意思。判断一个系统是否符合异地多活,需要满足两个标准: 正常情况下，用户无论访问哪一个地点的业务系统，都能够得到正确的业务服务。 某个地方业务异常的时候，用户访问其他地方正常的业务系统，能够得到正确的业务服务。 架构模式 同城异区 跨城异地 跨国异地 可扩展架构模式软件系统与硬件和建筑系统最大的差异在于软件是可扩展的,一个硬件生产出来后就不会再进行改变、一个建筑完工后也不会再改变其整体结构。例如,一颗 CPU 生产出来后装到一台 PC 机上,不会再返回工厂进行加工以增加新的功能;金字塔矗立千年历经风吹雨打,但其现在的结构和当时建成完工时的结构并无两样。相比之下,软件系统就完全相反,如果一个软件系统开发出来后,再也没有任何更新和调整,反而说明了这套软件系统没有发展、没有生命力。真正有生命力的软件系统,都是在不断迭代和发展的,典型的如 Windows 操作系统,从 Windows 3.0 到 Windows 95 到 Windows XP ,直到现在的 Windows 10 ,一直在跟着技术的发展而不断地发展。 可扩展架构的基本思想和模式可扩展的基本思想 可扩展性架构的设计方法很多，但万变不离其宗，所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆 拆，就是将原来大一统的系统拆分成多个规模小的部分，扩展时只修改其中一个部分即可，无须整个系统到处都改，通过这种方式来减少改动范围，降低改动风险。 按照不同的思路来拆分软件系统，就会得到不同的架构。常见的拆分思路有如下三种： 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分 理解这三种思路的关键就在于如何理解“流程”、“服务”、“功能”三者的联系和区别。从范围上来看，从大到小依次为：流程&gt;服务&gt;功能。 不同的拆分方式，本质上决定了系统的扩展方式。不同的拆分方式，将得到不同的系统架构，典型的可扩展系统架构有： 面向流程拆分：分层架构 面向服务拆分：SOA、微服务 面向功能拆分：微内核架构 传统的可扩展架构模式：分层架构和SOA分层架构 分层架构是很常见的架构模式，也加N层架构，通常情况下，N至少是2层。例如，C/S架构、B/S脚骨。常见的是3层架构（例如，MVC、MVP架构），4层架构，5层脚骨的比较少见，一般是比较复杂的系统才会达到或者超过5层，比如操作系统内核架构。 按照分层架构进行设计时，根据不同的划分维度和对象，可以得到多种不同的分层架构。 C/S架构、B/S架构 划分的对象是整个业务系统,划分的维度是用户交互,即将和用户交互的部分独立为一层,支撑用户交互的后台作为另外一层 MVC架构、MVP架构 划分的对象是单个业务子系统,划分的维度是职责,将不同的职责划分到独立层,但各层的依赖关系比较灵活。 逻辑分层架构 划分的对象可以是单个业务子系统,也可以是整个业务系统,划分的维度也是职责。虽然都是基于职责划分,但逻辑分层架构和 MVC 架构、 MVP 架构的不同点在于,逻辑分层架构中的层是自定向下依赖的。典型的有操作系统内核架构、TCP/IP架构。 无论采取何种分层维度，分层架构设计最核心的一点就是需要保证各层之间的差异足够清晰，边界足够明显，让人看到架构图后就能看懂整个架构，这也是分层不能太多的原因。 分层架构之所以能够较好地支撑系统扩展，本质在于隔离关注点，即每个层中的组件只会处理本层的逻辑。但是，分层时要保证层与层之间的依赖是稳定的，才能真正支撑快速扩展。 分层结构的另外一个特点就是层层传递，也就是说一旦分层确定，整个业务流程是按照层进行依次传递的，不能 在层之间进行跳跃。这种约束的好处在于强制将分层依赖限定为两两依赖，降低了整体系统复杂度，但代价就是冗余，也就是说，不管这个业务多么简单，每层都必须要参与处理。langfei 分层架构另外一个典型的缺点就是性能，因为每一次l业务请求都需要穿越所有的架构分层，有一些事情是多余的，多少都会有一些性能的浪费。 SOA SOA的全称是 Service Oriented Architecture，中文翻译为“面向服务的架构”。 SOA提出了3个关键概念 服务 所有业务功能都是一项服务，服务就意味着要对外提供开放的能力，当其他系统需要使用这项功能时，无须定制化开发。 ESB ESB的全称是 Enterprise Service Bus，中文翻译为“企业服务总线”。从名字就可以看出，ESB参考了计算机总线的概念。ESB将企业中各个不同的服务连接在一起。 松耦合 松耦合的目的是减少各个服务间的依赖和互相影响。 微服务架构微服务是一种和SOA相似但本质上不同架构理念。 对比维度 SOA 微服务 服务粒度 粗 细 服务通信 重量级，ESB 轻量级，例如，HTTP RESTful RPC 服务交付 慢 快 应用场景 企业级 互联网 Martin Fowle在他的微服务文章中，做了很好地提炼 In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. 微服务的陷阱 服务划分过膝，服务间关系复杂 服务数量太多，团队效率急剧下降 调用链太长，性能下降 调用链太长，问题定位困难 没有自动化支撑，无法快速交付 没有服务治理，微服务数量多了后台管理混乱 微内核架构微内核脚骨（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构，通常用于实现基于产品的应用。例如Eclipse这类IDE软件、UNIX这类操作系统、淘宝APP这类客户端软件。 基本架构 微内核架构包含两类组件：核心系统（core system）和插件模块（plug-in modules）。核心系统负责和具体业务功能无关的通用功能，例如模块加载、模块间通信等；插件模块负责实现具体的业务逻辑。 微内核的基本架构示意图如下：]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
</search>
