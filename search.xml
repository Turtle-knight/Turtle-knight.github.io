<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flask学习笔记]]></title>
    <url>%2F2019%2F04%2F11%2FFlask_Web%2F</url>
    <content type="text"><![CDATA[FlaskFlask是使用Python编写的Web微框架，Web框架可以让开发者不用关心底层的请求响应处理，更方便更高效地编写Web程序。Flask有两个主要依赖，一个是WSGI（Web Server Gateway Interface，Web服务器网关接口）工具集——Werkzeug，另一个是Jinja2模板引擎。 搭建开发环境 安装pip和pipenv 1$ pip install pipenv 创建虚拟环境 在Python中虚拟环境（virtual environment）就是隔离的Python解释器环境。通过创建虚拟环境，你可以拥有一个独立的Python解释器环境。这样做的好处是可以为每一个项目创建独立的Python解释器环境，因为不同的项目常常会话依赖不同版本的库或Python版本。使用虚拟环境可以保持全局Python解释器环境的干净，避免包和版本的混乱，并且可以方便地区分和记录每个项目的依赖，以便在新环境下复现依赖环境。 123$ pipenv install # 为当前目录的项目创建虚拟环境$ pipenv shell # 显式激活虚拟环境 安装Flask 1$ pipenv install flask # 在虚拟环境中安装Flask 注册路由在一个Web应用里，客户端和服务器上的Flask程序的交互可以简单概括为以下几步： 1）用户在浏览器中输入URL访问某个资源 2）Flask接收用户请求并分析请求的URL 3）为这个URL找到对应的处理函数 4）执行函数并生成响应，返回给浏览器 5）浏览器接收并解析响应，将信息显示在页面中 在以上步骤中，大部分都由Flask完成，开发者要做的只是建立处理请求的函数，并定义对应的URL规则。只需为函数附加app.route()装饰器，并传入URL规则作为参数，就可以让URL与函数建立联系。这个过程称为注册路由（route），路由负责管理URL和函数之间的映射，而这个函数则被称为视图函数（view function）。 例如： 123@app.route('/')def index(): return '&lt;h1&gt;Hello, World&lt;/h1&gt;' 在这个程序里，app.route()装饰器把根地址/和index()函数绑定起来，当用户访问这个URL时就会触发index()函数。这个视图函数可以像其他普通函数一样执行任意操作，最后，视图函数返回的值作为响应的主体。 为视图绑定多个URL 一个视图函数可以绑定多个URL。 例： 1234@app.route('/hi')@app.route('/hello')def say_hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt;' 动态URL 123@app.route('/greet/&lt;name&gt;')def greet(name): return '&lt;h1&gt;Hello, %s!&lt;/h1&gt;' % name 启动开发服务器1$ flask run flask run命令启动内置的开发服务器。 自动发现程序实例 一般来说，在执行flask run命令运行程序前，需要提供程序实例所在模块的位置。若无提供，Flask会自动探测程序实例，自动探测存在以下规则： 从当前目录寻找app.py和wsgi.py模块，并从中寻找名为app或application的程序实例。 从环境变量FLASK_APP对应的值寻找名为app或application的程序实例。 管理环境变量 Flask的自动发现程序实例机制还有第三条规则：如果安装了python-dotenv，那么在使用flask run或其他命令时会使用它自动从.flaskenv文件和.env文件中加载环境变量。 为了避免频繁设置环境变量，可以使用python-dotenv管理项目的环境变量。 1$ pipenv install python-dotenv .flaskenv文件用来存储和Flask相关的公开环境变量，比如FLASK_APP; .env文件用来存储包含敏感信息的环境变量，比如账户名和密码。 环境变量以键值对的形式定义。 Flask与HTTP请求响应循环 HTTP请求Request对象这个请求对象封装了从客户端发来的请求报文，能从它获取请求报文中的所有数据。 在Flask中处理请求 设置监听的HTTP方法 123@app.route('/hello', method=['GET', 'POST'])def hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt; 请求钩子有时需要对请求进行预处理（preprocessing）和后处理（postprocessing）。这时可以使用Flask提供的一些请求钩子（Hook），它们可以用来注册在请求处理的不同阶段执行的处理函数。这些请求钩子用装饰器实现，通过程序实例app调用。 ​ 请求钩子 钩子 说明 before_first_request 注册一个函数，在处理第一个请求前运行 before_request 注册一个函数，在处理每个请求前运行 after_request 注册一个函数，如果没有未处理的异常抛出，会在每个请求结束后运行 teardown_request 注册一个函数，即使有未处理的异常抛出，会在每个请求结束后运行 after_this_request 在视图函数内注册一个函数，会在这个请求结束后运行 HTTP响应响应格式在HTTP响应中，数据可以通过多种格式传输。大多数情况下，我们会使用HTML格式，这是Flask中的默认设置。在特定的情况下，也会使用其他格式。不同的响应数据格式需要设置不同的MIME类型。 纯文本 MIME类型： text/plain HTML MIME类型：text/html XML MIME类型：application/xml JSON MIME类型：application/json CookieHTTP是无状态协议。在一次响应结束后，服务器不会留下任何关于对方状态的信息。 Cookie是Web服务器为了存储某些数据（比如用户信息）而保存在浏览器上的小型数据。浏览器会在一定时间内保存它，并在下一次向同一个服务器发送请求时附带这些数据。Cookie通常被用来进行用户会话管理（比如登录状态），保存用户的个性化信息以及记录和收集用户浏览数据以用来分析用户行为等。 在Flask中，想要在响应中添加一个cookie，最方便的方法是使用Response类提供的set_cookie() 方法。 1234567from flask import Flask, make_response...@app.route('/set/&lt;name&gt;')def set_cookie(name): response = make_response(redirect(url_for('hello'))) response.set_cookie('name', name) return response Session：安全的Cookie在编程中，session指用户会话，又称为对话，即服务器和客户端/浏览器之间或桌面程序和用户之间建立的交互活动。而在Flask中，session对象用来加密Cookie。默认情况下，它会把数据存储在浏览器上一个名为session的cookie里。 session通过密钥对数据进行签名以加密数据。因此，得先社会一个密钥。 1234567# 程序的密钥可以通过Flask.secret_key属性或配置变量SECRET_KEY设置app.secret_key = 'secret string'# 更安全的做法是把密钥写进系统环境变量或是保存在.env文件中SECRET_KEY = secret string# 然后在陈旭脚本中使用os模块提供的getenv()方法获取app.secret_key = os.getenv('SECRET_KEY', ‘secret string') HTTP进阶重定向回上一个页面要重定向回上一个页面，最关键的是获取上一个页面的URL。上一个页面的URL一般可以通过两种方法获取。 HTTP referer HTTP referer是一个用来记录请求发源地的HTTP首部字段，即访问来源。当用户在某个站点单击链接，浏览器向新链接所在的服务器发起请求，请求的数据中包含的HTTP_REFERER字段记录了用户所在的原站点URL。 1return redirect(request.referrer) 查询参数 在URL中手动加入包含当前URL的查询参数，这个查询参数一般命名为next。 12345@app.route('/foo')def foo(): return '&lt;h1&gt;Foo page&lt;/h1&gt;&lt;a href="%s"&gt;Do somthing and redirect&lt;/a&gt;' % url_for('do something', next=request.full_path) return redirect(request.args.get('next')) Ajax技术发送异步请求AJAX指异步JavaScript和XML，它不是编程语言或通信协议，而是一系列技术的组合体。简单来说，Ajax基于XMLHttpRequest让我们可以在不重载页面的情况下和服务器进行数据交换。加上JavaScript和DOM，就可以在接收到数据后局部更新页面。 使用JQuery发送Ajax请求 jQuery是流行的JavaScript库，它包装了JavaScript，让我们可以通过更简单的方式编写JavaScript代码。对于Ajax，它提供了多个相关的方法，使用它可以很方便的实现Ajax操作。更重要的是，jQuery处理了不同浏览器的Ajax兼容问题，只需要编写一套代码，就可以在所有主流的浏览器正常运行。 JQuery中和Ajax相关的方法及具体用法访问http://api.jquery.com/category/ajax/ 模板在动态Web程序中，视图函数返回的HTML数据往往需要根据相应的变量（比如查询函数）动态生成。当HTML代码保存到单独的文件中时，没法再使用字符串格式化或拼接字符串的方式来在HTML代码中插入变量，这时，需要使用模板引擎（template engine），借助模板引擎，可以在HTML文件中使用特殊的语法来标记处变量，这类包含固定内容和动态部分的可重用文件称为模板（template）。 模板引擎的作用就是读取并执行模板中的特殊语法标记，并根据传入的数据将变量替换为实际值，输出最终的HTML页面，这个过程被称为渲染（rendering）。 模板基本用法（1）语句 比如 if 判断、for 循环等： {/% for %/}注：因为hexo缘故，实际使用不需要斜杠。 （2）表达式 比如字符串、变量、函数调用等 {/{ xxx.xx }/}注：因为hexo缘故，实际使用不需要斜杠。 （3）注释 {/# xxx #/}注：因为hexo缘故，实际使用不需要斜杠。 模板语法渲染模板在视图函数中，不直接使用Jinja2提供的函数，而是使用Flask提供的渲染函数render_template()。 123@app.route('/example')def example_for_render(): return render_templae('example.html', arg1=xxx, arg2=yyy) 在render_template() 函数中，首先传入模板的文件名作为参数，以关键字参数的形式传入模板中使用的变量值。其他类型的变量通过相同的方式传入。传入Jinja2中的变量值可以使字符串、列表、和字典，也可以是函数、类和类实例。 模板辅助工具上下文 内置上下文变量 Flask在模板上下文中提供了一些内置变两个，可以在模板中直接使用 ​ 标准模板全局变量 变量 说明 config 当前的配置对象 request 当前的请求对象，在已激活的请求环境下可用 session 当前的会话对象，在已激活的请求环境下可用 g 与请求绑定的全局变量，在已激活的请求环境下可用 自定义上下文 如果多个模板都需要使用同一变量，那么较好的方法是能够设置一个模板全局变量。Flask提供了一个app.context_processor()装饰器，可以用来注册模板上下文处理函数，它可以完成统一传入变量的工作。 1234567@app.context_processo()def inject_foo(): foo = 'I am foo.' return dict(foo=foo) # 等同于return &#123;'foo': foo&#125;# 直接将app.context_processor作为方法调用app.context_processor(inject_foo) 当调用render_template()函数渲染任意一个模板时，所有使用app.context_processor装饰器注册的模板上下文处理函数（包括Flask内置的上下文处理函数）都会被执行，这些函数的返回值会被添加到模板中，因此可以在模板中直接使用变量。 全局对象全局对象是指在所有的模板中都可以直接使用的对象，包括在模板中导入的模板。 内置全局函数 ​ Jinja2内置模板全局函数(部分) | 函数 | 说明 || ————————————– | ————————— || range([start,]stop[, step]) | 和python中的range()用法相同 || lipsum(n=5, html=True, min=20,max=100) | 生成随机文本（lorem ipsum） || dict(**items) | 和python中的dict()用法相同 | ​ Flask内置模板全局函数 | 函数 | 说明 || ———————- | ———————– || url_for() | 用于生成URL的函数 || get_flashed_message(0) | 用于获取flash消息的函数 | 自定义全局函数 使用app.template_global()装饰器直接将函数注册为模板全局函数 123@app.template_global()def bar(): return 'I am bar' 过滤器在Jinja2中，过滤器（filter）是一些可以用来修改和过滤变量值的特殊函数，过滤器和变量用一个竖线（管道符号）隔开，需要参数的过滤器可以像函数一样使用括号传递。 例如： 内置过滤器 Jinja2提过了许多内置过滤器，访问http://jinjia.pocoo.org/docs/2.10/template/#builtin-filters 自定义过滤器 使用app.template_filter()装饰器可以自定义过滤器 12345from flask import Markup@app.template_filter()def miscal(s): return s + Markup(' &amp;#9835;') 测试器在Jinja中，测试器（Test）是一些用来测试变量或表达式，返回值（True或False）的特殊函数。比如，number测试器用来判断一个变量或变大时是否数字。使用 is 连接变量和测试器 12345&#123;% if age is number %&#125; &#123;&#123; age * 365&#125;&#125;&#123;% else %&#125; 无效数字&#123;% endif %&#125; 内置测试器 Jinja2提供了许多内置测试器，访问http://jinjia.pocoo.org/docs/2.10/template/#list-of-builtin-tests 自定义测试器 使用app.template_test()装饰器自定义测试器 12345@app.template_test()def baz(n): if n == 'baz': return True return False 模板环境对象在jinja2中，渲染行为有jinja2.Environment类控制，所有的配置选项，上下文变量、全局函数、过滤器和测试器都存储在Environment实例上。当与Flask结合后，我们并不单独创建Environment对象，而是使用Flask创建的Environment对象，它存储在app.jinja_env属性上。 在程序中，可以使用app.jinja_env更改Jinja2设置。 模板环境中的全局函数、过滤器和测试器分别存储在Environment对象的globals、filters和tests属性中，这三个属性都是字典对象。可以直接操作这三个字典来添加相应的函数或变量。 添加自定义全局对象 123456def bar(): return 'I am bar'foo = 'I am foo'app.jinja_env.globals['bar'] = barapp.jinja_env.globals['foo'] = foo 添加自定义过滤器 1234def smiling(s): return s + ':)' app.jinja_env.filters['smiling'] = smiling 添加自定义测试器 123456def baz(n): if n == 'baz': return True return False app.jinja_env.tests['baz'] = baz 模板结构组织 局部模板 当多个独立模板总都会使用同一块HTML代码时，可以把这部分代码抽离出来，存储到局部模板中。这样一方面可以避免重复，另一方面也可以方便统一管理。 1&#123;% include &apos;xxx.html&apos; %&#125; 模板继承 Jinja2的模板继承允许定义一个基模板，把网页上的导航栏、页脚等通用内容放在基模板中，而每一个继承基模板的子模板在被渲染时都会自动包含这些部分。 为了能够让子模板方便地覆盖或插入内容到基模板中，需要在基模板中定义块(block)，在子模板中可以通过定义同名的块来执行继承操作。 模板进阶加载静态文件一个Web项目不仅需要HTML模板，还需要虚度静态文件，比如CSS、JavaScript文件、图片及音频等。在Flask程序中，默认需要将静态文件存储在与主脚本（包含程序实例的脚本）同级目录的static文件夹中。 为了在HTML文件中引用静态文件，需要使用url_for() 函数获取静态URL。Flask内置了用于获取静态文件的试图函数，端点值为static， 默认URL规则为 static/path:filename，URL变量filename是相对于static文件夹根目录的文件路径。 例如： 123&lt;img src="&#123;&#123; url_for('static', filename='xxx.jpg') &#125;&#125;" &gt;&lt;link rel="stylesheet" type="text/css" href="&#123;&#123; url_for('static', filename='styles.css') &#125;&#125;" &gt; 使用CSS框架在编写Web程序时，手动编写CSS比较麻烦，常见的做法是使用CSS框架来为程序添加样式。CSS框架内置了大量可以直接使用的CSS样式类和JavaScript函数，使用它们可以非常快速地让程序页面变得美观和易用，同时也可以定义自己的CSS文件来进行补充和调整。 12345678&#123;% block sysles %&#125; &lt;link ref="stylesheet" href="&#123;&#123; url_for('static', filename='css/bootstrap.min.css') &#125;&#125;" &gt;&#123;% endblock %&#125;...&#123;% block script %&#125; &lt;script scr="&#123;&#123; url_for('static', filename='js/jquery.min.js') &#125;&#125;"&gt;&lt;/script&gt; &lt;script src="&#123;&#123; url_fro('static', filename='js/popper.min.js') &#125;&#125;"&gt;&lt;/script&gt;&#123;% endblock %&#125; 消息闪现Flask提供了一个非常有用的flash() 函数，它可以用来“闪现”需要显示给用户的消息。在视图函数中调用flash()函数，传入消息内容即可“闪现”一条消息。发送的消息会存储在session中，需要在模板中使用全局函数get_flashed_messages() 获取消息并将其显示出来。 123456from flask import flash@app.route('/') def just_flash(): flash('I am flash, who is looking for me.') return redirect(url_for('index')) 表单HTML表单HTML表单的具体定义和用法访问http://www.w3.org/TR/html401/interact/forms.html 使用Flask-WTF处理表单在模板中渲染表单提交表单出于安全考虑，一般使用POST方法提交表单。使用POST方法时，按照默认的编码类型，表单数据会被存储在请求主体中。 为了支持接收表单提交发送的POST请求，必须在app.route()装饰器里使用methods关键字为路由指定HTTP方法。 1234@app.route('/', methods=['GET', 'POST'])def basic(): form = LoginForm() return render_template('basic.html', form=form) 验证表单数据 客户端验证和服务器端验证 客户端验证 指在客户端（比如Web浏览器）对用户的输入值进行验证。客户端方式可以实时动态提示用户输入是否正确，只有用户输入正确后才会将表单数据发送到服务器。客户端验证可以增强用户体验，降低服务器负载。 服务器端验证 指用户把输入的数据提交到服务器，在服务器端对数据进行验证。如果验证出错，就在返回的响应中加入错误信息。 客户端验证和服务器端验证都是必不可少的。 WTForms验证机制 WTForms验证表单字段的方式是在实例化表单类时传去表单数据，然后对表单实例调用validate() 方法。 表单进阶自定义验证器在WTForms中，验证器是指在定义字段时传入validators参数列表的可调用对象。 行内验证器 12345678910from wtforms import IntegerField, SubmitFieldfrom wtforms.validators import ValidationErrorclass FortyTwoForm(FlaskForm): answer = IntegerField('The Number') submit = SubmitField() def validate_answer(form, field): # 验证器在表单类中定义 if field.data != 42: raise ValidationError('Must be 42') 当表单类总包含以“validate_字段属性名“形式命名的方法时，在验证字段数据时会同时调用这个方法来验证对应的字段，这也是为什么表单类的字段属性名不能以validate开头。 全局验证器 123456789from wtforms.validators import ValidationErrordef is_42(form, field): # 验证器在表单类外定义 if filed.data != 42: raise ValidationError('Must be 42') class FortyTwoForm(FlaskForm): answer = IntegerField('The Number', validators=[is_42]) submit = SubmitField() 文件上传在HTML中，渲染一个文件上传字段只需要将标签的type属性设为file，即。这会在浏览器中渲染陈一个文件上传字段，单机文件选择按钮会打开文件选择窗口，选择对应的文件后，被选择的文件名会显示在文件选择按钮旁边。 定义上传表单 在Python表单类中创建文件上传字段时，使用扩展Flask-WTF提供的FileField类，它继承了WTForm提供的上传字段FileField，添加了对Flask的集成。 例： 1234from flask wtf.file import FileField, FileRequired, FileAllowedclass UploadForm(FlaskForm): photo = FileField('Upload Image', validators=[FileRequired(), FileAllowed(['jpg', 'jpeg', 'png', 'gif'])]) submit = SubmitField() 渲染上传表单 在创建的upload视图里，实例化表单类UploadForm，然后传入模板： 12345@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() ... return render_template('upload.html, form=form) 12345&lt;form method="post" enctype="multipart/form-data"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.photo) &#125;&#125; &#123;&#123; form.submit() &#125;&#125;&lt;/form&gt; 处理上传文件 和普通的表单数据不同，当包含上传文件字段的表单提交后，上传的文件需要在请求对象的files属性（reuqest.files）中获取。 当使用Flask-WTF时，它会自动帮我们获取对应的文件对象。这里使用表单类属性的data属性获取上传文件。 123456789101112131415import osapp.config['UPLOAD_PATH'] = os.path.join(app.root_path, 'uploads')@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() if form.validate_on_submit(): f = form.photo.data filename = random_filename(f.filename) f.save(os.path.join(app.config['UPLOAD)PATH'], filename)) flash('Upload success.') session['filenames'] = [filename] return redirect(url_for('show_images')) return render_template('upload.html', form=form) 使用Flask-CKEditor集成富文本编辑器1$ pipenv install flask-ckeditor # 安装 1）实例化Flask-CkEditor提供的CkEditor类，传入程序实例 123from flask_ckeditor import CKEditorckeditor = CKEditor() 2）渲染富文本编辑器 123456789from flask_wtf import FlaskFormFrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequired, Lengthfrom flask_ckeditor import CKEditorFieldclass RichTextForm(FlaskForm): title = StringField('Title', validators=[DataRequired(), Length[1. 50]]) body = CKEditorField('Body', validators=[DataRequeired()]) submit= SubmitField('Publish') 123456789&#123;% block content %&#125;&lt;h1&gt;Integrate CKEditor with Flask-CKEditor&lt;/h1&gt;&lt;form method="post"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.title) &#125;&#125; &#123;&#123; form_field(form.body) &#125;&#125; &#123;&#123; form.submit &#125;&#125;&lt;/form&gt;&#123;% endblock %&#125; 单个表单多个提交按钮1234567891011121314class NewPostForm(FlaskForm): title = String('Title') ... save = SubmitField('Save') publish = SubmitField('Publish') @app.route('/xxx', methods=['GET', 'POST'])def two_submits(): form = NewPostForm() if form.validate_on_submit(): if form.save.data: .... elif form.publish.data: .... 数据库电子邮件Flask程序的自动化测试Flask程序性能优化部署FLask程序Flask的一些设计理念后续补充]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Web开发</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量PATH]]></title>
    <url>%2F2019%2F02%2F25%2FLinux_%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8FPATH%2F</url>
    <content type="text"><![CDATA[环境变量$PATH在Linux中，执行命令时，系统会按照PATH的设置，去每个PATH定义的路径下搜索执行文件，先搜索到的文件先执行。（From：《鸟哥的LINUX私房菜》） 改变PATH直接修改$PATH值：12echo $PATH //查看当前PATH的配置路径export PATH=$PATH:/xxx1:/xxx2 //将需要的配置路径加入$PATH 等号两边没有空格，path之间用':'间隔 生效方法：立即生效 有效期限：临时改变，只对当前终端有效，关闭后恢复原来的PATH 用户局限：仅当前用户 通过修改.bashrc文件：（.bashrc文件在根目录下）12345vim .bashrc // 编辑.bashrc文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx // /xxx/xxx为需要加入的环境变量地址，等号两边无空格 生效方法：（有一下两种） 关闭当前终端窗口，重新打开一个新的终端窗口即可 输入 1source .bashrc 命令，立即生效。 有效期限：永久有效 用户局限：仅当前用户 通过修改profile文件：（profile文件在/etc目录下）12345vim /etc/profile // 编辑profile文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户 通过修改environment文件：（environment文件在/etc目录下）123vim /etc/environment //编辑environment文件在PATH=/.......中加入“:/xxx/xxx” 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu环境]]></title>
    <url>%2F2019%2F02%2F25%2FUbuntu%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Ubuntu工作环境快速配置首先更新一下 1sudo apt update &amp;&amp; sudo apt upgrade 更换软件源详情https://blog.csdn.net/JRRRJ/article/details/81082444 将阿里源添加到sources.list中 1deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 保存退出，然后更新。 安装显卡驱动在「软件和更新」-「附加驱动」选项卡中进行选择 基础软件安装VIM1sudo apt install vim vim 个人配置.vimrc (保存在个人百度网盘快速配置Ubuntu环境文件夹) 搜狗输入法https://blog.csdn.net/fx_yzjy101/article/details/80243710 Git1sudo apt install git PyCharmhttps://blog.csdn.net/qq_15192373/article/details/81091278 ipython1sudo apt install ipython3 flask安装详情见flask官网 Typora(Markdown编辑)安装详情见Typora官网 Shutter(截图软件)详情见https://blog.csdn.net/qq_19339041/article/details/80058892 WPS先卸载LibreOffice 1sudo apt-get remove --purge libreoffice* 下载安装访问WPS官网 MySQL &amp;&amp; Redis12sudo apt install mysql-serversudo apt install redis-server WechatUbuntu 18.04 安装微信（Linux通用）]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发问题整理]]></title>
    <url>%2F2019%2F02%2F25%2Fdjango_web_%E5%BC%80%E5%8F%91%E9%94%99%E8%AF%AF%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[在使用Django2.0进行Web开发过程中遇到的问题Django在根据models生成数据库表时报 _ init _()missing 1 required positional argument: ‘on_delete’ 原因 在django2.0后，定义外键和一对一关系的时候需要加on_delete选项，此参数为了避免两个表里的数据不一致问题，不然会报错：TypeError: _ init _() missing 1 required positional argument: ‘on_delete’ 解决方法 1234567# 以下代码报错user = models.OneToOneField(User)owner = models.ForeignKey(UserProfile)# 以下代码正确user = models.OneToOneField(User, on_delete=models.CASCADE)owner = models.ForergnKey(UserProfile, on_delete=models.CASCADE) 参数说明 on_delete有CASCADE、PROTECT、SET_NULL、SET_DEFAULT、SET()五个可选择的值。CASCADE：此值设置，是级联删除。PROTECT：此值设置，是会报完整性错误。SET_NULL：此值设置，会把外键设置为null，前提是允许为null。SET_DEFAULT：此值设置，会把设置为外键的默认值。SET()：此值设置，会调用外面的值，可以是一个函数。一般情况下使用CASCADE就可以了。 Django2.0配置Mysql数据库后执行数据迁移时报错： 报错 1django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11.None 原因 MySQLclient目前只支持到python3.4 解决方法 因为要使用python3.6，所以修改下面路径的文件： 1$ vim /home/utur/.local/lib/python3.6/site-packages/django/db/backends/mysql 将以下代码注释即可： 12if version &lt; (1, 3, 3): raise ImproperlyConfigured("mysqlclient 1.3.3 or newer is required; you have %s" % Database.__version__) MySQL: django.db.utils.OperationalError:( 1698, “Access denied for user ‘roo‘@’localhost’”) with correct username and pw 详情见：https://stackoverflow.com/questions/41542045/mysql-django-db-utils-operationalerror-1698-access-denied-for-user-root 解决方法 123create user &apos;django&apos;@&apos;localhost&apos; identified by &apos;django-user-password&apos;;grant usage on *.* to &apos;django&apos;@&apos;localhost&apos;;grant all privileges on django-database-1.* to &apos;django&apos;@&apos;localhost&apos;; AttributeError: ‘str’ object has no attribute ‘decode’ 报错 执行 1python3 manage.py makemigrations 报错 123 File "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/Django-2.2-py3.7.egg/django/db/backends/mysql/operations.py", line 146, in last_executed_query query = query.decode(errors='replace')AttributeError: 'str' object has no attribute 'decode' 原因 python在bytes和str两种类型转换，所需要的函数依次是encode(),decode() 解决方法 在报错路径下 1vim operations.py 找到错误代码 1query = query.decode(errors='replace') 修改为 12query = query.encode(errors='replace')# 保存并退出 include() got an unexpected keyword argument ‘app_name’ 原因 在Django2.0版本使用url()导致，推荐使用path() 解决方法 在xxx应用下的urls.py添加app_name变量 12345678910from django.contrib import adminfrom django.conf.urls import url,includeapp_name = xxxurlpatterns = [ # 路由规则 ...]]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列Kafka学习笔记]]></title>
    <url>%2F2019%2F02%2F25%2FApache_Kafka%2F</url>
    <content type="text"><![CDATA[Kafka简介Kafka是一款由美国领英公司（LinkedIn）开源出来的高性能消息引擎系统（Messaging system）,其核心功能是——高性能的消息发送与高性能的消息消费。但随着Kafka的不断演进，在Kafka 0.10.0.0版本正式推出了Kafka Streams，即流式处理组件。自此Kafka正式成为了一个流式处理框架。 前置知识背景消息引擎系统消息引擎，又叫消息队列，消息中间件等。 根据维基百科的定义，企业消息引擎系统（EMS）是企业发布的一组规范。公司使用这组规范实现在不同系统之间传递语义准确的消息。在实际使用场景中，消息引擎系统通常以软件接口为主要形式，实现了松耦合的异步式数据传递语义。 消息引擎范型根据维基百科定义，一个消息引擎范型是一个基于网络的架构范型，描述了消息引擎系统的两个不同的子部分是如何互连且交互的。如果把消息引擎系统的这两个子系统比喻成两座城市，那么传输协议就是需要铺设的沥青公路，而引擎范型决定了来往穿梭与这两座城市的路线。 最常见的两种消息引擎范型是消息队列模型和发布/订阅模型。 消息队列（message queue）模型是基于队列提供消息传输服务的，多用于进程间通信以及线程间通信。该模型定义了消息队列、发送者和接收者，提供了一种点对点的消息传递方式，即发送者发送每条消息到队列的指定位置，接收者从指定位置获取消息。每条消息由一个发送者生产出来，且只被一个消费者处理。 发布/订阅模型(publish/subscribe),它有主题（topic）的概念：一个topic可以理解为逻辑语义相近的消息的容器。这种模型定义了类似于生产者/消费者这样的角色，即发布者和订阅者。发布者将消息生产出来发送到指定的topic中，所有订阅了该topic的订阅者都可以接收到该topic下的所有消息。 Kafka术语消息既然Kafka的核心功能就是消息引擎，那么对消息的设计日然是首当其冲的事情。Kafka在消息设计时特意避开了繁重的Java堆上内存分配，直接使用紧凑二进制字节数组ByteBuffer而不是独立的对象，因此至少能够访问多一倍的可用内存。 省去padding，java对对象保存的大开销以及可能的页缓存。 topic和partiiton从概念上来说，topic只是一个逻辑概念，代表了一类消息，也可以认为是消息被发送到的地方。通常可以使用topic来区分实际业务，比如业务A使用一个topic，业务B使用另一个topic。 Kafka中的topic通常都会被多个消费者订阅，出于性能的考量，Kafka并不是topic-message的两级结构，而是采取了topic-partition-message的三级结构来分散负载。从本质上来说，每个Kafka topic都由若干个partition组成。 topic是由多个partition组成的，而Kafka的partition是不可修改的有序消息队列，也可以说是有序的消息日志。每个partition都有自己专属的partition号。用户对partition唯一能做的操作就是在消息序列的尾部追加写入消息。partition上的每条消息都会被分配一个唯一的序列号-该序列号被称为位移（offset）。位移信息可以唯一定位到某partition下的一条消息 offset实际上，Kafka消费者也有位移（offset）的概念，但这两个offset属于不同的概念。 每条消息在某个partition的位移是固定的，但消费该partition的消费者的位移会随着消费进度不断前移，但不能超过该分区最新一条消息的位移。 从本质上看，Kafka中的一条消息其实就是一个&lt;topic,partition,offset&gt;三元组（tuple），通过该元组，可以在Kafka集群中找到位移对应的那条消息。 replica为了实现高可靠性，通过冗余机制——备份多份日志。这些备份日志在Kafka中被称为副本（replica），它们存在的唯一目的就是防止数据丢失。 副本分为两类：领导者副本（leader replica）和追随者副本（follower replica）。follower replica是不能提供服务给客户端的，它只是被动地向领导者副本（leader replica）获取数据，一旦leader replica所在的broker宕机，Kafka会从剩余的replica中选举出新的leader继续提供服务。 ISRISR的全称是 in-sync replica，就是与leader replica保持同步的replica集合。 Kafka为partition动态维护一个replica集合。该集合中的所有replica保存的消息日志都与leader replica保护同步状态。只有这个集合中的replica才能被选举为leader，也只有该集合中所有replica都接收到了同一条消息，Kafka才会将该消息置于“已提交”状态，即认为这条消息发送成功。Kafka承诺只要这个集合中至少存在一个replica，那些”已提交“状态的消息就不会丢失。 Kafka使用场景 消息传输 网站行为日志追踪 审计数据收集 日志收集 Event Sourcing 流式处理 Kafka设计原理broker端设计架构broker是Apache Kafka最重要的组件，本质上它是一个功能载体（或服务载体），承载了绝大多数的Kafka服务。事实上，大多数的消息队列框架都有broker或已知类似的角色。一个broker通常是以服务器的形式出现的。 消息设计 消息格式 V2版本分为消息和消息集合两个维度，不过消息集合的提法被消息批次所取代。V2版本中，它有一个专门的属于：RecordBatch。 V2版本消息格式 “可变长度”表示Kafka会根据具体的值来确定到底需要几字节保存。为了在序列化时降低使用的字节数，V2版本借鉴了Google ProtoBuffer中的Zig-zag编码方式，使得绝对值较小的整数占用字节数较少的字节。 消息batch CRC值从消息层面被移除，放入batch这一层 PID、producer epoch和序列号等消息都是0.11.0.0版本为了实现幂等性producer和支持事务而一如的。 通过使用mirco-batch，批次地发送消息，能大幅度地提高Kafka的吞吐量。 集群管理Kafka是分布式的消息引擎集群环境，支持自动化的服务发现与成员管理。依赖于Apache Zookeeper实现，每当一个broker启动，它会将自己注册到Zookeeper下的一个节点。 首先，每个broker在Zookeper下注册节点的路径是chroot/brokers/ids/&lt;broker.id&gt;。如果没有配置chroot，则路径是/broker/ids/&lt;broker.id&gt;。 其次，broker向Zookeeper中的注册消息以JSON格式保存。 12345678910111213141516&#123; "version": 4, "host": "loacalhost", "port": 9092, "jmx_port": 9999, "timestamp": 1499737197, "endpoints": [ "CLIENT"://host1:9092", "REPLICATION://HOST1:9093" ], "listener_security_protocol_map": &#123; "CLIENT": "SSL", "REPLICATION": "PLAINTEXT" &#125;, "rack": "dc1"&#125; 最后，Zookeeper临时节点的生命周期和客户端会话绑定。如果客户端会话失效，该临时节点就会自动被清除掉。Kafka正是利用Zookeeper临时节点来管理broker生命周期的。broker启动时在Zookeeper中创建对应的临时节点，同时还会创建一个监听器（listener）监听该临时节点的状态；一旦broker启动后，监听器会自动同步整个集群消息到该broker上；而一旦broker崩溃，它与Zookeeper的会话就会失效，导致临时节点被删除，监听器被触发，然后处理broker崩溃的后续事宜。这就是Kafka管理集群及其成员的主要流程。 副本与ISR设计一个Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在Kafka中被称为副本（replica）。 follower副本同步 起始位移（base offset）：表示该副本当前所含第一条消息的位移 高水印值（high watermark，HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader分区的HW值决定了副本中已提交消息的范围，也确定了consumer能够获取消息的消息上限。任何一个副本对象的HW值一定不大于其LEO值。Kafka对leader副本和follower副本的HW值更新机制是不同的。 日志末端位移（log end offset，LEO）：副本日志中下一条待写入消息的offset。所有副本都需要维护自己的LEO信息。只有ISR中的所有副本都更新了对应的LEO之后，leader副本才会向右移动HW值表明消息写入成功。Kafka对leader副本和follower副本的LEO值更新机制也是不同的。 水印（watermark）和leader epoch 水印被称为高水印或高水位，通常被用在流水式处理领域，以表征元素或时间在基于时间层面上的进度。在Kafka中，水印的概念与时间无关，而与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。 LEO更新机制 follower follower副本不停地向leader副本所在broker发送FETCH请求，一旦获取消息，便写入自己的日志中进行备份。 Kafka设计了两套follower副本LEO属性：一套LEO属性保存在follower副本所在broker的缓存上；另一套LEO值保存在leader副本所在broker的缓存上。换句话说，leader副本所在broker的缓存上保存了该分区下所有follower副本的LEO属性值。 follower副本端LEO更新 每当在底层日志新写入一条消息，其LEO值就会加1. leader副本端的follower副本LEO更新 一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO。 leader 每当在底层日志新写入一条消息，其LEO值就会加1. HW更新机制 前面说过，leader broker上保存了一套follower副本的LEO以及它自己的LEO。当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO，并选择最小的LEO值作为HW值。 图解Kafka备份原理 基于水印机制的缺陷 数据丢失：使用HW值来确定备份进度时其值的更新是在下一轮RPC中完成的。延迟一轮FETCH请求更新HW的值的设计使得followerHW值是异步延迟更新的，若在这个过程中leader发生变更，那么称为新leader的follower的HW值就有可能是过期的，使得clients端认为成功提交的消息被删除了。 数据不一致/数据离散：leader端log和follower端的log数据不一致 leader epoch 上述两个问题的根本原因在于HW值被用于衡量副本备份的成功与否，以及在出现崩溃时作为日志截断的依据，但HW值的更新是异步延迟的，特别是需要额外的FETCH请求处理流程才能更新，这中间发生的任何崩溃都可能导致HW值的过期 leader epoch，实际上是一对值(epoch，offset)。epoch表示leader的版本号，从0开始，当leader变更过1次时，epoch就会+1，而offset则对应于该epoch版本的leadre写入第一条消息的位移。 通信协议 协议设计 所谓通信协议，就是实现client-server间或server-server间数据传输的一套规范。Kafka通信协议是基于TCP之上的二进制协议，这套协议提供的API表现为服务于不同功能的多种请求类型以及对应的相应。所有类型的请求和响应都是结构化的，有不同的初始类型构成。 常见请求类型 PRODUCE请求 FETCH请求 METADATA请求 请求处理流程 clients端 broker端 controller设计 controller概览 在一个Kafka集群中，某一个broker会被选举出来承担特殊的角色，即控制器。一如controller就是用来管理和协调Kafka集群的。具体来说，就是管理集群中所有分区的状态并执行相应的管理操作。 controller管理状态 controller维护的状态分为两类：每台broker上的分区副本和每个分区的leader副本信息。从维度上看，这些状态可分为副本状态和分区状态。 副本状态机 分区状态机 controller职责 更新集群元数据信息 创建topic 删除topic 分区重分配 preferred leader副本选举 topic分区扩展 broker加入集群 broker崩溃 受控关闭 controller leader选举 broker请求处理 Reactor模式 Kafka broker处理请求的模式就是Reactor设计模式。Reactor设计模式是一种事件处理模式，旨在处理多个输入源同时发送过来的请求。Reactor模式中的服务处理器或分发器将入站请求按照多路复用的方式分发到对应的请求处理器。 Kafka broker请求处理 Kafka broker请求处理实现了Reactor模式。在Kafka中，每个broker都有一个acceptor线程和若干个processor线程。processor线程的数量是可以配置的。 producer端设计架构producer端基本数据结构 ProducerRecord 一个ProducerRecord封装了一条待发送的消息（或称为记录）。 ProducerRecord由5个字段构成: topic：该消息所属的topic partition：该消息所属的分区 key：消息key value：消息体 timestamp：消息时间戳 RecordMetadata 该数据结构表示Kafka服务器端返回给客户端的消息的元数据 offset：消息在 分区日志中的位移信息 timesstamp：消息时间戳 topic/partition checksum：消息CRC32码 serializedKeySize：序列化后消息的key字节数 serializedValueSize：序列化后消息value字节数 工作流程如果把producer统一看成一个盒子，那么整个producer端的工作原理便如图所示。大体来说，用户首先构建待发送的消息对象ProducerRecord，然后调用KafkaProducer#send方法进行发送。KafkaProducer接收到消息后首先对其进行序列化，然后结合本地缓存的元数据信息一起发送给partitioner去确定目标分区，最后追加写入内存中的消息缓冲池。 调用KafkaProducer.send执行的操作： 序列化+计算目标分区 追加写入消息缓冲区 Sender线程预处理及消息发送 consumer端设计架构consumer group 状态机新版本consumer依赖于broker端的组协调者coordinator来管理组内的所有consumer实例并负责把分配方案发到每个consumer上。分配方案由组内的leader consumer根据指定的分区分配策略指定的。 分区分配的操作在consumer端执行而非broker端的好处： 便于维护与升级：如果在broker端实现，那么分配策略的变动势必要重启整个Kafka集群。生产环境中重启服务器的代价是很高的。 便于实现自定义策略：不同的策略由不同的逻辑实现。coordinator端代码不容易实现灵活可定制的分配逻辑 解耦了组管理与分区分配，coordinator负责组管理工作，而consumer程序负责分区分配。 Kafka为每个consumer group定义了5个状态： Empty：表明group下没有任何active consumer，但可能包含位移信息。 PreparingRebalance：该状态表明group正在准备进行group rebalance。 AwaitingSync：该状态表明所有成员都已经加入组并等待leader consumer发送分区分配方案。 Stable：该状态表明group开始正常消费。此时group必须响应clients发送过来的任何请求。 Dead：该状态表明group已经彻底废弃，group内没有任何成员并且group的所有元数据都已被删除。 实现精确一次处理语义(exactly-once semanties, EOS)clients端常见的3种消息交付语义： 最多一次（ai most once）：消息可能丢失也可能被处理，但最多只会被处理一次 至少一次（at last once）：消息不会丢失，但可能被多次处理 精确一次（exactly once）：消息被处理且只会被处理一次。 幂等性producer（idempotent producer）幂等性producer是Apache Kafka 0.11.0.0版本用于实现EOS的一个利器。若一个操作执行多次的结果与只运行一次的结果是相同的，那么称该操作为幂等操作。引入幂等producer表示它的发送操作是幂等。瞬时的发送错可能导致produecer端出现重试，同一个消息被producer发送多次，但在broker端这条消息只会被写入日志一次。 幂等性producer的设计思路类似于TCP的工作方式。发送到broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和TCP不同的是，这个序列号不会被丢弃，相反Kafka会把它们保存在底层日志中，这样即使分区的leader副本挂掉，新选出来的leader broker也能执行消息去重工作。 事务（transaction）对事务的支持是Kafka实现EOS的第二个利器。引入事务使得clients端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。 处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中。重要的是不论是发送还是消费，Kafka都能保证它们是原子性，即所有的写入操作幺妹全部成功，要么全部失败。 Kafka为实现事务要求应用程序必须提供一个唯一的id来表征事务。这个id被称为事务id，它必须在应用程序所有的会话上是唯一的。 PS：未完待续，后续深入学习再做补充]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核]]></title>
    <url>%2F2019%2F02%2F25%2FLinux%E5%86%85%E6%A0%B8%EF%BC%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深入理解Linux内核Linux 的优势 Linux是免费的。除硬件之外，无需任何花费就能安装一套玩整的Linux系统 Linux的所有成分都可以充分地定制。通过内核编译选项，你可以选择自己真正需要的特征来定制内核。 Linux可以运行在低档、便宜的硬件平台上。 Linux是强大的，由于充分挖掘了硬件部分的特点，使得Linux系统速度非常块，Linux的主要目标是效率 Linux的开发者都是非常出色的程序员。 Linux内核非常小，而且紧凑。 Linux与很多通用操作系统高度兼容。 Linux有很好的技术支持 内核控制路径（Kernel control path）表示内核处理系统调用、异常或中断所执行的指令序列。 最简单的情况下，CPU从第一条指令到最后一条指令顺序地执行内核控制路径。然而当下述事件之一发生时，CPU交错执行内核控制路径： 运行在用户态的进程调用一个系统调用。 当运行一个内核控制路径时，CPU检测到一个异常（例如，访问一个不在RAM中的页）。 当CPU正在运行一个启用了中断的内核控制路径时，一个硬件中断发生。 在支持抢占式调度的内核中，CPU正在运行，而一个更高优先级的进程加入就绪队列，则中断发生。 同步内核路径 非抢占式内核，当进程在内核态执行时，它不能被任意挂起，也不能被另一个进程代替。因此，在单处理器系统上，中断或异常处理程序不能修改的所有内核数据结构，内核对它们讷的访问都是安全的 禁止中断，单处理器系统上的另一种同步机制是：在进入一个临界区之前禁止所有硬件中断，离开时再重新启动中断。 信号量,信号量仅仅是与一个数据结构相关的计数器。所有内核线程在试图访问这个数据结构之前，都要检查这个信号量。可以把每个信号量看成一个对象，其组成如下： 一个整数变量 一个等待进程的链表 两个原子方法：down()和up() 自旋锁,如果修改数据结构所需的时间比较段，那么，信号量可能是低效的。为了检查信号量，内核必须把进程插入到信号量链表中，然后挂起它。因为这两种操作比较费时，完成这些操作时，其他的内核控制路径可能已经释放了信号量。在这些情况下，多处理器操作系统使用了自旋锁（spin lock）。自旋锁与信号量非常相似，但没有进程链表，当一个进程发现锁被另一个进程锁着时，它就不停地“旋转”，执行一个紧凑的循环指令直到锁打开。当然，自旋锁在单处理器环境下是无效的。 内存寻址随机访问存储器（RAM）的使用 所有的Unix操作系统都将RAM毫无疑义地划分为两部分，其中若干兆字节专门用于存放内核映像（也就是内核代码和内核静态数据结构）。RAM的其余部分通常有虚拟内存系统来处理，并且用在以下三种可能的方面： 满足内核对缓冲去、描述符及其他动态内核数据结构的请求 满足进程对一般内存区的请求及对文件内存映射的请求 借助于高速缓存从磁盘及其他缓冲设备获得较好的性能 内核内存分配器 内存内核分配其（Kernel Memory Allocator, KMA）是一个子系统，它试图满足系统中所有部分对内存的请求。 基于各种不同的算法技术，已经提出了集中KMA，包括： 资源图分配算法（allocator） 2的幂次方空间链表 McKusick-Karels分配算法 伙伴（Buddy）系统 Mach的区域（Zone）分配算法 Dynix分配算法 Solaris的Slab分配算法 物理内存布局 在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用（或者因为它们映射硬件设备I/O的共享内存，或者因为相应的页框含有BIOS数据）。 内核将下列页框记为保留： 在不可用的物理地址范围内的页框。 含有内核代码和已初始化的数据结构的页框 保留页框中的页绝不嫩被动态分配或交换到磁盘上。 进程进程链表 Linux的进程链表是一个双向链表，进程链表把所有进程的描述符链接起来。每个task_struct结构都包含一个list_head类型的tasks字段，这个类型的prev和next字段分别指向前面和后面的task_struct元素。 进程链表的头是init_task描述符，它是所谓的0进程（process 0）或swapper进程的进程描述符。init_task的tasks.prev字段指向链表中最后插入的进程描述符tasks字段。 TASK_RUNNING状态的进程链表 当内核寻找一个新进程在CPU上运行时，必须只考虑可运行进程（即处在TASK_RUNNING状态的进程）。 早期的Linux版本把所有的可运行进程都放在同一个叫作运行队列（runqueue）的链表中，由于维持链表中的进程按优先级排序开销过大，因此，早期的调度程序不得不为选择“最佳”可运行进程而扫描整个队列。 Linux 2.6实现的运行队列有所不同。其目的是让点读程序能在固定的时间内选出“最佳”可运行程序，与队列中可运行的进程数无关。提高调度程序运行速度的诀窍是建立多个可运行进程链表，每种进程优先权对应一个不同的链表。这是一个通过使数据结构更复杂来改善性能的典型例子：调度程序的操作效率的确更高了，但运行队列的链表却为此而被拆分成140(0-139）个不同的队列。——空间换时间 进程间的关系 程序创建的进程具有父/子关系。如果一个进程创建多个子进程时，则子进程之间具有兄弟关系。 图3-4显示了一组进程间的亲属关系。进程P0接连创建了P1，P2，和P3。进程P3又创建了P4。 pidhash表及链表 在几种情况下，内核必须能从进程的PID到处对应的进程描述符指针。 顺序扫描进程链表并检查进程描述符的pid字段是可行但相当低效的。为了加速查找，引入了4个散列表。需要4个散列表是因为进程描述符包含了表示不同类型pid的字段，而且每种类型的PID需要它自己的散列表。 正如计算机科学的基础课程所阐述的那样，散列（hash）函数并不总能确保PID与表的索引一一对应。两个不同的PID散列（hash）到相同的表索引称为冲突（colliding） Linux利用链表来处理冲突的PID：每一个表项是由冲突的进程描述符组成的双向链表。 具有链表的散列法比从PID到表索引的线性转换更优越，这是因为在任何给定的实例中，系统中的进程数总是远远小于32768（所允许的进程PID的最大数）。如果在任何给定的实例中大部分表项都不使用的话，那么把表定义为32768项会是一种存储浪费。 由于需要跟踪进程间的关系，PID散列表中使用的数据结构非常复杂。 PID散列表的数据结构解决了所有这些难题，因为他们可以为包含在一个散列表中任意PID号定义进程链表。 等待队列 等待队列在内核中有很多用途，尤其用在中断处理、进程同步及定时。等待队列表示一组睡眠的进程，当某一条件变为真时，由内核唤醒它们。 等待队列由双向链表实现，其元素包括指向进程描述符的指针。因为等待队列是由中断处理和主要内核函数修改的，因此必须对其双向链表进行保护以免对其进行同事访问，因为同事访问会导致不可预测的后果。 注：雷鸣般兽群问题：即唤醒多个进程只为了竞争一个资源，而这个资源只能有一个进程访问，结果是其他进程必须再次回去睡眠。 非互斥进程插入等待队列链表的第一个位置。互斥进程插入等待队列链表的最后一个位置。 因为所有的非互斥进程总是在双向链表的开始位置，而所有的互斥进程在双向链表的尾部，所以函数总是先唤醒非互斥进程然后再唤醒互斥进程，如果有进程存在的话。 进程切换 硬件上下文 进程恢复执行前必须转股寄存器的一组数据称为硬件上下文（hardware context)。硬件上下文是进程可执行上下文的一个子集。在Linux中，进程硬件上下文的一部分存放在TSS段，而剩余部分存放在内核太堆栈中。 任务状态段(TSS) 80x86体系结构包括了一个特殊的段类型，叫任务状态段（Task State Segment, TSS)来存放硬件上下文。尽管Linux并不使用硬件上下文切换，但是强制它为系统中每个不同的CPU创建一个TSS。 thread字段 在每次进程切换时，被替换进程的硬件上下文必须保存在别处。不能像Intel原始设计那样把它保存在TSS中，因为Linux为每个处理器而不是为每个进程使用TSS。 因此，每个进程描述符包含一个类型为thread_struct的thread字段，只要进程被切换出去，内核就把其硬件上下文保存在这个结构中。 执行进程切换 从本质上说，每个进程切换由两步组成： 切换页全局目录以安装一个新的地址空间 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包括CPU寄存器。 创建进程 Unix操作系统紧紧依赖进程创建来满足用户的需求。 传统的Unix操作系统以统一的方式对待所有的进程：子进程复制父进程所拥有的资源。这种方法使进程的创建非常慢且效率低，因为子进程需要拷贝父进程的整个个、地址空间。 现代Unix内核通过引入三种不同的机制解决了这个问题： 写时复制技术允许父子进程读相同的物理页。只要两者中有一个试图写一个物理页，内核就把这个页的内容拷贝到一个新的物理页，并把这个新的物理页分配给正在写的进程。 轻量级进程允许父子进程共享进程在内核的很多数据结构，如页表、打开文件表及信号处理。 vfork()系统调用创建的进程能共享其父进程的内存地址空间。为了防止父进程重写子进程需要的数据，阻塞父进程的执行，一直到到子进程退出或执行一个新的程序为止。 clone()、fork()及vfork()系统调用 在Linux中、轻量级进程是由名为clone()的函数创建的。 实际上，clone()是在C语言库中定义的一个封装（wrapper）函数，它负责建立新轻量级进程的堆栈并且调用对编程者隐藏的clone()系统调用。 传统的fork()系统调用和vfork()系统调用在Linux中也是用clone()实现的。 内核线程 因为一些系统进程只运行在内核太，所以现代操作系统把它们的函数委托给内核线程（kernel thread），内核线程不受不必要的用户态上下文的拖累。 进程 0 所有进程的祖先叫作进程0，idle进程，或因为历史的原因叫作swapper进程，它是在Linux的初始化阶段从无到有创建的一个内核线程。这个祖先进程使用下列静态分配的数据结构（所有其他进程的数据结构都是动态分配的）： 存放在init_task变量中的进程描述符，由INIT_TASK宏完成对它的初始化 存放在init_thread_union变量中的thread__info描述符和内核堆栈，由INIT_THREAD_INFO宏完成对它们的初始化。。 由进程描述符指向的下列表： init_mm init_fs init_files init_signals init_sighand 主内核页全局目录存放在swapper_pg_dir中。 start_kernel()函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程（一般叫作init进程）。新创建内核线程的PID为1，并与进程0共享每个进程所有的内核数据结构。此外，当调度程序选择到它时，init进程开始执行init（）函数。 在多处理器系统中，每个CPU都有一个进程0.只要打开机器电源，计算机的BIOS就启动某一个CPU，同时禁用其他CPU。运行在CPU0还是上的swapper进程初始化内核数据结构，然后激活其他的CPU，并通过copy_process()函数创建另外的swapper进程，把 0 传递给新创建的swapper进程作为它们的新PID。 进程 1 由进程 0 创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init。结果，init内核线程变为一个普通进程，且拥有自己的每进程（per-process）内核数据结构。在系统关闭之前，init进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。 其他内核线程 Linux使用很多其他内核线程。其中一些在初始化阶段创建，一直运行奥系统关闭，而其他一些在内核必须执行一个任务时“按需”创建，这种任务在内核的执行上下文中得到很好的执行。 进程删除Unix允许进程查询内核以获得其父进程的PID，或者其任何子进程的执行状态。 为了遵循这些设计选择，不允许Unix内核在进程一终止后就丢弃包含在进程描述符字段中的数据。只有父进程发出了与被终止的进程相关的wait（）类系统调用之后，才允许这样做。这就是引入僵死状态的原因：尽管从技术上来说进程已死，但必须保存它的描述符，直到父进程得到通知。 如果父进程在子进程结束之前结束会发生什么情况呢？在这种情况下，系统中会到处是僵死的进程，而且它们的进程描述符永久占据这RAM。所以这必须强迫所有的孤儿进程成为init进程的子进程来解决这个问题。这样，init进程在用wait（）类系统调用检查其合法的子进程终止时，就会撤销僵死的进程。 对僵死进程的处理有两种可能的方式： 如果父进程不需要接收来自子进程的信号，就调用do_exit()。 如果已经给父进程发送了一个信号，就调用wait4（）或waitpid（）系统调用。 中断和异常中断通常分为同步（synchronous）中断和异步（asynchronous）中断： 同步中断是指当指令执行时有CPU控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后CPU才会发出中断。 异步中断是由其他硬件设备依照CPU时钟信号随机产生的。 在Intel微处理器手册中，把同步和异步中断分别称为异常（exception）和中断（interrupt）。 中断 可屏蔽中断（maskable interrupt） 非屏蔽中断（nonmaskable interrupt） 异常 故障（fault） 陷阱（trap） 异常中止（abort） 编程异常（programmed exception) 中断描述符表 中断描述符表（Interrupt Descriptor Table, IDT）是一个系统表，它与灭一个中断或异常向量相联系，每一个向量在表中有相应的中断或异常处理程序的入口地址。 IDT包含三种类型的描述符。 这些描述符是： 任务门（task_gate) ​ 当中断信号发生时，必须取代当前进程的那个进程的TSS选择符存放在任务门中。 中断门（interrupt gate) ​ 包含段选择符和中断或异常处理程序的段内偏移量。当控制权转移到一个适当的段时， 处理器清IF标志，从而关闭将来会发生的可屏蔽中断。 陷阱门（Trap gate） ​ 与中断门相似，只是控制权传递到一个适当的段时处理器不修改IF标志。 Linux利用中断门处理中断，利用陷阱门处理异常 中断和异常处理程序的嵌套执行 每个中断或异常都会引起一个内核控制路径，或者说代表当前进程在内核态执行单独的指令序列。内核控制路径可以任意嵌套：一个中断处理程序可以被另一个中断处理程序“中断”，因此引起内核控制路径的嵌套执行。如图所示。 允许内核控制路径嵌套执行必须付出代价，那就是中断处理程序必须永不阻塞，换句话说，中断处理程序运行期间不能发生进程切换。事实上，嵌套的内核控制路径恢复执行时需要的所有数据都存放在内核态堆栈栈中，这个栈毫无疑义的属于当前进程。 一个中断处理程序既可以抢占其他的中断处理程序，也可以抢占异常处理程序。相反，异常处理程序从不抢占中断处理程序。 基于以下两个主要原因，Linux交错执行内核控制路径： 为了提高可编程中断控制器和设备控制器的吞吐量。 为了实现一种没有优先级的中断模型。简化了内核代码，提高了内核的可移植性。 IRQ在多处理器系统上的分发 Linux遵循对称多处理模型（SMP），这意味着，内核从内本质上对任何一个CPU都不应该有 偏爱。因而，内核试图以轮转的方式把来自硬件设备的IRQ信号在所有CPU之间分发。因此，所有CPU服务于I/O中断的执行时间片几乎相同。 在系统启动的过程中，引导CPU执行setup_IO_APIC_irqs()函数来初始化I/O APIC芯片。芯片的中断重定向表的24项被填充，以便根据“最低优先级”模式把来自I/O硬件设备的所有信号都传递给系统中的每个CPU。此外，在系统启动期间，所有的CPU都执行setup_local_APIC()函数，该函数处理本地APIC的初始化。特别是，每个芯片的任务优先级寄存器（TPR）都初始化为一个固定的值，这就意味着CPU愿意处理任何类型的IRQ信号，而不管优先级。Linux内核启动后再也不修改这个值。 因为所有的任务优先级寄存器都包含相同的值，因此，有所CPU总是具有相同的优先级。为了突破这种约束，多APIC系统使用本地APIC仲裁优先级寄存器中的值。因为这样的值在每次中断后都自动改变，因此，IRQ信号就公平地在所有CPU之间分发。 简而言之，当硬件设备发生了一个中断信号时，多APIC系统就选择其中的一个CPU，并把该信号传递给相应的本地APIC，本地APIC又依次中断它的CPU。这个事件不通报给其他所有的CPU。 内核同步可以把内核看作是不断对请求进行响应的服务器，这些请求可能来自在CPU上执行的进程，也可能来自发出中断请求的外部设备。这个类比强调内核的各个部分并不是严格按照顺序依次执行的，而是采用交错执行的方式。因此，这些请求可能引起竞争条件,而我们必须采用适当的同步机制对这种情况进行控制。 内核抢占 如果进程执行内核函数时，即它在内核态运行时，允许发生内核切换（被替换的进程是正执行内核函数的进程），这个内核就是抢占的。 使内核可抢占的目的是减少用户态进程的分派延迟（dispatch latency），即从进程变为可执行状态到它实际开始运行之间的时间间隔。 内核使用的各种同步技术 每CPU变量 最好的同步技术是把设计不需要同步的内核放在首位。最简单也是最最重要的同步技术包括把内核变量声明为每CPU变量（per-cpu variable)。每CPU变量主要是数据结构的数组，系统的每个CPU对应数组的一个元素。 一个CPU不应该访问与其它CPU对应的数组元素，另外，它可以随意读或修改它自己的元素而不用担心出现竞争条件。但是，这也意味着每CPU变量基本上只能在特殊情况下使用，也就是当它确定在系统的CPU上的数据在逻辑上是独立的时候。 每CPU的数组元素在主存中被排列以使每个数据结构存放在硬件高速缓存的不同行，因此，对每CPU数组的并发访问不会导致高速缓存行的窃用和失效。 此外，在单处理器和多处理器系统中，内核抢占都可能使每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。 原子操作 若干汇编语言指令具有“读—修改—写”类型——也就是说，它们访问内存单元两次，第一次读原值，第二次写新值。 避免由于“读—修改—写”指令引起的竞争条件的最容易的方法，就是确保这样的操作在芯片级是原子的。任何一个这样 的操作都必须以单个指令执行，中间不嫩中断，且避免其他的CPU访问同一存储器单元。这些很小的原子操作（atomic opreations)可以建立在其他更灵活机制的基础之上以创建临界区。 操作码前缀是lock字节（0xf0）的“读—修改—写”汇编语言指令即使在多处理器系统中也是原子的。当控制大暖检测到这个前缀时，就“锁定”内存总线，直到这条指令执行完成为止。因此，当枷锁的指令执行时，其他处理器不能访问这个内存单元。 优化和内存屏障 当使用优化的编译器时，编译器可能重新安排汇编语言指令以使寄存器以最优的方式使用。此外，现代CPU通常并行地执行若干条指令，且可能重新安排内存访问。这种重新排序可以极大地加速程序的执行。 然而，当处理同步时，必须避免指令重新排序。如果发放在同步原语之后的一条指令在同步原语本身之前执行，事情很快就会变得失控。事实上，所有的同步原语起优化和内存屏障的作用。 优化屏障（memory barrier）原语保证编译程序不会混淆放在原语操作之前的汇编语言指令和放在原语操作之后的汇编语言指令。在Linux中，优化屏障就是barrier（）宏，它展开为asm volatile(“:::”memory”)。volatile关键字禁止编译器把asm指令与程序中的其他指令重新组合。memory关键字强制编译器假定RAM中的所有内存单元已经被汇编语言指令修改。因此，编译器不能使用存放在CPU寄存器中的内存单元的值来优化asm指令前的代码。 内存屏障（memory barrier）原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，内存屏障类似于防火墙，让任何汇编语言指令都不能通过。 Linux使用六个内存屏障原语： rm() rmb() wmb() smp_mb() smp_rmb() smp_wmb() 这些原语也被当做优化屏障，因为我们必须保证编译程序不在屏障前后移动汇编语言指令。内存屏障原语的实现依赖与系统的体系机构。在80x86微处理器上，如果CPU支持lfence汇编语言指令，就把rmb（）宏展开为asm volatile（”lfence”)，否则就展开为asm volatile（”lock;addl $0,0(%%esp)”:::”memory”)。 自旋锁 一种广泛使用的同步技术是加锁（locking）。当内核控制路径必须访问共享数据结构或进入临界区时，就需要为自己获取一把”锁“。 自旋锁（spin lock）是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁”开着“，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径”锁着“，就在周围”旋转“，反复执行一条紧凑的循环指令，直到锁被释放。 自旋锁的循环指令表示”忙等“。及时等待的内核控制路径无事可做（除了浪费时间），它也在CPU上保持运行。不过自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时间片段。 一般来说，由自旋锁所保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这种锁本身不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。在自旋锁忙等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进程替代。 在Linux中，每个自旋锁都用spin_lock_t结构表示，其中包含两个字段： slock：该字段表示自旋锁的状态，值为1表示”未加锁“状态，而任何负数和0都表示”加锁“状态。 break_lock：表示进程正在忙等自旋锁（只在内核支持SMP和内核抢占的情况下使用该标志）。 读/写自旋锁 读/写自旋锁的引入是为了增加内核的并发能力。只要没有内核控制路径对数据结构进行修改，读/写自旋锁就允许多个内核控制路径同时读同一数据结构。如果一个内核控制路径想对这个结构进行写操作，那么它必须首先获取读/写锁的写锁，写锁授权独占访问这个资源。当然，允许对数据结构并发读可以提高系统性能。 顺序锁 Linux2.6中引入了顺序锁（seqlock），它与读/写自旋锁非常相似，只是它为写着赋予了较高的优先级：事实上，即使在读者正在读的时候也允许写者继续运行。这种策略的好处是写者永远不会等待（除非另一个写者正在写），缺点是有些时候读者不等不反复多次读相同的数据直到它获得有效的副本。 每个顺序所都是包括两个字段seqlock_t结构：一个类型为spin_lock_t的lock字段和一个整型的sequence字段，第二个字段是一个顺序计数器。**每个读者都必须在读数据前后两次读顺序计数器，并检查两次读到的值是否相同，如果不相同，说明新的写者已经开始写并增加了顺序计数器，因此暗示读者刚读到的数据是无效的。 读—拷贝—更新（RCU） 读—拷贝—更新（RCU）是为了保护在多数情况下被多个CPU读的数据结构而设计的另一种同步技术。RCU允许多个读者和写者并发执行。而且，RCU是不适用锁的，就是说，它不适用被所有CPU共享的锁或计数器，在这一点上与读/写自旋锁和顺序锁（由于高速缓存行窃用和失效而有很高的开销）相比，RCU具有更大的优势。 其关键思想包括限制RCU的范围： RCU只保护被动态分配并通过指针引用的数据结构 在被RCU保护的临界区中，任何内核控制路径都不能失眠。 信号量 实际上，Linux提供两种信号量： 内核信号量，由内核控制路径使用 System V IPC信号量，由用户态进程使用 内核信号量类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。然而，当内核控制路径试图获取内核信号量所保护的忙资源时，相应的进程被挂起。只有在资源被释放时，进程才再次变为可运行的。因此，只有可以睡眠的的函数才能获取内核信号量，中断处理程序和可延迟函数都不能使用内核信号量。 禁止本地中断 确保一组内核语句被当做一个临界区处理的主要机制之一就是中断禁止。即使当硬件设备产生了一个IRQ信号时，中断禁止也让内核控制路径继续执行，因此，这就提供了一中有效的方式 ，确保中断处理程序访问的数据结构也受到保护。然而禁止本地中断并不保护运行在另一个CPU上的中断处理程序对数据结构的并发访问，因此，在多处理器系统上，禁止本地中断经常与自旋锁结合使用。 禁止和激活可延迟函数 禁止可延迟函数在一个CPU上执行的一种简单方式就是禁止在那个CPU上的中断。因为没有中断处理程序被激活，因此，软中断操作就不能异步地开始。 总结 技术 说明 使用范围 每CPU变量 在CPU之间复制数结构 所有CPU 原子操作 对一个计数器原子地”读—修改—写“的指令 所有CPU 内存屏障 避免指令重新排序 本地CPU或所有CPU 自旋锁 加锁时忙等 所有CPU 信号量 加锁时阻塞等待（睡眠） 所有CPU 顺序锁 基于访问计数器的锁 所有CPU 本地中断的禁止 禁止单个CPU上的中断处理 本地CPU 本地软中断的禁止 禁止单个CPU上的可延迟函数处理 本地CPU 读—拷贝—更新（RCU) 通过指针而不是锁来访问共享数据结构 所有CPU 定时测量 Linux计时体系结构 Linux必定执行于定时相关的操作。例如，内核周期性地： 更新自系统启动以来所经过的时间 更新时间和日期 确定当前进程在每个CPU上已运行了多长时间，如果已经超过了分配给它的时间，则抢占它。 更新资源使用统计数 检查每个软定时器的时间间隔是否已到。 进程调度Linux与任何分时系统一样，通过一个进程到另一个进程的快速切换，达到表面上看来多个进程同时执行的神奇效果。 Linux的调度基于分时技术：多个进程以”时间多路服用“方式运行，因为CPU的时间被分成片”（slice）”，给每个可运行进程分配一片。如果当前运行进程的时间片或时限到期时，该进程还没有运行完毕，进程切换就可以发生。 传统上把进程分类为“I/O受限（I/O-bound）“或”CPU受限（CPU-bound）“。前者频繁地使用I/O设备，并花费很多时间等待I/O操作的完成；而后者则需要大量CPU时间的数据计算应用程序。 另一种分类法把进程分为三类： 交互式进程（interactive process） 这些进程经常与用户进行交互，因此，要花很多时间等待键盘和鼠标操作。当接受了输入后，进程必须被很快唤醒，否则用户将发现系统反应迟钝。典型的交互式程序是命令shell、文本编辑程序及图形应用程序。 批处理进程（batch process) 这些进程不必与用户交互，因此经常在后台运行。典型的批处理进程是程序设计语言的编译程序、数据库搜索引擎及科学计算。 实时进程（real-time process） 这些进程有很强的调度需要。这样的进程绝不会被低优先级的进程阻塞，它们应该有一个很短的响应时间，更重要的是，响应时间的变化应该很小。典型的实时程序有视频和音频应用程序、机器人控制程序及从物理传感器上收集数据的程序。 调度算法每个Linux进程总是按照下面的调度类型被调度： SCHED_FIFO 先进先出的实时进程 SCHED_RR 时间片轮转的实时进程 SCHED_NORMAL 普通的分时进程 普通进程的调度每个普通进程都有它自己的静态优先级，调度程序使用静态优先级来估计系统中这个进程与其他普通进程之间调度的程度。内核用从100（最高优先级）到139（最低优先级）的数表示普通进程的静态优先级。 基本时间片： 与优先级低的进程相比，通常优先级较高的进程获得更长额CPU时间片。 实时进程的调度每个实时进程都与一个实时优先级相关，实时优先级是一个范围从1（最高优先级）～99（最低优先级）的值。调度程序总是让优先级高的进程运行，换句话说，实时进程运行的过程中，禁止低优先级进程的执行。与普通进程相反，实时进程总是被当成活动进程。 只有在下述事件之一发生时，实时进程才会被另外一个进程取代： 进程被另外一个具有更高实时优先级的实时进程抢占 进程执行了阻塞操作并进入睡眠 进程停止或被杀死 进程通过调用系统调用sched_yield()自愿放弃CPU 进程是基于时间片轮转的实时进程，而且用完了它的时间片。 内存管理​]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>内核</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
