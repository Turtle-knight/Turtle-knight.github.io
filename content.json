{"meta":{"title":"Utur的个人博客","subtitle":"天天学习，好好向上","description":"木龟想做一个哈皮程序猿。","author":"Utur","url":"http://yoursite.com","root":"/"},"pages":[{"title":"categories","date":"2019-07-06T07:21:58.000Z","updated":"2019-07-06T08:31:30.648Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-06T07:21:40.000Z","updated":"2019-07-06T08:31:44.957Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Flask学习笔记","slug":"Flask_Web","date":"2019-04-10T16:00:00.000Z","updated":"2019-07-06T09:04:27.482Z","comments":true,"path":"2019/04/11/Flask_Web/","link":"","permalink":"http://yoursite.com/2019/04/11/Flask_Web/","excerpt":"","text":"FlaskFlask是使用Python编写的Web微框架，Web框架可以让开发者不用关心底层的请求响应处理，更方便更高效地编写Web程序。Flask有两个主要依赖，一个是WSGI（Web Server Gateway Interface，Web服务器网关接口）工具集——Werkzeug，另一个是Jinja2模板引擎。 搭建开发环境 安装pip和pipenv 1$ pip install pipenv 创建虚拟环境 在Python中虚拟环境（virtual environment）就是隔离的Python解释器环境。通过创建虚拟环境，你可以拥有一个独立的Python解释器环境。这样做的好处是可以为每一个项目创建独立的Python解释器环境，因为不同的项目常常会话依赖不同版本的库或Python版本。使用虚拟环境可以保持全局Python解释器环境的干净，避免包和版本的混乱，并且可以方便地区分和记录每个项目的依赖，以便在新环境下复现依赖环境。 123$ pipenv install # 为当前目录的项目创建虚拟环境$ pipenv shell # 显式激活虚拟环境 安装Flask 1$ pipenv install flask # 在虚拟环境中安装Flask 注册路由在一个Web应用里，客户端和服务器上的Flask程序的交互可以简单概括为以下几步： 1）用户在浏览器中输入URL访问某个资源 2）Flask接收用户请求并分析请求的URL 3）为这个URL找到对应的处理函数 4）执行函数并生成响应，返回给浏览器 5）浏览器接收并解析响应，将信息显示在页面中 在以上步骤中，大部分都由Flask完成，开发者要做的只是建立处理请求的函数，并定义对应的URL规则。只需为函数附加app.route()装饰器，并传入URL规则作为参数，就可以让URL与函数建立联系。这个过程称为注册路由（route），路由负责管理URL和函数之间的映射，而这个函数则被称为视图函数（view function）。 例如： 123@app.route('/')def index(): return '&lt;h1&gt;Hello, World&lt;/h1&gt;' 在这个程序里，app.route()装饰器把根地址/和index()函数绑定起来，当用户访问这个URL时就会触发index()函数。这个视图函数可以像其他普通函数一样执行任意操作，最后，视图函数返回的值作为响应的主体。 为视图绑定多个URL 一个视图函数可以绑定多个URL。 例： 1234@app.route('/hi')@app.route('/hello')def say_hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt;' 动态URL 123@app.route('/greet/&lt;name&gt;')def greet(name): return '&lt;h1&gt;Hello, %s!&lt;/h1&gt;' % name 启动开发服务器1$ flask run flask run命令启动内置的开发服务器。 自动发现程序实例 一般来说，在执行flask run命令运行程序前，需要提供程序实例所在模块的位置。若无提供，Flask会自动探测程序实例，自动探测存在以下规则： 从当前目录寻找app.py和wsgi.py模块，并从中寻找名为app或application的程序实例。 从环境变量FLASK_APP对应的值寻找名为app或application的程序实例。 管理环境变量 Flask的自动发现程序实例机制还有第三条规则：如果安装了python-dotenv，那么在使用flask run或其他命令时会使用它自动从.flaskenv文件和.env文件中加载环境变量。 为了避免频繁设置环境变量，可以使用python-dotenv管理项目的环境变量。 1$ pipenv install python-dotenv .flaskenv文件用来存储和Flask相关的公开环境变量，比如FLASK_APP; .env文件用来存储包含敏感信息的环境变量，比如账户名和密码。 环境变量以键值对的形式定义。 Flask与HTTP请求响应循环 HTTP请求Request对象这个请求对象封装了从客户端发来的请求报文，能从它获取请求报文中的所有数据。 在Flask中处理请求 设置监听的HTTP方法 123@app.route('/hello', method=['GET', 'POST'])def hello(): return '&lt;h1&gt;Hello, Flask!&lt;/h1&gt; 请求钩子有时需要对请求进行预处理（preprocessing）和后处理（postprocessing）。这时可以使用Flask提供的一些请求钩子（Hook），它们可以用来注册在请求处理的不同阶段执行的处理函数。这些请求钩子用装饰器实现，通过程序实例app调用。 ​ 请求钩子 钩子 说明 before_first_request 注册一个函数，在处理第一个请求前运行 before_request 注册一个函数，在处理每个请求前运行 after_request 注册一个函数，如果没有未处理的异常抛出，会在每个请求结束后运行 teardown_request 注册一个函数，即使有未处理的异常抛出，会在每个请求结束后运行 after_this_request 在视图函数内注册一个函数，会在这个请求结束后运行 HTTP响应响应格式在HTTP响应中，数据可以通过多种格式传输。大多数情况下，我们会使用HTML格式，这是Flask中的默认设置。在特定的情况下，也会使用其他格式。不同的响应数据格式需要设置不同的MIME类型。 纯文本 MIME类型： text/plain HTML MIME类型：text/html XML MIME类型：application/xml JSON MIME类型：application/json CookieHTTP是无状态协议。在一次响应结束后，服务器不会留下任何关于对方状态的信息。 Cookie是Web服务器为了存储某些数据（比如用户信息）而保存在浏览器上的小型数据。浏览器会在一定时间内保存它，并在下一次向同一个服务器发送请求时附带这些数据。Cookie通常被用来进行用户会话管理（比如登录状态），保存用户的个性化信息以及记录和收集用户浏览数据以用来分析用户行为等。 在Flask中，想要在响应中添加一个cookie，最方便的方法是使用Response类提供的set_cookie() 方法。 1234567from flask import Flask, make_response...@app.route('/set/&lt;name&gt;')def set_cookie(name): response = make_response(redirect(url_for('hello'))) response.set_cookie('name', name) return response Session：安全的Cookie在编程中，session指用户会话，又称为对话，即服务器和客户端/浏览器之间或桌面程序和用户之间建立的交互活动。而在Flask中，session对象用来加密Cookie。默认情况下，它会把数据存储在浏览器上一个名为session的cookie里。 session通过密钥对数据进行签名以加密数据。因此，得先社会一个密钥。 1234567# 程序的密钥可以通过Flask.secret_key属性或配置变量SECRET_KEY设置app.secret_key = 'secret string'# 更安全的做法是把密钥写进系统环境变量或是保存在.env文件中SECRET_KEY = secret string# 然后在陈旭脚本中使用os模块提供的getenv()方法获取app.secret_key = os.getenv('SECRET_KEY', ‘secret string') HTTP进阶重定向回上一个页面要重定向回上一个页面，最关键的是获取上一个页面的URL。上一个页面的URL一般可以通过两种方法获取。 HTTP referer HTTP referer是一个用来记录请求发源地的HTTP首部字段，即访问来源。当用户在某个站点单击链接，浏览器向新链接所在的服务器发起请求，请求的数据中包含的HTTP_REFERER字段记录了用户所在的原站点URL。 1return redirect(request.referrer) 查询参数 在URL中手动加入包含当前URL的查询参数，这个查询参数一般命名为next。 12345@app.route('/foo')def foo(): return '&lt;h1&gt;Foo page&lt;/h1&gt;&lt;a href=\"%s\"&gt;Do somthing and redirect&lt;/a&gt;' % url_for('do something', next=request.full_path) return redirect(request.args.get('next')) Ajax技术发送异步请求AJAX指异步JavaScript和XML，它不是编程语言或通信协议，而是一系列技术的组合体。简单来说，Ajax基于XMLHttpRequest让我们可以在不重载页面的情况下和服务器进行数据交换。加上JavaScript和DOM，就可以在接收到数据后局部更新页面。 使用JQuery发送Ajax请求 jQuery是流行的JavaScript库，它包装了JavaScript，让我们可以通过更简单的方式编写JavaScript代码。对于Ajax，它提供了多个相关的方法，使用它可以很方便的实现Ajax操作。更重要的是，jQuery处理了不同浏览器的Ajax兼容问题，只需要编写一套代码，就可以在所有主流的浏览器正常运行。 JQuery中和Ajax相关的方法及具体用法访问http://api.jquery.com/category/ajax/ 模板在动态Web程序中，视图函数返回的HTML数据往往需要根据相应的变量（比如查询函数）动态生成。当HTML代码保存到单独的文件中时，没法再使用字符串格式化或拼接字符串的方式来在HTML代码中插入变量，这时，需要使用模板引擎（template engine），借助模板引擎，可以在HTML文件中使用特殊的语法来标记处变量，这类包含固定内容和动态部分的可重用文件称为模板（template）。 模板引擎的作用就是读取并执行模板中的特殊语法标记，并根据传入的数据将变量替换为实际值，输出最终的HTML页面，这个过程被称为渲染（rendering）。 模板基本用法（1）语句 比如 if 判断、for 循环等： {/% for %/}注：因为hexo缘故，实际使用不需要斜杠。 （2）表达式 比如字符串、变量、函数调用等 {/{ xxx.xx }/}注：因为hexo缘故，实际使用不需要斜杠。 （3）注释 {/# xxx #/}注：因为hexo缘故，实际使用不需要斜杠。 模板语法渲染模板在视图函数中，不直接使用Jinja2提供的函数，而是使用Flask提供的渲染函数render_template()。 123@app.route('/example')def example_for_render(): return render_templae('example.html', arg1=xxx, arg2=yyy) 在render_template() 函数中，首先传入模板的文件名作为参数，以关键字参数的形式传入模板中使用的变量值。其他类型的变量通过相同的方式传入。传入Jinja2中的变量值可以使字符串、列表、和字典，也可以是函数、类和类实例。 模板辅助工具上下文 内置上下文变量 Flask在模板上下文中提供了一些内置变两个，可以在模板中直接使用 ​ 标准模板全局变量 变量 说明 config 当前的配置对象 request 当前的请求对象，在已激活的请求环境下可用 session 当前的会话对象，在已激活的请求环境下可用 g 与请求绑定的全局变量，在已激活的请求环境下可用 自定义上下文 如果多个模板都需要使用同一变量，那么较好的方法是能够设置一个模板全局变量。Flask提供了一个app.context_processor()装饰器，可以用来注册模板上下文处理函数，它可以完成统一传入变量的工作。 1234567@app.context_processo()def inject_foo(): foo = 'I am foo.' return dict(foo=foo) # 等同于return &#123;'foo': foo&#125;# 直接将app.context_processor作为方法调用app.context_processor(inject_foo) 当调用render_template()函数渲染任意一个模板时，所有使用app.context_processor装饰器注册的模板上下文处理函数（包括Flask内置的上下文处理函数）都会被执行，这些函数的返回值会被添加到模板中，因此可以在模板中直接使用变量。 全局对象全局对象是指在所有的模板中都可以直接使用的对象，包括在模板中导入的模板。 内置全局函数 ​ Jinja2内置模板全局函数(部分) | 函数 | 说明 || ————————————– | ————————— || range([start,]stop[, step]) | 和python中的range()用法相同 || lipsum(n=5, html=True, min=20,max=100) | 生成随机文本（lorem ipsum） || dict(**items) | 和python中的dict()用法相同 | ​ Flask内置模板全局函数 | 函数 | 说明 || ———————- | ———————– || url_for() | 用于生成URL的函数 || get_flashed_message(0) | 用于获取flash消息的函数 | 自定义全局函数 使用app.template_global()装饰器直接将函数注册为模板全局函数 123@app.template_global()def bar(): return 'I am bar' 过滤器在Jinja2中，过滤器（filter）是一些可以用来修改和过滤变量值的特殊函数，过滤器和变量用一个竖线（管道符号）隔开，需要参数的过滤器可以像函数一样使用括号传递。 例如： 内置过滤器 Jinja2提过了许多内置过滤器，访问http://jinjia.pocoo.org/docs/2.10/template/#builtin-filters 自定义过滤器 使用app.template_filter()装饰器可以自定义过滤器 12345from flask import Markup@app.template_filter()def miscal(s): return s + Markup(' &amp;#9835;') 测试器在Jinja中，测试器（Test）是一些用来测试变量或表达式，返回值（True或False）的特殊函数。比如，number测试器用来判断一个变量或变大时是否数字。使用 is 连接变量和测试器 12345&#123;% if age is number %&#125; &#123;&#123; age * 365&#125;&#125;&#123;% else %&#125; 无效数字&#123;% endif %&#125; 内置测试器 Jinja2提供了许多内置测试器，访问http://jinjia.pocoo.org/docs/2.10/template/#list-of-builtin-tests 自定义测试器 使用app.template_test()装饰器自定义测试器 12345@app.template_test()def baz(n): if n == 'baz': return True return False 模板环境对象在jinja2中，渲染行为有jinja2.Environment类控制，所有的配置选项，上下文变量、全局函数、过滤器和测试器都存储在Environment实例上。当与Flask结合后，我们并不单独创建Environment对象，而是使用Flask创建的Environment对象，它存储在app.jinja_env属性上。 在程序中，可以使用app.jinja_env更改Jinja2设置。 模板环境中的全局函数、过滤器和测试器分别存储在Environment对象的globals、filters和tests属性中，这三个属性都是字典对象。可以直接操作这三个字典来添加相应的函数或变量。 添加自定义全局对象 123456def bar(): return 'I am bar'foo = 'I am foo'app.jinja_env.globals['bar'] = barapp.jinja_env.globals['foo'] = foo 添加自定义过滤器 1234def smiling(s): return s + ':)' app.jinja_env.filters['smiling'] = smiling 添加自定义测试器 123456def baz(n): if n == 'baz': return True return False app.jinja_env.tests['baz'] = baz 模板结构组织 局部模板 当多个独立模板总都会使用同一块HTML代码时，可以把这部分代码抽离出来，存储到局部模板中。这样一方面可以避免重复，另一方面也可以方便统一管理。 1&#123;% include &apos;xxx.html&apos; %&#125; 模板继承 Jinja2的模板继承允许定义一个基模板，把网页上的导航栏、页脚等通用内容放在基模板中，而每一个继承基模板的子模板在被渲染时都会自动包含这些部分。 为了能够让子模板方便地覆盖或插入内容到基模板中，需要在基模板中定义块(block)，在子模板中可以通过定义同名的块来执行继承操作。 模板进阶加载静态文件一个Web项目不仅需要HTML模板，还需要虚度静态文件，比如CSS、JavaScript文件、图片及音频等。在Flask程序中，默认需要将静态文件存储在与主脚本（包含程序实例的脚本）同级目录的static文件夹中。 为了在HTML文件中引用静态文件，需要使用url_for() 函数获取静态URL。Flask内置了用于获取静态文件的试图函数，端点值为static， 默认URL规则为 static/path:filename，URL变量filename是相对于static文件夹根目录的文件路径。 例如： 123&lt;img src=\"&#123;&#123; url_for('static', filename='xxx.jpg') &#125;&#125;\" &gt;&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"&#123;&#123; url_for('static', filename='styles.css') &#125;&#125;\" &gt; 使用CSS框架在编写Web程序时，手动编写CSS比较麻烦，常见的做法是使用CSS框架来为程序添加样式。CSS框架内置了大量可以直接使用的CSS样式类和JavaScript函数，使用它们可以非常快速地让程序页面变得美观和易用，同时也可以定义自己的CSS文件来进行补充和调整。 12345678&#123;% block sysles %&#125; &lt;link ref=\"stylesheet\" href=\"&#123;&#123; url_for('static', filename='css/bootstrap.min.css') &#125;&#125;\" &gt;&#123;% endblock %&#125;...&#123;% block script %&#125; &lt;script scr=\"&#123;&#123; url_for('static', filename='js/jquery.min.js') &#125;&#125;\"&gt;&lt;/script&gt; &lt;script src=\"&#123;&#123; url_fro('static', filename='js/popper.min.js') &#125;&#125;\"&gt;&lt;/script&gt;&#123;% endblock %&#125; 消息闪现Flask提供了一个非常有用的flash() 函数，它可以用来“闪现”需要显示给用户的消息。在视图函数中调用flash()函数，传入消息内容即可“闪现”一条消息。发送的消息会存储在session中，需要在模板中使用全局函数get_flashed_messages() 获取消息并将其显示出来。 123456from flask import flash@app.route('/') def just_flash(): flash('I am flash, who is looking for me.') return redirect(url_for('index')) 表单HTML表单HTML表单的具体定义和用法访问http://www.w3.org/TR/html401/interact/forms.html 使用Flask-WTF处理表单在模板中渲染表单提交表单出于安全考虑，一般使用POST方法提交表单。使用POST方法时，按照默认的编码类型，表单数据会被存储在请求主体中。 为了支持接收表单提交发送的POST请求，必须在app.route()装饰器里使用methods关键字为路由指定HTTP方法。 1234@app.route('/', methods=['GET', 'POST'])def basic(): form = LoginForm() return render_template('basic.html', form=form) 验证表单数据 客户端验证和服务器端验证 客户端验证 指在客户端（比如Web浏览器）对用户的输入值进行验证。客户端方式可以实时动态提示用户输入是否正确，只有用户输入正确后才会将表单数据发送到服务器。客户端验证可以增强用户体验，降低服务器负载。 服务器端验证 指用户把输入的数据提交到服务器，在服务器端对数据进行验证。如果验证出错，就在返回的响应中加入错误信息。 客户端验证和服务器端验证都是必不可少的。 WTForms验证机制 WTForms验证表单字段的方式是在实例化表单类时传去表单数据，然后对表单实例调用validate() 方法。 表单进阶自定义验证器在WTForms中，验证器是指在定义字段时传入validators参数列表的可调用对象。 行内验证器 12345678910from wtforms import IntegerField, SubmitFieldfrom wtforms.validators import ValidationErrorclass FortyTwoForm(FlaskForm): answer = IntegerField('The Number') submit = SubmitField() def validate_answer(form, field): # 验证器在表单类中定义 if field.data != 42: raise ValidationError('Must be 42') 当表单类总包含以“validate_字段属性名“形式命名的方法时，在验证字段数据时会同时调用这个方法来验证对应的字段，这也是为什么表单类的字段属性名不能以validate开头。 全局验证器 123456789from wtforms.validators import ValidationErrordef is_42(form, field): # 验证器在表单类外定义 if filed.data != 42: raise ValidationError('Must be 42') class FortyTwoForm(FlaskForm): answer = IntegerField('The Number', validators=[is_42]) submit = SubmitField() 文件上传在HTML中，渲染一个文件上传字段只需要将标签的type属性设为file，即。这会在浏览器中渲染陈一个文件上传字段，单机文件选择按钮会打开文件选择窗口，选择对应的文件后，被选择的文件名会显示在文件选择按钮旁边。 定义上传表单 在Python表单类中创建文件上传字段时，使用扩展Flask-WTF提供的FileField类，它继承了WTForm提供的上传字段FileField，添加了对Flask的集成。 例： 1234from flask wtf.file import FileField, FileRequired, FileAllowedclass UploadForm(FlaskForm): photo = FileField('Upload Image', validators=[FileRequired(), FileAllowed(['jpg', 'jpeg', 'png', 'gif'])]) submit = SubmitField() 渲染上传表单 在创建的upload视图里，实例化表单类UploadForm，然后传入模板： 12345@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() ... return render_template('upload.html, form=form) 12345&lt;form method=\"post\" enctype=\"multipart/form-data\"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.photo) &#125;&#125; &#123;&#123; form.submit() &#125;&#125;&lt;/form&gt; 处理上传文件 和普通的表单数据不同，当包含上传文件字段的表单提交后，上传的文件需要在请求对象的files属性（reuqest.files）中获取。 当使用Flask-WTF时，它会自动帮我们获取对应的文件对象。这里使用表单类属性的data属性获取上传文件。 123456789101112131415import osapp.config['UPLOAD_PATH'] = os.path.join(app.root_path, 'uploads')@app.route('/upload', methods=['GET', 'POST'])def upload(): form = UploadForm() if form.validate_on_submit(): f = form.photo.data filename = random_filename(f.filename) f.save(os.path.join(app.config['UPLOAD)PATH'], filename)) flash('Upload success.') session['filenames'] = [filename] return redirect(url_for('show_images')) return render_template('upload.html', form=form) 使用Flask-CKEditor集成富文本编辑器1$ pipenv install flask-ckeditor # 安装 1）实例化Flask-CkEditor提供的CkEditor类，传入程序实例 123from flask_ckeditor import CKEditorckeditor = CKEditor() 2）渲染富文本编辑器 123456789from flask_wtf import FlaskFormFrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequired, Lengthfrom flask_ckeditor import CKEditorFieldclass RichTextForm(FlaskForm): title = StringField('Title', validators=[DataRequired(), Length[1. 50]]) body = CKEditorField('Body', validators=[DataRequeired()]) submit= SubmitField('Publish') 123456789&#123;% block content %&#125;&lt;h1&gt;Integrate CKEditor with Flask-CKEditor&lt;/h1&gt;&lt;form method=\"post\"&gt; &#123;&#123; form.csrf_token &#125;&#125; &#123;&#123; form_field(form.title) &#125;&#125; &#123;&#123; form_field(form.body) &#125;&#125; &#123;&#123; form.submit &#125;&#125;&lt;/form&gt;&#123;% endblock %&#125; 单个表单多个提交按钮1234567891011121314class NewPostForm(FlaskForm): title = String('Title') ... save = SubmitField('Save') publish = SubmitField('Publish') @app.route('/xxx', methods=['GET', 'POST'])def two_submits(): form = NewPostForm() if form.validate_on_submit(): if form.save.data: .... elif form.publish.data: .... 数据库电子邮件Flask程序的自动化测试Flask程序性能优化部署FLask程序Flask的一些设计理念后续补充","categories":[{"name":"Flask","slug":"Flask","permalink":"http://yoursite.com/categories/Flask/"}],"tags":[{"name":"Web开发","slug":"Web开发","permalink":"http://yoursite.com/tags/Web开发/"},{"name":"Flask","slug":"Flask","permalink":"http://yoursite.com/tags/Flask/"}]},{"title":"Linux环境变量PATH","slug":"Linux_环境变量PATH","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:07:58.988Z","comments":true,"path":"2019/02/25/Linux_环境变量PATH/","link":"","permalink":"http://yoursite.com/2019/02/25/Linux_环境变量PATH/","excerpt":"","text":"环境变量$PATH在Linux中，执行命令时，系统会按照PATH的设置，去每个PATH定义的路径下搜索执行文件，先搜索到的文件先执行。（From：《鸟哥的LINUX私房菜》） 改变PATH直接修改$PATH值：12echo $PATH //查看当前PATH的配置路径export PATH=$PATH:/xxx1:/xxx2 //将需要的配置路径加入$PATH 等号两边没有空格，path之间用':'间隔 生效方法：立即生效 有效期限：临时改变，只对当前终端有效，关闭后恢复原来的PATH 用户局限：仅当前用户 通过修改.bashrc文件：（.bashrc文件在根目录下）12345vim .bashrc // 编辑.bashrc文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx // /xxx/xxx为需要加入的环境变量地址，等号两边无空格 生效方法：（有一下两种） 关闭当前终端窗口，重新打开一个新的终端窗口即可 输入 1source .bashrc 命令，立即生效。 有效期限：永久有效 用户局限：仅当前用户 通过修改profile文件：（profile文件在/etc目录下）12345vim /etc/profile // 编辑profile文件// 在最后一行添加：export PATH=$PATH:/xxx/xxx 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户 通过修改environment文件：（environment文件在/etc目录下）123vim /etc/environment //编辑environment文件在PATH=/.......中加入“:/xxx/xxx” 生效方法：系统重启 有效期限：永久有效 用户局限：所有用户","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"环境变量","slug":"环境变量","permalink":"http://yoursite.com/tags/环境变量/"}]},{"title":"Ubuntu环境","slug":"Ubuntu快速配置工作环境","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T08:42:11.530Z","comments":true,"path":"2019/02/25/Ubuntu快速配置工作环境/","link":"","permalink":"http://yoursite.com/2019/02/25/Ubuntu快速配置工作环境/","excerpt":"","text":"Ubuntu工作环境快速配置首先更新一下 1sudo apt update &amp;&amp; sudo apt upgrade 更换软件源详情https://blog.csdn.net/JRRRJ/article/details/81082444 将阿里源添加到sources.list中 1deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 保存退出，然后更新。 安装显卡驱动在「软件和更新」-「附加驱动」选项卡中进行选择 基础软件安装VIM1sudo apt install vim vim 个人配置.vimrc (保存在个人百度网盘快速配置Ubuntu环境文件夹) 搜狗输入法https://blog.csdn.net/fx_yzjy101/article/details/80243710 Git1sudo apt install git PyCharmhttps://blog.csdn.net/qq_15192373/article/details/81091278 ipython1sudo apt install ipython3 flask安装详情见flask官网 Typora(Markdown编辑)安装详情见Typora官网 Shutter(截图软件)详情见https://blog.csdn.net/qq_19339041/article/details/80058892 WPS先卸载LibreOffice 1sudo apt-get remove --purge libreoffice* 下载安装访问WPS官网 MySQL &amp;&amp; Redis12sudo apt install mysql-serversudo apt install redis-server WechatUbuntu 18.04 安装微信（Linux通用）","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"},{"name":"配置","slug":"配置","permalink":"http://yoursite.com/tags/配置/"}]},{"title":"django开发问题整理","slug":"django_web_开发错误整理","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:12:50.422Z","comments":true,"path":"2019/02/25/django_web_开发错误整理/","link":"","permalink":"http://yoursite.com/2019/02/25/django_web_开发错误整理/","excerpt":"","text":"在使用Django2.0进行Web开发过程中遇到的问题Django在根据models生成数据库表时报 _ init _()missing 1 required positional argument: ‘on_delete’ 原因 在django2.0后，定义外键和一对一关系的时候需要加on_delete选项，此参数为了避免两个表里的数据不一致问题，不然会报错：TypeError: _ init _() missing 1 required positional argument: ‘on_delete’ 解决方法 1234567# 以下代码报错user = models.OneToOneField(User)owner = models.ForeignKey(UserProfile)# 以下代码正确user = models.OneToOneField(User, on_delete=models.CASCADE)owner = models.ForergnKey(UserProfile, on_delete=models.CASCADE) 参数说明 on_delete有CASCADE、PROTECT、SET_NULL、SET_DEFAULT、SET()五个可选择的值。CASCADE：此值设置，是级联删除。PROTECT：此值设置，是会报完整性错误。SET_NULL：此值设置，会把外键设置为null，前提是允许为null。SET_DEFAULT：此值设置，会把设置为外键的默认值。SET()：此值设置，会调用外面的值，可以是一个函数。一般情况下使用CASCADE就可以了。 Django2.0配置Mysql数据库后执行数据迁移时报错： 报错 1django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11.None 原因 MySQLclient目前只支持到python3.4 解决方法 因为要使用python3.6，所以修改下面路径的文件： 1$ vim /home/utur/.local/lib/python3.6/site-packages/django/db/backends/mysql 将以下代码注释即可： 12if version &lt; (1, 3, 3): raise ImproperlyConfigured(\"mysqlclient 1.3.3 or newer is required; you have %s\" % Database.__version__) MySQL: django.db.utils.OperationalError:( 1698, “Access denied for user ‘roo‘@’localhost’”) with correct username and pw 详情见：https://stackoverflow.com/questions/41542045/mysql-django-db-utils-operationalerror-1698-access-denied-for-user-root 解决方法 123create user &apos;django&apos;@&apos;localhost&apos; identified by &apos;django-user-password&apos;;grant usage on *.* to &apos;django&apos;@&apos;localhost&apos;;grant all privileges on django-database-1.* to &apos;django&apos;@&apos;localhost&apos;; AttributeError: ‘str’ object has no attribute ‘decode’ 报错 执行 1python3 manage.py makemigrations 报错 123 File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/Django-2.2-py3.7.egg/django/db/backends/mysql/operations.py\", line 146, in last_executed_query query = query.decode(errors='replace')AttributeError: 'str' object has no attribute 'decode' 原因 python在bytes和str两种类型转换，所需要的函数依次是encode(),decode() 解决方法 在报错路径下 1vim operations.py 找到错误代码 1query = query.decode(errors='replace') 修改为 12query = query.encode(errors='replace')# 保存并退出 include() got an unexpected keyword argument ‘app_name’ 原因 在Django2.0版本使用url()导致，推荐使用path() 解决方法 在xxx应用下的urls.py添加app_name变量 12345678910from django.contrib import adminfrom django.conf.urls import url,includeapp_name = xxxurlpatterns = [ # 路由规则 ...]","categories":[{"name":"django","slug":"django","permalink":"http://yoursite.com/categories/django/"}],"tags":[{"name":"Web开发","slug":"Web开发","permalink":"http://yoursite.com/tags/Web开发/"}]},{"title":"爬虫基本知识","slug":"爬虫知识点","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:24:57.809Z","comments":true,"path":"2019/02/25/爬虫知识点/","link":"","permalink":"http://yoursite.com/2019/02/25/爬虫知识点/","excerpt":"","text":"HTTP基本原理 URL:Uniform Resource Identifier,统一资源标志符 URL:Universal Resource Locator,统一资源定位符 网页基础网页的组成网页可以分为三大部分——HTML、CSS和JavaScript。 HTML: HTML是用来描述网页的一种语言，全称叫作 Hyper Text Markup Language，即超文本标记语言。网页包括文字、按钮、图片和视频等各种复杂的元素，其基础=架构就是HTML。不同类型的文字通过不同类型的标签来表示。 CSS：全称叫作Cascading Style Sheets，即层叠样式表。”层叠”是指当在HTML中引用了数个样式文件，并且样式发生冲突时，浏览器能依据层叠顺序处理。”样式”指网页中文字大小、颜色、元素间距、排列等格式。 JavaScript：简称JS，是一种脚本语言。HTML和CSS配合使用，提供给用户的只是一种静态信息，缺乏交互性。我们在网页里可能会看到一些交互和动画效果，如下载进度条、提示框、轮播图等，这通常是JavaScript的功劳。它的出现使得用户与信息之间不只是浏览与显示的关系，而是实现了一种实时、动态、交互的页面功能。 爬虫的基本原理 爬取网页 爬虫首先要做的工作就是获取网页，这里就是获取网页的源代码。源代码里包含了网页的部分有用信息，所以只要把源代码获取下来，就可以从中提取想要的信息。 提取信息 获取网页源代码后，接下来就是分析网页源代码，从中提取想要的数据。 保存数据 提取信息后，一般会将提取到的数据和保存到某处以便后续使用。这里保存形式有多种多样，如可以简单保存为TXT文本或JSON文本，也可以保存到数据库，如MySQL和MongoDB等。 自动化程序 会话和Cookies 无状态HTTP：HTTP的无状态是指HTTP协议对事务处理是没有一个记忆能力的，也就是说服务器不知道客户端是什么状态。当像服务器发送请求后，服务器解析词请求，然后返回对应的响应，服务器负责完成这个过程，而且这个过程是完全独立的，服务器不会记录前后状态的变化，也就是缺乏状态记录。 会话：在Web中，会话对象用来存储特定用户会话所需要的属性及配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在会话对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当用户请求来自应用程序的Web页时，如果该用户还没有会话，则Web服务器讲自动创建一个会话对象。当会话过期或被放弃后，服务器讲终止该会话。 Cookies：Cookies指某些网站为了辨别用户身份、进行会话跟踪而存储在 用户本地终端上的数据。 Cookies字段： Name：Cookies的名称，一旦创建，名称便不可更改 Value： Cookies的值。如果值为Unicode字符，需要为字符编码。如果值为二进制数据，则需要使用BASE64编码。 Domain：可以访问该Cookies的域名 Max Age：Cookies失效的时间，单位为秒，常和Expires一起使用，通过它可以计算出其有效时间 Path：Cookies的使用路径 Size：Cookies的大小 HTTP：Cookies的httponly属性。若此属性为true，则只有在HTTP头中会带有此Cookie的信息，而不能通过document.cookie来访问Cookie。 Secure：该Cookie是否被使用安全协议传输。安全协议有HTTPS和SSL等、、 会话Cookie和持久Cookie 会话Cookie：就是把Cookie放在浏览器内存里，浏览器在关闭之后该Cookie即失效 持久Cookie：Cookie会保存到客户端的硬盘中，下次还可以继续使用，用于长久保持用户登录状态。本质是Cookie的Max Age活Expires字段决定了过期的时间。 Cookies和会话需要配合，一个处于客户端，一个处于服务端，二者共同协作，就实现了登录会话控制。 代理的基本原理 基本原理 实际上就是在本机和服务器之间搭建了一个桥，此时本机不是直接像Web服务器发起请求，而是向代理服务器发出请求，请求会发送给代理服务器，然后由代理服务器再发送给Web服务器，接着由代理服务器再把Web服务器返回的响应转发给本机。这个过程中Web服务器识别出的真实IP就不再是我们本机的IP了，成功实现了IP伪装，这就是代理的基本原理。 代理的作用 突破自身IP访问限制，访问一些平时不能访问的站点 访问一些单位或内部资源 2,提高访问速度：通常代理服务器都设置一个较大的硬盘缓冲去，当有外界的信息通过时，同时也将其保存到缓冲区，当其他用户再访问相同的信息时，则直接由缓冲区中取出信息，传给用户，以提高访问速度。 隐藏真实IP：上网者可以通过这种方法隐藏自己的IP，免受攻击。对应爬虫来说，我们代理就是为了隐藏自身的IP，防止自身的IP被封锁。 Ajax数据爬取Ajax，全称为Asynchronous JavaScript and XML，即异步的JavaScript和XML。它不是一门编程语言，而是利用JavaScript在保证页面不被刷新、页面链接不改变的情况下与服务器变换数据并更新部分网页的技术。 基本原理 发送请求 实际上就是新建了XMLHttp&amp;Request对象，然后调用onreadystatechange属性设置了监听，然后调用open()和send()方法向某个链接（也就是服务器）发送了请求。 解析内容 得到响应之后，onreadystatechange属性对应的方法便会被触发，此时利用xmlhttp的responseText属性便可取到响应内容。 渲染网页 JavaScript有改变网页内容的能力，解析完响应内容之后，就可以调用JavaScript来针对解析玩的内容对网页进行下一步处理。 验证码的识别 图形验证码（利用tesserocr库） 极验滑动验证码 模拟点击验证按钮 识别滑动缺口的位置 模拟拖动滑块 点触验证码（12306） 利用验证码服务平台辅助验证 微博宫格验证码","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/categories/爬虫/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"消息队列Kafka学习笔记","slug":"Apache_Kafka","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T08:50:18.649Z","comments":true,"path":"2019/02/25/Apache_Kafka/","link":"","permalink":"http://yoursite.com/2019/02/25/Apache_Kafka/","excerpt":"","text":"Kafka简介Kafka是一款由美国领英公司（LinkedIn）开源出来的高性能消息引擎系统（Messaging system）,其核心功能是——高性能的消息发送与高性能的消息消费。但随着Kafka的不断演进，在Kafka 0.10.0.0版本正式推出了Kafka Streams，即流式处理组件。自此Kafka正式成为了一个流式处理框架。 前置知识背景消息引擎系统消息引擎，又叫消息队列，消息中间件等。 根据维基百科的定义，企业消息引擎系统（EMS）是企业发布的一组规范。公司使用这组规范实现在不同系统之间传递语义准确的消息。在实际使用场景中，消息引擎系统通常以软件接口为主要形式，实现了松耦合的异步式数据传递语义。 消息引擎范型根据维基百科定义，一个消息引擎范型是一个基于网络的架构范型，描述了消息引擎系统的两个不同的子部分是如何互连且交互的。如果把消息引擎系统的这两个子系统比喻成两座城市，那么传输协议就是需要铺设的沥青公路，而引擎范型决定了来往穿梭与这两座城市的路线。 最常见的两种消息引擎范型是消息队列模型和发布/订阅模型。 消息队列（message queue）模型是基于队列提供消息传输服务的，多用于进程间通信以及线程间通信。该模型定义了消息队列、发送者和接收者，提供了一种点对点的消息传递方式，即发送者发送每条消息到队列的指定位置，接收者从指定位置获取消息。每条消息由一个发送者生产出来，且只被一个消费者处理。 发布/订阅模型(publish/subscribe),它有主题（topic）的概念：一个topic可以理解为逻辑语义相近的消息的容器。这种模型定义了类似于生产者/消费者这样的角色，即发布者和订阅者。发布者将消息生产出来发送到指定的topic中，所有订阅了该topic的订阅者都可以接收到该topic下的所有消息。 Kafka术语消息既然Kafka的核心功能就是消息引擎，那么对消息的设计日然是首当其冲的事情。Kafka在消息设计时特意避开了繁重的Java堆上内存分配，直接使用紧凑二进制字节数组ByteBuffer而不是独立的对象，因此至少能够访问多一倍的可用内存。 省去padding，java对对象保存的大开销以及可能的页缓存。 topic和partiiton从概念上来说，topic只是一个逻辑概念，代表了一类消息，也可以认为是消息被发送到的地方。通常可以使用topic来区分实际业务，比如业务A使用一个topic，业务B使用另一个topic。 Kafka中的topic通常都会被多个消费者订阅，出于性能的考量，Kafka并不是topic-message的两级结构，而是采取了topic-partition-message的三级结构来分散负载。从本质上来说，每个Kafka topic都由若干个partition组成。 topic是由多个partition组成的，而Kafka的partition是不可修改的有序消息队列，也可以说是有序的消息日志。每个partition都有自己专属的partition号。用户对partition唯一能做的操作就是在消息序列的尾部追加写入消息。partition上的每条消息都会被分配一个唯一的序列号-该序列号被称为位移（offset）。位移信息可以唯一定位到某partition下的一条消息 offset实际上，Kafka消费者也有位移（offset）的概念，但这两个offset属于不同的概念。 每条消息在某个partition的位移是固定的，但消费该partition的消费者的位移会随着消费进度不断前移，但不能超过该分区最新一条消息的位移。 从本质上看，Kafka中的一条消息其实就是一个&lt;topic,partition,offset&gt;三元组（tuple），通过该元组，可以在Kafka集群中找到位移对应的那条消息。 replica为了实现高可靠性，通过冗余机制——备份多份日志。这些备份日志在Kafka中被称为副本（replica），它们存在的唯一目的就是防止数据丢失。 副本分为两类：领导者副本（leader replica）和追随者副本（follower replica）。follower replica是不能提供服务给客户端的，它只是被动地向领导者副本（leader replica）获取数据，一旦leader replica所在的broker宕机，Kafka会从剩余的replica中选举出新的leader继续提供服务。 ISRISR的全称是 in-sync replica，就是与leader replica保持同步的replica集合。 Kafka为partition动态维护一个replica集合。该集合中的所有replica保存的消息日志都与leader replica保护同步状态。只有这个集合中的replica才能被选举为leader，也只有该集合中所有replica都接收到了同一条消息，Kafka才会将该消息置于“已提交”状态，即认为这条消息发送成功。Kafka承诺只要这个集合中至少存在一个replica，那些”已提交“状态的消息就不会丢失。 Kafka使用场景 消息传输 网站行为日志追踪 审计数据收集 日志收集 Event Sourcing 流式处理 Kafka设计原理broker端设计架构broker是Apache Kafka最重要的组件，本质上它是一个功能载体（或服务载体），承载了绝大多数的Kafka服务。事实上，大多数的消息队列框架都有broker或已知类似的角色。一个broker通常是以服务器的形式出现的。 消息设计 消息格式 V2版本分为消息和消息集合两个维度，不过消息集合的提法被消息批次所取代。V2版本中，它有一个专门的属于：RecordBatch。 V2版本消息格式 “可变长度”表示Kafka会根据具体的值来确定到底需要几字节保存。为了在序列化时降低使用的字节数，V2版本借鉴了Google ProtoBuffer中的Zig-zag编码方式，使得绝对值较小的整数占用字节数较少的字节。 消息batch CRC值从消息层面被移除，放入batch这一层 PID、producer epoch和序列号等消息都是0.11.0.0版本为了实现幂等性producer和支持事务而一如的。 通过使用mirco-batch，批次地发送消息，能大幅度地提高Kafka的吞吐量。 集群管理Kafka是分布式的消息引擎集群环境，支持自动化的服务发现与成员管理。依赖于Apache Zookeeper实现，每当一个broker启动，它会将自己注册到Zookeeper下的一个节点。 首先，每个broker在Zookeper下注册节点的路径是chroot/brokers/ids/&lt;broker.id&gt;。如果没有配置chroot，则路径是/broker/ids/&lt;broker.id&gt;。 其次，broker向Zookeeper中的注册消息以JSON格式保存。 12345678910111213141516&#123; \"version\": 4, \"host\": \"loacalhost\", \"port\": 9092, \"jmx_port\": 9999, \"timestamp\": 1499737197, \"endpoints\": [ \"CLIENT\"://host1:9092\", \"REPLICATION://HOST1:9093\" ], \"listener_security_protocol_map\": &#123; \"CLIENT\": \"SSL\", \"REPLICATION\": \"PLAINTEXT\" &#125;, \"rack\": \"dc1\"&#125; 最后，Zookeeper临时节点的生命周期和客户端会话绑定。如果客户端会话失效，该临时节点就会自动被清除掉。Kafka正是利用Zookeeper临时节点来管理broker生命周期的。broker启动时在Zookeeper中创建对应的临时节点，同时还会创建一个监听器（listener）监听该临时节点的状态；一旦broker启动后，监听器会自动同步整个集群消息到该broker上；而一旦broker崩溃，它与Zookeeper的会话就会失效，导致临时节点被删除，监听器被触发，然后处理broker崩溃的后续事宜。这就是Kafka管理集群及其成员的主要流程。 副本与ISR设计一个Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在Kafka中被称为副本（replica）。 follower副本同步 起始位移（base offset）：表示该副本当前所含第一条消息的位移 高水印值（high watermark，HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader分区的HW值决定了副本中已提交消息的范围，也确定了consumer能够获取消息的消息上限。任何一个副本对象的HW值一定不大于其LEO值。Kafka对leader副本和follower副本的HW值更新机制是不同的。 日志末端位移（log end offset，LEO）：副本日志中下一条待写入消息的offset。所有副本都需要维护自己的LEO信息。只有ISR中的所有副本都更新了对应的LEO之后，leader副本才会向右移动HW值表明消息写入成功。Kafka对leader副本和follower副本的LEO值更新机制也是不同的。 水印（watermark）和leader epoch 水印被称为高水印或高水位，通常被用在流水式处理领域，以表征元素或时间在基于时间层面上的进度。在Kafka中，水印的概念与时间无关，而与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。 LEO更新机制 follower follower副本不停地向leader副本所在broker发送FETCH请求，一旦获取消息，便写入自己的日志中进行备份。 Kafka设计了两套follower副本LEO属性：一套LEO属性保存在follower副本所在broker的缓存上；另一套LEO值保存在leader副本所在broker的缓存上。换句话说，leader副本所在broker的缓存上保存了该分区下所有follower副本的LEO属性值。 follower副本端LEO更新 每当在底层日志新写入一条消息，其LEO值就会加1. leader副本端的follower副本LEO更新 一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO。 leader 每当在底层日志新写入一条消息，其LEO值就会加1. HW更新机制 前面说过，leader broker上保存了一套follower副本的LEO以及它自己的LEO。当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO，并选择最小的LEO值作为HW值。 图解Kafka备份原理 基于水印机制的缺陷 数据丢失：使用HW值来确定备份进度时其值的更新是在下一轮RPC中完成的。延迟一轮FETCH请求更新HW的值的设计使得followerHW值是异步延迟更新的，若在这个过程中leader发生变更，那么称为新leader的follower的HW值就有可能是过期的，使得clients端认为成功提交的消息被删除了。 数据不一致/数据离散：leader端log和follower端的log数据不一致 leader epoch 上述两个问题的根本原因在于HW值被用于衡量副本备份的成功与否，以及在出现崩溃时作为日志截断的依据，但HW值的更新是异步延迟的，特别是需要额外的FETCH请求处理流程才能更新，这中间发生的任何崩溃都可能导致HW值的过期 leader epoch，实际上是一对值(epoch，offset)。epoch表示leader的版本号，从0开始，当leader变更过1次时，epoch就会+1，而offset则对应于该epoch版本的leadre写入第一条消息的位移。 通信协议 协议设计 所谓通信协议，就是实现client-server间或server-server间数据传输的一套规范。Kafka通信协议是基于TCP之上的二进制协议，这套协议提供的API表现为服务于不同功能的多种请求类型以及对应的相应。所有类型的请求和响应都是结构化的，有不同的初始类型构成。 常见请求类型 PRODUCE请求 FETCH请求 METADATA请求 请求处理流程 clients端 broker端 controller设计 controller概览 在一个Kafka集群中，某一个broker会被选举出来承担特殊的角色，即控制器。一如controller就是用来管理和协调Kafka集群的。具体来说，就是管理集群中所有分区的状态并执行相应的管理操作。 controller管理状态 controller维护的状态分为两类：每台broker上的分区副本和每个分区的leader副本信息。从维度上看，这些状态可分为副本状态和分区状态。 副本状态机 分区状态机 controller职责 更新集群元数据信息 创建topic 删除topic 分区重分配 preferred leader副本选举 topic分区扩展 broker加入集群 broker崩溃 受控关闭 controller leader选举 broker请求处理 Reactor模式 Kafka broker处理请求的模式就是Reactor设计模式。Reactor设计模式是一种事件处理模式，旨在处理多个输入源同时发送过来的请求。Reactor模式中的服务处理器或分发器将入站请求按照多路复用的方式分发到对应的请求处理器。 Kafka broker请求处理 Kafka broker请求处理实现了Reactor模式。在Kafka中，每个broker都有一个acceptor线程和若干个processor线程。processor线程的数量是可以配置的。 producer端设计架构producer端基本数据结构 ProducerRecord 一个ProducerRecord封装了一条待发送的消息（或称为记录）。 ProducerRecord由5个字段构成: topic：该消息所属的topic partition：该消息所属的分区 key：消息key value：消息体 timestamp：消息时间戳 RecordMetadata 该数据结构表示Kafka服务器端返回给客户端的消息的元数据 offset：消息在 分区日志中的位移信息 timesstamp：消息时间戳 topic/partition checksum：消息CRC32码 serializedKeySize：序列化后消息的key字节数 serializedValueSize：序列化后消息value字节数 工作流程如果把producer统一看成一个盒子，那么整个producer端的工作原理便如图所示。大体来说，用户首先构建待发送的消息对象ProducerRecord，然后调用KafkaProducer#send方法进行发送。KafkaProducer接收到消息后首先对其进行序列化，然后结合本地缓存的元数据信息一起发送给partitioner去确定目标分区，最后追加写入内存中的消息缓冲池。 调用KafkaProducer.send执行的操作： 序列化+计算目标分区 追加写入消息缓冲区 Sender线程预处理及消息发送 consumer端设计架构consumer group 状态机新版本consumer依赖于broker端的组协调者coordinator来管理组内的所有consumer实例并负责把分配方案发到每个consumer上。分配方案由组内的leader consumer根据指定的分区分配策略指定的。 分区分配的操作在consumer端执行而非broker端的好处： 便于维护与升级：如果在broker端实现，那么分配策略的变动势必要重启整个Kafka集群。生产环境中重启服务器的代价是很高的。 便于实现自定义策略：不同的策略由不同的逻辑实现。coordinator端代码不容易实现灵活可定制的分配逻辑 解耦了组管理与分区分配，coordinator负责组管理工作，而consumer程序负责分区分配。 Kafka为每个consumer group定义了5个状态： Empty：表明group下没有任何active consumer，但可能包含位移信息。 PreparingRebalance：该状态表明group正在准备进行group rebalance。 AwaitingSync：该状态表明所有成员都已经加入组并等待leader consumer发送分区分配方案。 Stable：该状态表明group开始正常消费。此时group必须响应clients发送过来的任何请求。 Dead：该状态表明group已经彻底废弃，group内没有任何成员并且group的所有元数据都已被删除。 实现精确一次处理语义(exactly-once semanties, EOS)clients端常见的3种消息交付语义： 最多一次（ai most once）：消息可能丢失也可能被处理，但最多只会被处理一次 至少一次（at last once）：消息不会丢失，但可能被多次处理 精确一次（exactly once）：消息被处理且只会被处理一次。 幂等性producer（idempotent producer）幂等性producer是Apache Kafka 0.11.0.0版本用于实现EOS的一个利器。若一个操作执行多次的结果与只运行一次的结果是相同的，那么称该操作为幂等操作。引入幂等producer表示它的发送操作是幂等。瞬时的发送错可能导致produecer端出现重试，同一个消息被producer发送多次，但在broker端这条消息只会被写入日志一次。 幂等性producer的设计思路类似于TCP的工作方式。发送到broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和TCP不同的是，这个序列号不会被丢弃，相反Kafka会把它们保存在底层日志中，这样即使分区的leader副本挂掉，新选出来的leader broker也能执行消息去重工作。 事务（transaction）对事务的支持是Kafka实现EOS的第二个利器。引入事务使得clients端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。 处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中。重要的是不论是发送还是消费，Kafka都能保证它们是原子性，即所有的写入操作幺妹全部成功，要么全部失败。 Kafka为实现事务要求应用程序必须提供一个唯一的id来表征事务。这个id被称为事务id，它必须在应用程序所有的会话上是唯一的。 PS：未完待续，后续深入学习再做补充","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"Redis设计与实现（笔记）","slug":"Redis设计与实现（笔记）","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:21:00.276Z","comments":true,"path":"2019/02/25/Redis设计与实现（笔记）/","link":"","permalink":"http://yoursite.com/2019/02/25/Redis设计与实现（笔记）/","excerpt":"","text":"Redis总体认识Redis是一个速度非常快的非关系远程内存数据库，它不仅性能强劲，而且具有复制特性以及为解决问题而省的独一无二的数据模型。 数据结构与对象简单动态字符串（SDS）Redis没有直接使用C语言传统的字符串表示（以空字符结尾的字符数组），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将SDS用作Redis的默认字符串表示。 SDS的定义每个sds.h/shshdr结构表示一个SDS值： 1234567891011struct sdshdr&#123; //记录buf数组中已使用字节的数量 //等于SDS所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[];&#125;; SDS遵循C字符串以空字符结尾的惯例，保存空字符串的1字节空间不计算在SDS的len属性里面，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由SDS函数自动完成的，所以这个空字符对于SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS可以直接重用一部分C字函数库里面的函数 SDS与Ｃ字符串的区别 常数复杂度获取字符串长度 获取一个Ｃ字符串的长度，操作复杂度为Ｏ(N)。 获取一个SDS的长度复杂度为O(1)，因为SDS在len属性中记录了SDS本身的长度。 通过使用SDS而不是C字符串，确保了获取字符串长度的工作不会成为Redis的性能瓶颈。 杜绝缓冲区溢出 与C字符串不同，SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当SDS API需要对SDS进行修改时，API会先检查SDS的空间是否满足修改的需求，如果不满足的话，API会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作。 减少修改字符串时带来的内存重新分配次数 空间预分配，用于优化SDS的字符串增长操作：当需要进行空间扩展时，程序不仅会为SDS分配修改时所必须要的空间，还会为SDS分配额外的未使用空间。 如果对SDS进行修改之后，SDS的长度将小于1MB，那么程序分配和len属性同样大小的未使用空间，这时SDS len属性将和free属性的值相同。 如果对SDS进行修改之后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间.。 惰性空间释放，用于优化SDS的字符串缩短操作：当API需要缩短SDS保存的字符串时，程序并不立即使用内存重新分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。与此同时，SDS也提供了相应的API，可以在有需要时真正地释放SDS的未使用空间。所以不用担心惰性空间释放策略会造成内存浪费。通过使用惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。 二进制安全 所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。 通过使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。 兼容部分C字符串 链表链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。Redis构建了自己的链表实现。链表在Redis中的应用非常广泛，比如列表键的底层实现之一就是链表。除了链表键之外，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还是用了链表来保存多个客户端的状态信息，以及使用链表来构建客户端输出缓冲区。 链表和链表节点的实现每个链表节点使用一个adlist.h/listNode结构来表示 12345678typedef struct listNode&#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;&#125;listNode; 多个listNode可以通过prev和next指针组成双端链表。 使用adlist.h/list来持有链表的话，操作起来会更方便： 1234567891011121314typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含的节点数量 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值对比函数 int (*match)(void *ptr, void *key);&#125;list; Redis的链表实现的特性可以总结如下； 双端 无环 带表头指针和表尾指针 带链表长度计数器 多态：链表节点使用void *指针来保存节点值，并且可以通过list结构的dup、match、free三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。 字典字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。 字典在Redis中的应用相当广泛，比如Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。除了用来表示数据库之外，字典还是哈希键的底层实现之一。 字典的实现哈希表Redis字典使用的哈希表有dict.h/dictht结构定义： 1234567891011typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size； //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //哈希表已有节点的数量 unsigned long used;&#125;dictht; 哈希表节点哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对： 123456789101112typedef struct dictEntry&#123; //键 void *key; //值 union( void *val; uint64_t u64; int64_t s64; )v; //指向下个哈希表节点，形成链表 struct dictEntry *next;&#125;dictEntry; 字典Redis中的字典由dict.h/dict结构来表示： 123456789101112typedef struct dict&#123; //类型特定函数 dictType *type; //私有数据 void *privdata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx; /*rehashing not in progress if rehashidx == -1 */&#125;dict; type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数。 privdata属性则保存了需要传给那些类型特定函数的可选参数。 1234567891011121314typedef struct dictType&#123; //计算哈细致的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(keyDup)（void *privdata, const void *key); //复制值的函数 void *(valueDup)（void *privdata, const void *obj); //对比键的函数 int (*keyCompare)（void *privdata, const void *key1, const void *key2); //销毁键的函数 void (*keyDestructor)（void *privdata, void *key); //销毁值的函数 void (*valDestructor)（void *privdata, void *obj);&#125;dictType; ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。 哈希算法当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis使用MurmurHash2算法来计算键的哈希值。 解决键冲突Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接骑起来，这就要解决了键冲突的问题。 渐进式rehash为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。 扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成。最终结果是将ht[0]包含所有键值对都迁移到ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。 但是为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。 渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作摊到对字典的每个添加、删除、查找和更新操作之上，从而避免了集中式rehash而带来的庞大计算量。 跳跃表跳跃表（skiplist)是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表支持平均O(logN)，最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树媲美，并且因为跳跃表的实现比平衡树更为简单，所以有不少程序都用跳跃表来代替平衡树。 Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。 每个跳跃表节点的层高都是1至32之间的随机数 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。 跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。 整数集合整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。 每个intset.h/inttset结构表示一个整数集合： 12345678typedef struct intset&#123; //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];&#125; contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。 contents数组的真正类型取决于encoding属性的值 升级当新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要进行升级（upgrade)，然后才能将新元素添加到整数集合里面。 升级分为三部进行： 根据新元素的类型，扩展整数集合底层数组的孔家你大小，并为新元素分配空间 将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素继续放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性不变。 将新元素添加到底层数组里面。 升级的好处： 提升整数集合的灵活性，因为C语言是静态类型语言，为了避免类型错误，通常不会将两种不同类型的值放在同一个数据结构里面。 尽可能地节约内存，只在有需要的时候进行升级。 压缩列表压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是是小整数值，要么就是长度比较长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。 压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含 任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 压缩列表和压缩列表节点的构成 对象Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每个对象都用到了至少一种数据结构。 通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，可以针对不同的使用场景，为对像设置多种不同的数据结构实现，从而优化对象在不同场景的使用效率。 Redis的对象系统还实现了基于引用技术技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被释放；另外，Redis还通过引用技术技术实现了对象共享机制，在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。 Redis的对象带有访问时间记录信息。 Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据结构有关的三个属性分别是type属性、encoding属性和ptr属性： 12345678910typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4' //指向底层实现数据结构的指针 void *ptr: //... &#125;robj; 编码转换 字符串对象 列表对象 哈希对象 集合对象 有序集合对象 内存回收因为C语言并不具备自动内存回收功能，所以Redis在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制，通过这一机制，程序可以 通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。 对象共享对象的引用计数属性还带有对象共享的作用。目前来说，Redis会在初始化服务器时，创建一万个字符串对象，这些对象 包含了从0到9999的所有整数值，当需要用到这些字符串对象时，服务器就会使用这些共享对象，而不是新创建对象。 单机数据库的实现数据库Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库： 1234567struct redisServer&#123; //.. //服务器的数据库数量 int dbnum； //一个数组，保存着服务器中的所有数据库 redisDb *Db;&#125;; 在服务器内部，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个指向redisDb结构的指针。 123456typedef struct redisClient&#123; //... //记录客户端当前正在使用的数据库 redisDb *db； //...&#125;redisClient redisClient.db指针指向redisServer.db数组的其中一个元素，而被指向的元素就是客户端的目标数据库。 数据库键空间Redis是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个redis.h/redisDb结构表示，其中redisDb结构中的dict字典保存了数据库中的所有键值对，这个字典被称为键空间（key space）： 12345678typedef struct redisDb&#123; //... //数据库键空间，保存着数据库中的所有键值对 dict *dict; //过期字典，保存着键的过期时间 dict *expores; //...&#125;redicDb; 键空间和用户所见的数据库是直接对应的： 键空间的键也就是数据库的键，每个键都是一个字符串对象。 键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种对象。 所有针对数据库的操作，增删改查，实际上都是对键空间字典进行操作来实现的。 其他键空间操作 维护操作 读取键之后，服务器会更新键空间的命中（hit）次数或键空间不命中（miss）次数。 更新键的LRU（最后一次使用）时间。 键过期，删除 键被WATCH命令监视，修改后将键标记为脏（dirty），进行通知 键修改后，按配置发送相应的数据库通知 设置键的生存时间或过期时间 过期键删除策略惰性删除+定期删除 惰性删除惰性删除策略对CPU时间来说是友好的：程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行 ，并且删除的目标仅限与当前处理的键，这个策略不会在删除其他无关的过期键上花费任何CPU时间。 惰性删除的缺点是：它对内存是最不友好的，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会被释放。有内存泄露的危险。 定期删除定期删除策略每隔一段时间执行一次过期键操作，并通过限制删除键执行的时长和频率来减少删除操作对CPU时间的影响。 惰性删除策略的实现过期键的惰性删除策略由db.c/expirIfNeeded函数实现。 定期删除策略的实现过期键的定期删除策略由redis.c/activeExpireCycle函数实现，每当Redis服务器周期性操作redis.c/serverCron函数执行时，activeExpireCycle就会被调用，它在规定时间内，分多次遍历服务器中的多个数据库，从数据库的expires字典中随机检查一部分建的过期时间，并删除其中的过期键。 其余重点 执 行SAVE命令或者BGSAVE命令所产生的新RDB未见不会包含已经过期的键 执行BGREWRITEAOF命令所产生的重写AOF未见不会包含已经过期的键 当一个过期键被删除之后，服务器会追加一条DEL命令到现有AOF文件的末尾 当主服务器删除一个过期键之后，它会向所有从服务器发送一条DEL命令，显式地删除过期键 从服务器及时发现过期键也不会自作主张地删除它，而是等待主节点发来DEL命令，这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。 当Redis命令对数据库进行修改之后，服务器会根据配置向客户端发送数据库通知。 RDB持久化因为Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。 为了解决这个为题，Redis提供了RDB持久化功能，这个功能可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失。 RDB持久化既可以手动执行，也可以根据服务器配置选项定期执行。 RDB文件的创建与载入 SAVE命令：阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求： 12redis&gt; SAVE //等待直到RDB文件创建完毕OK BGSAVE命令：派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求： 12redis&gt; BGSAVE //派生子进程，并由子进程创建RDB文件Background saving started RDB文件是一个经过压缩的二进制文件，由多个部分组成 对不同类型的键值对，RDB文件会使用不同的方式来保存它们 AOF持久化除了RDB持久化功能之外，Redis还提供了AOF（Append Only FIle）持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据状态的。 #### AOF持久化的实现分为三步 命令追加 当AOF持久化功能处于打开时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾 AOF文件的写入与同步 Redis的服务器进程就是一个事件循环（loop），这个循环中的文件时间负责接收客户端的命令请求，以及客户端发送命令回复，而时间事件则负责执行serverCron函数这样需要定时运行的函数。 因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲去里面，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面。 AOF文件的载入与数据还原因为AOF文件里包含了重建数据库状态所需的所有写命令，所以服务器只要读入并重新执行一遍AOF文件里面保存的命令，就可以还原服务器关闭之前的数据库状态。 AOF后台重写为了解决数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。 事件Redis服务器是一个事件驱动程序，服务器需要处理以下两类事件： 文件事件（fileevent）：Redis服务器通过套接字与客户端（或者其他Redis服务器）进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端（或者其他服务器）的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列网络通信操作。 时间事件（time event）：Redis服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。 文件事件Redis基于Reactor模式开发了自己的网络事件处理其器：这个处理器被称为文件事件处理器（flie event handler）： 文件事件处理器使用I/O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应到（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作像相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 文件事件处理器既实现了高性能的网络通信模型，又可以很好地与Redis服务器中其他同样以单线程方式运行的模块进行对接，这保持了Redis内部单线程设计的简单性 时间事件Redis的时间事件分为以下两类： 定时事件：让一段程序在指定的时间之后执行一次。 周期性事件：让一段程序每隔指定时间就执行一次。 服务器将所有时间事件都放在一个无序链表（不按when属性的大小排序）中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。 事件的调度与执行因为服务器中同时存在文件事件和时间事件两种事件类型，所以服务器必须对这两种事件进行调度。 客户端 服务器状态结构使用clients链表链接多个客户端状态，新添加的客户端状态会被放到链表的末尾 客户端状态的flags属性使用不同标志来表示客户端的角色，以及客户端当前所处的状态 输入缓冲区记录了客户端发送的命令请求，这个缓冲去的大小不能超过1GB 命令的参数和参数个数会被记录在客户端状态的argv和argc属性里面，而cmd属性则记录了客户端要执行命令的实现函数 客户端有固定大小缓冲和可变大小缓冲区两种缓冲区可用，其中固定大小缓冲区的最大大小为16KB，而可变大小缓冲去的最大大小不能超过服务器设置的硬性限制值。 输出缓冲区限制值有两种，如果输出缓冲区的大小超过了服务器设置的硬性设置，那么客户端会被立即关闭；除此之外，客户端在一定时间内，一直超过服务器设置的软性限制，那么客户端也会被关闭 当一个客户端通过网络连接连上服务器时，服务器会为这个客户端创建相应的客户端状态。网络连接关闭、发送了不合协议格式的命令请求、成为CLIENT KILL命令的目标、空转时间超时、输出缓冲区的大小超出限制，以上这些原因都会造成客户端被关闭 处理Lua脚本的伪客户端在服务器初始化时创建，这个客户端会一直存在，直到服务器关闭 载入AOF文件时使用的为2客户端在载入工作开始时动态创建，载入工作完毕之后关闭 服务器 一个命令请求从发送到完成主要包括以下步骤： 客户端将命令请求发送给服务器； 服务器读取命令请求，并分析出命令参数 命令执行器根据参数查找命令的实现函数，然后执行实现函数并得出命令回复 服务器将命令回复返回给客户端 serverCron函数默认每隔100毫秒执行一次，它的工作主要包括更新服务器状态信息，处理服务器接收的SIGTERN信号，管理客户端资源和数据库状态，检查并执行持久化操作等等 服务器从启动到能够处理客户端的命令请求需要执行以下步骤： 初始化服务器状态 载入服务器配置 初始化服务器数据结构 还原数据库状态 执行事件循环 多机数据库的实现SentinelSentinel（哨岗、哨兵）是Redis的高可用性（high availability）解决方案：由一个或多个Sentinel实例（instance）组成的Sentinel系统（system)可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。 后续深入学习再作补充","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"}]},{"title":"深入理解Linux内核","slug":"Linux内核（学习笔记）","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:18:46.221Z","comments":true,"path":"2019/02/25/Linux内核（学习笔记）/","link":"","permalink":"http://yoursite.com/2019/02/25/Linux内核（学习笔记）/","excerpt":"","text":"Linux 的优势 Linux是免费的。除硬件之外，无需任何花费就能安装一套玩整的Linux系统 Linux的所有成分都可以充分地定制。通过内核编译选项，你可以选择自己真正需要的特征来定制内核。 Linux可以运行在低档、便宜的硬件平台上。 Linux是强大的，由于充分挖掘了硬件部分的特点，使得Linux系统速度非常块，Linux的主要目标是效率 Linux的开发者都是非常出色的程序员。 Linux内核非常小，而且紧凑。 Linux与很多通用操作系统高度兼容。 Linux有很好的技术支持 内核控制路径（Kernel control path）表示内核处理系统调用、异常或中断所执行的指令序列。 最简单的情况下，CPU从第一条指令到最后一条指令顺序地执行内核控制路径。然而当下述事件之一发生时，CPU交错执行内核控制路径： 运行在用户态的进程调用一个系统调用。 当运行一个内核控制路径时，CPU检测到一个异常（例如，访问一个不在RAM中的页）。 当CPU正在运行一个启用了中断的内核控制路径时，一个硬件中断发生。 在支持抢占式调度的内核中，CPU正在运行，而一个更高优先级的进程加入就绪队列，则中断发生。 同步内核路径 非抢占式内核，当进程在内核态执行时，它不能被任意挂起，也不能被另一个进程代替。因此，在单处理器系统上，中断或异常处理程序不能修改的所有内核数据结构，内核对它们讷的访问都是安全的 禁止中断，单处理器系统上的另一种同步机制是：在进入一个临界区之前禁止所有硬件中断，离开时再重新启动中断。 信号量,信号量仅仅是与一个数据结构相关的计数器。所有内核线程在试图访问这个数据结构之前，都要检查这个信号量。可以把每个信号量看成一个对象，其组成如下： 一个整数变量 一个等待进程的链表 两个原子方法：down()和up() 自旋锁,如果修改数据结构所需的时间比较段，那么，信号量可能是低效的。为了检查信号量，内核必须把进程插入到信号量链表中，然后挂起它。因为这两种操作比较费时，完成这些操作时，其他的内核控制路径可能已经释放了信号量。在这些情况下，多处理器操作系统使用了自旋锁（spin lock）。自旋锁与信号量非常相似，但没有进程链表，当一个进程发现锁被另一个进程锁着时，它就不停地“旋转”，执行一个紧凑的循环指令直到锁打开。当然，自旋锁在单处理器环境下是无效的。 内存寻址随机访问存储器（RAM）的使用 所有的Unix操作系统都将RAM毫无疑义地划分为两部分，其中若干兆字节专门用于存放内核映像（也就是内核代码和内核静态数据结构）。RAM的其余部分通常有虚拟内存系统来处理，并且用在以下三种可能的方面： 满足内核对缓冲去、描述符及其他动态内核数据结构的请求 满足进程对一般内存区的请求及对文件内存映射的请求 借助于高速缓存从磁盘及其他缓冲设备获得较好的性能 内核内存分配器 内存内核分配其（Kernel Memory Allocator, KMA）是一个子系统，它试图满足系统中所有部分对内存的请求。 基于各种不同的算法技术，已经提出了集中KMA，包括： 资源图分配算法（allocator） 2的幂次方空间链表 McKusick-Karels分配算法 伙伴（Buddy）系统 Mach的区域（Zone）分配算法 Dynix分配算法 Solaris的Slab分配算法 物理内存布局 在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用（或者因为它们映射硬件设备I/O的共享内存，或者因为相应的页框含有BIOS数据）。 内核将下列页框记为保留： 在不可用的物理地址范围内的页框。 含有内核代码和已初始化的数据结构的页框 保留页框中的页绝不嫩被动态分配或交换到磁盘上。 进程进程链表 Linux的进程链表是一个双向链表，进程链表把所有进程的描述符链接起来。每个task_struct结构都包含一个list_head类型的tasks字段，这个类型的prev和next字段分别指向前面和后面的task_struct元素。 进程链表的头是init_task描述符，它是所谓的0进程（process 0）或swapper进程的进程描述符。init_task的tasks.prev字段指向链表中最后插入的进程描述符tasks字段。 TASK_RUNNING状态的进程链表 当内核寻找一个新进程在CPU上运行时，必须只考虑可运行进程（即处在TASK_RUNNING状态的进程）。 早期的Linux版本把所有的可运行进程都放在同一个叫作运行队列（runqueue）的链表中，由于维持链表中的进程按优先级排序开销过大，因此，早期的调度程序不得不为选择“最佳”可运行进程而扫描整个队列。 Linux 2.6实现的运行队列有所不同。其目的是让点读程序能在固定的时间内选出“最佳”可运行程序，与队列中可运行的进程数无关。提高调度程序运行速度的诀窍是建立多个可运行进程链表，每种进程优先权对应一个不同的链表。这是一个通过使数据结构更复杂来改善性能的典型例子：调度程序的操作效率的确更高了，但运行队列的链表却为此而被拆分成140(0-139）个不同的队列。——空间换时间 进程间的关系 程序创建的进程具有父/子关系。如果一个进程创建多个子进程时，则子进程之间具有兄弟关系。 图3-4显示了一组进程间的亲属关系。进程P0接连创建了P1，P2，和P3。进程P3又创建了P4。 pidhash表及链表 在几种情况下，内核必须能从进程的PID到处对应的进程描述符指针。 顺序扫描进程链表并检查进程描述符的pid字段是可行但相当低效的。为了加速查找，引入了4个散列表。需要4个散列表是因为进程描述符包含了表示不同类型pid的字段，而且每种类型的PID需要它自己的散列表。 正如计算机科学的基础课程所阐述的那样，散列（hash）函数并不总能确保PID与表的索引一一对应。两个不同的PID散列（hash）到相同的表索引称为冲突（colliding） Linux利用链表来处理冲突的PID：每一个表项是由冲突的进程描述符组成的双向链表。 具有链表的散列法比从PID到表索引的线性转换更优越，这是因为在任何给定的实例中，系统中的进程数总是远远小于32768（所允许的进程PID的最大数）。如果在任何给定的实例中大部分表项都不使用的话，那么把表定义为32768项会是一种存储浪费。 由于需要跟踪进程间的关系，PID散列表中使用的数据结构非常复杂。 PID散列表的数据结构解决了所有这些难题，因为他们可以为包含在一个散列表中任意PID号定义进程链表。 等待队列 等待队列在内核中有很多用途，尤其用在中断处理、进程同步及定时。等待队列表示一组睡眠的进程，当某一条件变为真时，由内核唤醒它们。 等待队列由双向链表实现，其元素包括指向进程描述符的指针。因为等待队列是由中断处理和主要内核函数修改的，因此必须对其双向链表进行保护以免对其进行同事访问，因为同事访问会导致不可预测的后果。 注：雷鸣般兽群问题：即唤醒多个进程只为了竞争一个资源，而这个资源只能有一个进程访问，结果是其他进程必须再次回去睡眠。 非互斥进程插入等待队列链表的第一个位置。互斥进程插入等待队列链表的最后一个位置。 因为所有的非互斥进程总是在双向链表的开始位置，而所有的互斥进程在双向链表的尾部，所以函数总是先唤醒非互斥进程然后再唤醒互斥进程，如果有进程存在的话。 进程切换 硬件上下文 进程恢复执行前必须转股寄存器的一组数据称为硬件上下文（hardware context)。硬件上下文是进程可执行上下文的一个子集。在Linux中，进程硬件上下文的一部分存放在TSS段，而剩余部分存放在内核太堆栈中。 任务状态段(TSS) 80x86体系结构包括了一个特殊的段类型，叫任务状态段（Task State Segment, TSS)来存放硬件上下文。尽管Linux并不使用硬件上下文切换，但是强制它为系统中每个不同的CPU创建一个TSS。 thread字段 在每次进程切换时，被替换进程的硬件上下文必须保存在别处。不能像Intel原始设计那样把它保存在TSS中，因为Linux为每个处理器而不是为每个进程使用TSS。 因此，每个进程描述符包含一个类型为thread_struct的thread字段，只要进程被切换出去，内核就把其硬件上下文保存在这个结构中。 执行进程切换 从本质上说，每个进程切换由两步组成： 切换页全局目录以安装一个新的地址空间 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包括CPU寄存器。 创建进程 Unix操作系统紧紧依赖进程创建来满足用户的需求。 传统的Unix操作系统以统一的方式对待所有的进程：子进程复制父进程所拥有的资源。这种方法使进程的创建非常慢且效率低，因为子进程需要拷贝父进程的整个个、地址空间。 现代Unix内核通过引入三种不同的机制解决了这个问题： 写时复制技术允许父子进程读相同的物理页。只要两者中有一个试图写一个物理页，内核就把这个页的内容拷贝到一个新的物理页，并把这个新的物理页分配给正在写的进程。 轻量级进程允许父子进程共享进程在内核的很多数据结构，如页表、打开文件表及信号处理。 vfork()系统调用创建的进程能共享其父进程的内存地址空间。为了防止父进程重写子进程需要的数据，阻塞父进程的执行，一直到到子进程退出或执行一个新的程序为止。 clone()、fork()及vfork()系统调用 在Linux中、轻量级进程是由名为clone()的函数创建的。 实际上，clone()是在C语言库中定义的一个封装（wrapper）函数，它负责建立新轻量级进程的堆栈并且调用对编程者隐藏的clone()系统调用。 传统的fork()系统调用和vfork()系统调用在Linux中也是用clone()实现的。 内核线程 因为一些系统进程只运行在内核太，所以现代操作系统把它们的函数委托给内核线程（kernel thread），内核线程不受不必要的用户态上下文的拖累。 进程 0 所有进程的祖先叫作进程0，idle进程，或因为历史的原因叫作swapper进程，它是在Linux的初始化阶段从无到有创建的一个内核线程。这个祖先进程使用下列静态分配的数据结构（所有其他进程的数据结构都是动态分配的）： 存放在init_task变量中的进程描述符，由INIT_TASK宏完成对它的初始化 存放在init_thread_union变量中的thread__info描述符和内核堆栈，由INIT_THREAD_INFO宏完成对它们的初始化。。 由进程描述符指向的下列表： init_mm init_fs init_files init_signals init_sighand 主内核页全局目录存放在swapper_pg_dir中。 start_kernel()函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程（一般叫作init进程）。新创建内核线程的PID为1，并与进程0共享每个进程所有的内核数据结构。此外，当调度程序选择到它时，init进程开始执行init（）函数。 在多处理器系统中，每个CPU都有一个进程0.只要打开机器电源，计算机的BIOS就启动某一个CPU，同时禁用其他CPU。运行在CPU0还是上的swapper进程初始化内核数据结构，然后激活其他的CPU，并通过copy_process()函数创建另外的swapper进程，把 0 传递给新创建的swapper进程作为它们的新PID。 进程 1 由进程 0 创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init。结果，init内核线程变为一个普通进程，且拥有自己的每进程（per-process）内核数据结构。在系统关闭之前，init进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。 其他内核线程 Linux使用很多其他内核线程。其中一些在初始化阶段创建，一直运行奥系统关闭，而其他一些在内核必须执行一个任务时“按需”创建，这种任务在内核的执行上下文中得到很好的执行。 进程删除Unix允许进程查询内核以获得其父进程的PID，或者其任何子进程的执行状态。 为了遵循这些设计选择，不允许Unix内核在进程一终止后就丢弃包含在进程描述符字段中的数据。只有父进程发出了与被终止的进程相关的wait（）类系统调用之后，才允许这样做。这就是引入僵死状态的原因：尽管从技术上来说进程已死，但必须保存它的描述符，直到父进程得到通知。 如果父进程在子进程结束之前结束会发生什么情况呢？在这种情况下，系统中会到处是僵死的进程，而且它们的进程描述符永久占据这RAM。所以这必须强迫所有的孤儿进程成为init进程的子进程来解决这个问题。这样，init进程在用wait（）类系统调用检查其合法的子进程终止时，就会撤销僵死的进程。 对僵死进程的处理有两种可能的方式： 如果父进程不需要接收来自子进程的信号，就调用do_exit()。 如果已经给父进程发送了一个信号，就调用wait4（）或waitpid（）系统调用。 中断和异常中断通常分为同步（synchronous）中断和异步（asynchronous）中断： 同步中断是指当指令执行时有CPU控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后CPU才会发出中断。 异步中断是由其他硬件设备依照CPU时钟信号随机产生的。 在Intel微处理器手册中，把同步和异步中断分别称为异常（exception）和中断（interrupt）。 中断 可屏蔽中断（maskable interrupt） 非屏蔽中断（nonmaskable interrupt） 异常 故障（fault） 陷阱（trap） 异常中止（abort） 编程异常（programmed exception) 中断描述符表 中断描述符表（Interrupt Descriptor Table, IDT）是一个系统表，它与灭一个中断或异常向量相联系，每一个向量在表中有相应的中断或异常处理程序的入口地址。 IDT包含三种类型的描述符。 这些描述符是： 任务门（task_gate) ​ 当中断信号发生时，必须取代当前进程的那个进程的TSS选择符存放在任务门中。 中断门（interrupt gate) ​ 包含段选择符和中断或异常处理程序的段内偏移量。当控制权转移到一个适当的段时， 处理器清IF标志，从而关闭将来会发生的可屏蔽中断。 陷阱门（Trap gate） ​ 与中断门相似，只是控制权传递到一个适当的段时处理器不修改IF标志。 Linux利用中断门处理中断，利用陷阱门处理异常 中断和异常处理程序的嵌套执行 每个中断或异常都会引起一个内核控制路径，或者说代表当前进程在内核态执行单独的指令序列。内核控制路径可以任意嵌套：一个中断处理程序可以被另一个中断处理程序“中断”，因此引起内核控制路径的嵌套执行。如图所示。 允许内核控制路径嵌套执行必须付出代价，那就是中断处理程序必须永不阻塞，换句话说，中断处理程序运行期间不能发生进程切换。事实上，嵌套的内核控制路径恢复执行时需要的所有数据都存放在内核态堆栈栈中，这个栈毫无疑义的属于当前进程。 一个中断处理程序既可以抢占其他的中断处理程序，也可以抢占异常处理程序。相反，异常处理程序从不抢占中断处理程序。 基于以下两个主要原因，Linux交错执行内核控制路径： 为了提高可编程中断控制器和设备控制器的吞吐量。 为了实现一种没有优先级的中断模型。简化了内核代码，提高了内核的可移植性。 IRQ在多处理器系统上的分发 Linux遵循对称多处理模型（SMP），这意味着，内核从内本质上对任何一个CPU都不应该有 偏爱。因而，内核试图以轮转的方式把来自硬件设备的IRQ信号在所有CPU之间分发。因此，所有CPU服务于I/O中断的执行时间片几乎相同。 在系统启动的过程中，引导CPU执行setup_IO_APIC_irqs()函数来初始化I/O APIC芯片。芯片的中断重定向表的24项被填充，以便根据“最低优先级”模式把来自I/O硬件设备的所有信号都传递给系统中的每个CPU。此外，在系统启动期间，所有的CPU都执行setup_local_APIC()函数，该函数处理本地APIC的初始化。特别是，每个芯片的任务优先级寄存器（TPR）都初始化为一个固定的值，这就意味着CPU愿意处理任何类型的IRQ信号，而不管优先级。Linux内核启动后再也不修改这个值。 因为所有的任务优先级寄存器都包含相同的值，因此，有所CPU总是具有相同的优先级。为了突破这种约束，多APIC系统使用本地APIC仲裁优先级寄存器中的值。因为这样的值在每次中断后都自动改变，因此，IRQ信号就公平地在所有CPU之间分发。 简而言之，当硬件设备发生了一个中断信号时，多APIC系统就选择其中的一个CPU，并把该信号传递给相应的本地APIC，本地APIC又依次中断它的CPU。这个事件不通报给其他所有的CPU。 内核同步可以把内核看作是不断对请求进行响应的服务器，这些请求可能来自在CPU上执行的进程，也可能来自发出中断请求的外部设备。这个类比强调内核的各个部分并不是严格按照顺序依次执行的，而是采用交错执行的方式。因此，这些请求可能引起竞争条件,而我们必须采用适当的同步机制对这种情况进行控制。 内核抢占 如果进程执行内核函数时，即它在内核态运行时，允许发生内核切换（被替换的进程是正执行内核函数的进程），这个内核就是抢占的。 使内核可抢占的目的是减少用户态进程的分派延迟（dispatch latency），即从进程变为可执行状态到它实际开始运行之间的时间间隔。 内核使用的各种同步技术 每CPU变量 最好的同步技术是把设计不需要同步的内核放在首位。最简单也是最最重要的同步技术包括把内核变量声明为每CPU变量（per-cpu variable)。每CPU变量主要是数据结构的数组，系统的每个CPU对应数组的一个元素。 一个CPU不应该访问与其它CPU对应的数组元素，另外，它可以随意读或修改它自己的元素而不用担心出现竞争条件。但是，这也意味着每CPU变量基本上只能在特殊情况下使用，也就是当它确定在系统的CPU上的数据在逻辑上是独立的时候。 每CPU的数组元素在主存中被排列以使每个数据结构存放在硬件高速缓存的不同行，因此，对每CPU数组的并发访问不会导致高速缓存行的窃用和失效。 此外，在单处理器和多处理器系统中，内核抢占都可能使每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。 原子操作 若干汇编语言指令具有“读—修改—写”类型——也就是说，它们访问内存单元两次，第一次读原值，第二次写新值。 避免由于“读—修改—写”指令引起的竞争条件的最容易的方法，就是确保这样的操作在芯片级是原子的。任何一个这样 的操作都必须以单个指令执行，中间不嫩中断，且避免其他的CPU访问同一存储器单元。这些很小的原子操作（atomic opreations)可以建立在其他更灵活机制的基础之上以创建临界区。 操作码前缀是lock字节（0xf0）的“读—修改—写”汇编语言指令即使在多处理器系统中也是原子的。当控制大暖检测到这个前缀时，就“锁定”内存总线，直到这条指令执行完成为止。因此，当枷锁的指令执行时，其他处理器不能访问这个内存单元。 优化和内存屏障 当使用优化的编译器时，编译器可能重新安排汇编语言指令以使寄存器以最优的方式使用。此外，现代CPU通常并行地执行若干条指令，且可能重新安排内存访问。这种重新排序可以极大地加速程序的执行。 然而，当处理同步时，必须避免指令重新排序。如果发放在同步原语之后的一条指令在同步原语本身之前执行，事情很快就会变得失控。事实上，所有的同步原语起优化和内存屏障的作用。 优化屏障（memory barrier）原语保证编译程序不会混淆放在原语操作之前的汇编语言指令和放在原语操作之后的汇编语言指令。在Linux中，优化屏障就是barrier（）宏，它展开为asm volatile(“:::”memory”)。volatile关键字禁止编译器把asm指令与程序中的其他指令重新组合。memory关键字强制编译器假定RAM中的所有内存单元已经被汇编语言指令修改。因此，编译器不能使用存放在CPU寄存器中的内存单元的值来优化asm指令前的代码。 内存屏障（memory barrier）原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，内存屏障类似于防火墙，让任何汇编语言指令都不能通过。 Linux使用六个内存屏障原语： rm() rmb() wmb() smp_mb() smp_rmb() smp_wmb() 这些原语也被当做优化屏障，因为我们必须保证编译程序不在屏障前后移动汇编语言指令。内存屏障原语的实现依赖与系统的体系机构。在80x86微处理器上，如果CPU支持lfence汇编语言指令，就把rmb（）宏展开为asm volatile（”lfence”)，否则就展开为asm volatile（”lock;addl $0,0(%%esp)”:::”memory”)。 自旋锁 一种广泛使用的同步技术是加锁（locking）。当内核控制路径必须访问共享数据结构或进入临界区时，就需要为自己获取一把”锁“。 自旋锁（spin lock）是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁”开着“，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径”锁着“，就在周围”旋转“，反复执行一条紧凑的循环指令，直到锁被释放。 自旋锁的循环指令表示”忙等“。及时等待的内核控制路径无事可做（除了浪费时间），它也在CPU上保持运行。不过自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时间片段。 一般来说，由自旋锁所保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这种锁本身不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。在自旋锁忙等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进程替代。 在Linux中，每个自旋锁都用spin_lock_t结构表示，其中包含两个字段： slock：该字段表示自旋锁的状态，值为1表示”未加锁“状态，而任何负数和0都表示”加锁“状态。 break_lock：表示进程正在忙等自旋锁（只在内核支持SMP和内核抢占的情况下使用该标志）。 读/写自旋锁 读/写自旋锁的引入是为了增加内核的并发能力。只要没有内核控制路径对数据结构进行修改，读/写自旋锁就允许多个内核控制路径同时读同一数据结构。如果一个内核控制路径想对这个结构进行写操作，那么它必须首先获取读/写锁的写锁，写锁授权独占访问这个资源。当然，允许对数据结构并发读可以提高系统性能。 顺序锁 Linux2.6中引入了顺序锁（seqlock），它与读/写自旋锁非常相似，只是它为写着赋予了较高的优先级：事实上，即使在读者正在读的时候也允许写者继续运行。这种策略的好处是写者永远不会等待（除非另一个写者正在写），缺点是有些时候读者不等不反复多次读相同的数据直到它获得有效的副本。 每个顺序所都是包括两个字段seqlock_t结构：一个类型为spin_lock_t的lock字段和一个整型的sequence字段，第二个字段是一个顺序计数器。**每个读者都必须在读数据前后两次读顺序计数器，并检查两次读到的值是否相同，如果不相同，说明新的写者已经开始写并增加了顺序计数器，因此暗示读者刚读到的数据是无效的。 读—拷贝—更新（RCU） 读—拷贝—更新（RCU）是为了保护在多数情况下被多个CPU读的数据结构而设计的另一种同步技术。RCU允许多个读者和写者并发执行。而且，RCU是不适用锁的，就是说，它不适用被所有CPU共享的锁或计数器，在这一点上与读/写自旋锁和顺序锁（由于高速缓存行窃用和失效而有很高的开销）相比，RCU具有更大的优势。 其关键思想包括限制RCU的范围： RCU只保护被动态分配并通过指针引用的数据结构 在被RCU保护的临界区中，任何内核控制路径都不能失眠。 信号量 实际上，Linux提供两种信号量： 内核信号量，由内核控制路径使用 System V IPC信号量，由用户态进程使用 内核信号量类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。然而，当内核控制路径试图获取内核信号量所保护的忙资源时，相应的进程被挂起。只有在资源被释放时，进程才再次变为可运行的。因此，只有可以睡眠的的函数才能获取内核信号量，中断处理程序和可延迟函数都不能使用内核信号量。 禁止本地中断 确保一组内核语句被当做一个临界区处理的主要机制之一就是中断禁止。即使当硬件设备产生了一个IRQ信号时，中断禁止也让内核控制路径继续执行，因此，这就提供了一中有效的方式 ，确保中断处理程序访问的数据结构也受到保护。然而禁止本地中断并不保护运行在另一个CPU上的中断处理程序对数据结构的并发访问，因此，在多处理器系统上，禁止本地中断经常与自旋锁结合使用。 禁止和激活可延迟函数 禁止可延迟函数在一个CPU上执行的一种简单方式就是禁止在那个CPU上的中断。因为没有中断处理程序被激活，因此，软中断操作就不能异步地开始。 总结 技术 说明 使用范围 每CPU变量 在CPU之间复制数结构 所有CPU 原子操作 对一个计数器原子地”读—修改—写“的指令 所有CPU 内存屏障 避免指令重新排序 本地CPU或所有CPU 自旋锁 加锁时忙等 所有CPU 信号量 加锁时阻塞等待（睡眠） 所有CPU 顺序锁 基于访问计数器的锁 所有CPU 本地中断的禁止 禁止单个CPU上的中断处理 本地CPU 本地软中断的禁止 禁止单个CPU上的可延迟函数处理 本地CPU 读—拷贝—更新（RCU) 通过指针而不是锁来访问共享数据结构 所有CPU 定时测量 Linux计时体系结构 Linux必定执行于定时相关的操作。例如，内核周期性地： 更新自系统启动以来所经过的时间 更新时间和日期 确定当前进程在每个CPU上已运行了多长时间，如果已经超过了分配给它的时间，则抢占它。 更新资源使用统计数 检查每个软定时器的时间间隔是否已到。 进程调度Linux与任何分时系统一样，通过一个进程到另一个进程的快速切换，达到表面上看来多个进程同时执行的神奇效果。 Linux的调度基于分时技术：多个进程以”时间多路服用“方式运行，因为CPU的时间被分成片”（slice）”，给每个可运行进程分配一片。如果当前运行进程的时间片或时限到期时，该进程还没有运行完毕，进程切换就可以发生。 传统上把进程分类为“I/O受限（I/O-bound）“或”CPU受限（CPU-bound）“。前者频繁地使用I/O设备，并花费很多时间等待I/O操作的完成；而后者则需要大量CPU时间的数据计算应用程序。 另一种分类法把进程分为三类： 交互式进程（interactive process） 这些进程经常与用户进行交互，因此，要花很多时间等待键盘和鼠标操作。当接受了输入后，进程必须被很快唤醒，否则用户将发现系统反应迟钝。典型的交互式程序是命令shell、文本编辑程序及图形应用程序。 批处理进程（batch process) 这些进程不必与用户交互，因此经常在后台运行。典型的批处理进程是程序设计语言的编译程序、数据库搜索引擎及科学计算。 实时进程（real-time process） 这些进程有很强的调度需要。这样的进程绝不会被低优先级的进程阻塞，它们应该有一个很短的响应时间，更重要的是，响应时间的变化应该很小。典型的实时程序有视频和音频应用程序、机器人控制程序及从物理传感器上收集数据的程序。 调度算法每个Linux进程总是按照下面的调度类型被调度： SCHED_FIFO 先进先出的实时进程 SCHED_RR 时间片轮转的实时进程 SCHED_NORMAL 普通的分时进程 普通进程的调度每个普通进程都有它自己的静态优先级，调度程序使用静态优先级来估计系统中这个进程与其他普通进程之间调度的程度。内核用从100（最高优先级）到139（最低优先级）的数表示普通进程的静态优先级。 基本时间片： 与优先级低的进程相比，通常优先级较高的进程获得更长额CPU时间片。 实时进程的调度每个实时进程都与一个实时优先级相关，实时优先级是一个范围从1（最高优先级）～99（最低优先级）的值。调度程序总是让优先级高的进程运行，换句话说，实时进程运行的过程中，禁止低优先级进程的执行。与普通进程相反，实时进程总是被当成活动进程。 只有在下述事件之一发生时，实时进程才会被另外一个进程取代： 进程被另外一个具有更高实时优先级的实时进程抢占 进程执行了阻塞操作并进入睡眠 进程停止或被杀死 进程通过调用系统调用sched_yield()自愿放弃CPU 进程是基于时间片轮转的实时进程，而且用完了它的时间片。 内存管理​","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"内核","slug":"内核","permalink":"http://yoursite.com/tags/内核/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"架构学习","slug":"架构学习","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:31:05.005Z","comments":true,"path":"2019/02/25/架构学习/","link":"","permalink":"http://yoursite.com/2019/02/25/架构学习/","excerpt":"","text":"定义架构软件架构指软件系统的顶层结构 相关概念 系统是一群关联个体组成，这些“个体”可以是“子系统”、”模块“、”组件“等；架构需要明确系统包含哪些”个体“。 系统中的个体需要根据某种规则运作，架构需要明确个体运作和协作的规则。 架构是顶层设计；框架是面向编程或配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体。 架构设计的真正目的整个软件技术发展的历史，其实就是一部与”复杂度“斗争的历史，架构的出现也不例外。简而言之，架构是为了应对软件系统负责度而提出的一个解决方案。架构设计的主要目的是为了解决软件系统复杂度带来的问题。 架构是为了应对软件系统复杂度而提出的一个解决方案。架构即（重要）决策，是在一个有约束的盒子里去求解或接近最合适的解。这个有约束的盒子是团队经验、成本、资源、进度、业务所处阶段等所编织、掺杂在一起的综合体（人、财、物、时间、事情等）。架构各有千秋，但是存在恰当的架构用在合适的软件系统中，而这些就是决策的结果。 需求驱动架构。在分析设计阶段，需要考虑一定的人力与时间去”跳出代码，总揽全局“，为业务和IT技术之间搭建一座”桥梁”。 架构设计处于软件研制的前期，一方面，越是前期，就越早发现问题，修改的代价也就越低；另一方面，软件实施后期若有架构上的修改，也需要付出更多的代价。 复杂度的来源复杂度的来源主要有6个。 高性能 对性能孜孜不倦的追求是整个人类技术不断发展的根本驱动力。软件系统中高性能带来的复杂度主要体现在两个方面，一方面是单台计算机内部为了高性能带来的复杂度；另一方面是多态计算机集群为了高性能带来的复杂度。 单机复杂度 计算机内部复杂度最关键的地方就是操作系统，操作系统是软件系统的运行环境，操作系统的复杂度决定了软件系统的复杂度。 操作系统和性能最相关的是进程和线程。 集群的复杂度 通过大量机器来提升性能，并不仅仅是增加机器这么简单，让多台机器配合起来达到高性能的目的，是一个复杂的任务。 任务分配 任务分配的意思是指每台机器都可以处理完成的业务任务，不同的任务分配到不同的机器上执行。 需要增加任务分配器 任务分配器和真正的业务服务器之间有连接和交互 任务分配器需要增加分配算法。例如，轮询算法、按权重分配、或按照负载进行分配。 任务分解 简单的系统更加容易做到高性能 可以针对单个任务进行扩展 高可用 维基百科的定义 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。 这个定义的关键在于“无中断”，但恰好难点也在“无中断”上面，因为无论是单个硬件还是单个软件，都不可能做到无中断，硬件会出故障，软件会老化；硬件会逐渐老化，软件会越来越复杂的庞大。 除了硬件和软件本质上无法做到”无中断“，外部环境导致的不可用更加不可避免、不受控制。例如、断点、水灾、的证。 系统的高可用方案五花八门，但万变不离其宗，本质上都是通过“ 冗余 ”来实现高可用。通俗点来讲，就是一台机器不够就两台，两台不够就四台;一个机房可能断电，那就部署两个机房;一条通道可能故障，那就用两条，两条不够那就用三条(移动、电信、联通一起上)。高可用的 “ 冗余 ” 解决方案，单纯从形式上来看，和之前的高性能是一样的，都是通过增加更多机器来达到目的，但其实本质上是有根本区别的: 高性能增加机器目的在于“扩展”处理性能;高可用增加机器目的在于“冗余”处理单元 。 通过冗余增强了可用性，但同事也带来了复杂性。 计算高可用 存储高可用 对于需要存储数据的系统来说，整个系统的高可用设计关键点和难点就在于“存储高可用”。存储与计算相比，有一个本质上的区别: 将数据从一台机器搬到到另一台机器，需要经过线路进行传输 。线路传输的速度是毫秒级别，同一机房内部能够做到几毫秒;分布在不同地方的机房，传输耗时需要几十甚至上百毫秒。例如，从广州机房到北京机房，稳定情况下 ping 延时大约是 50ms ，不稳定情况下可能达到 1s 甚至更多。 综合分析，无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题;但如果完全不做冗余，系统的整体高可用又无法保证，所以存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响 。 高可用状态决策 无论是计算高可用还是存储高可用，其基础都是“ 状态决策 ”，即系统需要能够判断当前的状态是正常还是异常，如果出现了异常就要采取行动来保证高可用。如果状态决策本身都是有错误或者有偏差的，那么后续的任何行动和处理无论多么完美也都没有意义和价值。但在具体实践的过程中，恰好存在一个本质的矛盾: 通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确。 独裁式 协商式 民主式 可扩展性 可扩展性指系统为了应对将来需求变化而提供的一种扩展能力，当有新的需求出现时，系统不需要或者仅需要少量修改就可以支持，无须整个系统重构或者重建。由于软件系统固有的多变性，新的需求总会不断提出来，因此可扩展性显得尤其重要。在软件开发领域，面向对象思想的提出，就是为了解决可扩展性带来的问题;后来的设计模式，更是将可扩展性做到了极致。得益于设计模式的巨大影响力，几乎所有的技术人员对于可扩展性都特别重视。设计具备良好可扩展性的系统，有两个基本条件: 正确预测变化 、 完美封装变化 。但要达成这两个条件，本身也是一件复杂的事情。 预测变化 不能对每个设计点都考虑可扩展性 不能完全不考虑可扩展性 所有的预测都存在出错的可能性 应对变化 将”变化“封装在一个”变化层”，将不变的部分封装在一个独立的“稳定层”。无论是变化层依赖稳定层，还是稳定层依赖变化层都是可以的，需要根据具体业务情况来设计。 系统需要拆分出变化层和稳定层 需要设计变化层和稳定层之间的接口 设计模式的核心就是，封装变化，隔离可变性。 低成本 低成本给架构设计带来的复杂度主要体现在，往往只有“创新”才能达到低成本的目标。。这里的“创新”既包括开创一个全新的技术领域(这个要求对绝大部分公司太高)，也包括引入新技术，如果没有找到能够解决自己问题的新技术，那么就真的需要自己创造新技术了。 安全 安全本身是一个庞大而又复杂的技术领域，并且一旦出问题，对业务和企业形象影响非常大。 功能安全 从实现的角度来看，功能安全更多地是和具体的编码相关，与架构关系不大。 架构安全 如果说功能安全是“防小偷”，那么 架构安全就是“防强盗” 。强盗会直接用大锤将门砸开，或者用炸药将围墙炸倒;小偷是偷东西，而强盗很多时候就是故意搞破坏，对系统的影响也大得多。因此架构设计时需要特别关注架构安全，尤其是互联网时代，理论上来说系统部署在互联网上时，全球任何地方都可以发起攻击。 规模 规模带来复杂度的主要原因就是“量变引起质变” ，当数量超过一定的阈值后，复杂度会发生质的变化。 功能越来越多，导致复杂度指数级上升 数据越来越多，系统复杂度发生质变 架构设计三原则 合适原则 合适原则宣言：“合适优于业界领先”。 真正优秀的架构都是在企业当前人力、条件、业务等各种约束下设计出来的，能够合理地将资源整合在一起并发挥出最大功效，并且能够快速落地。这也是很多 BAT 出来的架构师到了小公司或者创业团队反而做不出成绩的原因，因为没有了大公司的平台、资源、积累，只是生搬硬套大公司的做法，失败的概率非常高。 简单原则 简单原则宣言：“简单优于复杂”。 软件领域的复杂性体现在两个方面： 结构的复杂性 结构复杂的系统几乎毫无例外具备两个特点： 1）组成复杂系统的组件数量更多 2）同时这些组件之间的关系也更加复杂 逻辑的复杂性 演化原则 演化原则宣言：“演化优于一步到位”。 首先 ，设计出来的架构要满足当时的业务需要。 其次，架构要不断地在实际应用过程中迭代，保留优秀的设计，修复有缺陷的设计，改正错误的设计，去掉无用的设计，使得架构逐渐晚上。 第三，当业务发生变化时，架构需要扩展、重构，甚至重写；代码也许会重写，但有价值的经验、教训、逻辑、设计等却可以在新架构中延续。 架构师在进行架构设计时需要牢记这个原则，时刻提醒自己不要贪大求全，或者盲目照搬大公司的做法。应该认真分析当前业务的特点，明确业务面临的主要问题，设计合理的架构，快速落地以满足业务需要，然后在运行过程中不断完善架构，不断随着业务演化架构。即使是大公司的团队，在设计一个新系统的架构时，也需要遵循演化的原则，而不应该认为团队人员多、资源多，不管什么系统上来就要一步到位，因为业务的发展和变化是很快的，不管多牛的团队，也不可能完美预测所有的业务发展和变化路径。 合适优于先进&gt;演化优于一步到位&gt;简单优于复杂。 架构设计流程 识别复杂度 设计备选方案 评估和选择备选方案 详细方案设计 架构模式在具体的实践过程中，为了更快、更好地设计出优秀的架构，除了掌握这些基础知识外，还需要掌握业界已经成熟的各种架构模式。大部分情况下，我们做架构设计主要都是基于已有的成熟模式，结合业务和团队的具体情况，进行一定的优化或者调整;即使少部分情况我们需要进行较大的创新，前提也是需要对已有的各种架构模式和技术非常熟悉。 高性能架构模式高性能数据库集群高性能数据库集群的第一种方式是 “ 读写分离 ” ，其本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力;第二种方式是“分库分表”，既可以分散访问压力，又可以分散存储压力。 读写分离读写分离原理 读写分离的基本原理是将数据库读写操作分散到不同的节点上 ，下面是其基本架构图。 读写分离的基本实现是： 数据库服务器搭建主从集群，一主一从、一主多从都可以。 数据库主机负责读写操作，从机只负责读操作 数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。 业务服务器将写操作发给数据库主机，将读操作发给数据库从机。 读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度: 主从复制延迟和分配机制 。 复制延迟 主从复制延迟会带来一个问题:如果业务服务器将数据写入到数据库主服务器后立刻( 1 秒内)进行读取，此时读操作访问的是从机，主机还没有将数据复制过来，到从机读取数据是读不到最新数据的，业务上就可能出现问题。 解决主从复制延迟的集中常见的方法： 写操作后的读操作指定发给数据库主服务器 读从机失败后再读一次主机 关键业务读写操作全部指向主机，非关键业务采用读写分离。 分配机制 将读写操作区分开来，然后访问不同的数据库服务器，一般有两种方式：程序代码封装和中间件封装。 程序代码封装 程序代码封装指在代码中抽象一个数据访问层，实现读写操作分离和数据库服务器连接的管理 中间件封装 中间件封装指的是独立一套系统出来，实现读写操作和数据库服务器连接的管理。中间件对业务服务器提供SQL兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。 读写分离分散了数据库读写操作的压力，但没有分散存储压力，当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在以下几个方面： 数据量太大，读写的性能会下降，即使有索引，索引也会变得恨到，性能同样会下将。 数据文件会变得很大，数据库备份和恢复费需要耗费很长时间。 数据文件越大，极端情况下丢失数的风险越高。 分库分表业务分库 业务分库指的是按照业务模块将数据分散到不同的数据库服务器。 例如，一个简单的电商网站，包括用户、商品、订单三个业务模块，我们可以将用户数据、商品数据、订单数据分开放到三台不同的数据库服务器上，而不是将所有数据都放在一台数据库服务器上。 虽然业务分库能够分散存储和访问压力，但同时也带来了新的问题。 join操作问题 业务分库后，原本在同一个数据库中的表分散到不同的数据库表中，导致无法使用SQL的join查询。 事务问题 原本在同一个数据库中不同的表可以在用一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改。虽然数据库厂商提供了一些分布式事务的解决方案，但性能实在太低，与高性能存储的目标是相违背的。 成本问题 业务分库同时也带来了成本的代价，本来 1 台服务器搞定的事情，现在要 3 台，如果考虑备份，那就是 2 台变成了 6 台。 分表 将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。 单表数据拆分有两种方式：垂直分表和水平分表 高性能NoSQL关系数据库存在以下缺点： 关系数据库存储的是行为记录，无法存储数据结构 关系数据库的schema扩展很不方便 关系数据库在大数据场景下I/O较高 关系数据库的全文搜索功能较弱 针对上述问题，分别 针对上述问题，分别诞生了不同的 NoSQL 解决方案，这些方案与关系数据库相比，在某些应用场景下表现更好。但世上没有免费的午餐， NoSQL 方案带来的优势，本质上是牺牲ACID中的某个或者某几个特性， 因此我们不能盲目地迷信NoSQL是银弹，而应该将NoSQL作为SQL的一个有力补充 ，NoSQL != No SQL，而是NoSQL = Not Only SQL。常见的 NoSQL 方案分为 4 类。 K-V存储:解决关系数据库无法存储数据结构的问题，以Redis为代表。 文档数据库:解决关系数据库强schema约束的问题，以MongoDB为代表。 列式数据库:解决关系数据库大数据场景下的I/O问题，以HBase为代表。 全文搜索引擎:解决关系数据库的全文搜索性能问题，以Elasticsearch为代表。 高性能缓存架构缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理是将可能重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统。 缓存的架构设计要点： 缓存穿透 缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据。 缓存雪崩 缓存雪崩是指当缓存失效（过期）后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算,这个处理步骤耗时几十毫秒甚至上百毫秒。而对于一个高并发的业务系统来说,几百毫秒内可能会接到几百上千个请求。由于旧的缓存已经被清除,新的缓存还未生成,并且处理这些请求的线程都不知道另外有一个线程正在生成缓存,因此所有的请求都会去重新生成缓存,都会去访问存储系统,从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统,严重的会造成数据库宕机,从而形成一系列连锁反应,造成整个系统崩溃。 缓存热点 虽然缓存系统本身的性能比较高,但对于一些特别热点的数据,如果大部分甚至所有的业务请求都命中同一份缓存数据,则这份数据所在的缓存服务器的压力也很大。例如,某明星微博发布 “ 我们 ” 来宣告恋爱了,短时间内上千万的用户都会来观。缓存热点的解决方案就是复制多份缓存副本,将请求分散到多个缓存服务器上,减轻缓存热点导致的单台缓存服务器压力 。 单服务器高性能模式站在架构师的角度，需要特别关注高性能架构的设计。高性能架构设计主要集中在两方面： 尽量提升单服务器的性能，将单服务器的性能发挥到极致 如果单服务器无法支撑性能，设计服务器集群方案 除了以上两点，最终系统能否实现高性能，还和具体的实现及编码相关。但架构设计是高性能的基础，如果架构设计没有做到高性能，则后面的具体实现和编码能提升的空间是有限的。形象地说，架构设计决定了系统性能的上限，实现细节决定了系统性能的下限。 单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点： 服务器如何管理连接 服务器如何处理请求。 以上两个设计点最终都和操作系统的I/O模型及进程模型相关。 I/O模型：阻塞、非阻塞、同步、异步 进程模型：单进程、多进程、多线程 PPC与TPCPPC是Process Per Connection的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的UNIX网络服务器所采用的模型。基本的流程图是： TPC 是 Thread Per Connection 的缩写,其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。与进程相比,线程更轻量级,创建线程的消耗比进程要少得多;同时多线程是共享进程内存空间的,线程通信相比进程通信更简单。因此, TPC 实际上是解决或者弱化了 PPC fork 代价高的问题和父子进程通信复杂的问题。 Reactor与Proactor单服务器高性能的PPC和TPC模式，它们的优点是实现简单，缺点是都无法支撑高并发的场景。 Reactor PPC 模式最主要的问题就是每个连接都要创建进程(为了描述简洁,这里只以 PPC 和进程为例,实际上换成 TPC 和线程,原理是一样的),连接结束后进程就销毁了,这样做其实是很大的浪费。为了解决这个问题,一个自然而然的想法就是资源复用,即不再单独为每个连接创建进程,而是创建一个进程池,将连接分配给进程,一个进程可以处理多个连接的业务。引入资源池的处理方式后,会引出一个新的问题:进程如何才能高效地处理多个连接的业务?当一个连接一个进程时,进程可以采用 “read -&gt; 业务处理 -&gt; write” 的处理流程,如果当前连接没有数据可以读,则进程就阻塞在 read 操作上。这种阻塞的方式在一个连接一个进程的场景下没有问题,但如果一个进程处理多个连接,进程阻塞在某个连接的 read 操作上,此时即使其他连接有数据可读,进程也无法去处理,很显然这样是无法做到高性能的。解决这个问题的最简单的方式是将 read 操作改为非阻塞,然后进程不断地轮询多个连接。这种方式能够解决阻塞的问题,但解决的方式并不优雅。首先,轮询是要消耗 CPU 的;其次,如果一个进程处理几千上万的连接,则轮询的效率是很低的。为了能够更好地解决上述问题,很容易可以想到,只有当连接上有数据的时候进程才去处理,这就是 I/O 多路复用技术的来源。 I/O多路复用技术归纳起来有两个关键实现点： 当多条链接共用一个阻塞对象后，进程只需要在一个是阻塞对象上等待，而无序再轮询所连接，常见的实现方式有select、epoll、kqueue等。 当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。 I/O 多路复用结合线程池,完美地解决了 PPC 和 TPC 的问题,而且 “ 大神们 ” 给它取了一个很牛的名字: Reactor ,中文是 “ 反应堆 ” 。联想到 “ 核反应堆 ” ,听起来就很吓人,实际上这里的“反应”不是聚变、裂变反应的意思,而是“ 事件反应 ”的意思,可以通俗地理解为“ 来了一个事件我就有相应的反应 ”,这里的“我”就是Reactor,具体的反应就是我们写的代码, Reactor 会根据事件类型来调用相应的代码进行处理。 Reactor 模式也叫 Dispatcher 模式(在很多开源的系统里面会看到这个名称的类,其实就是实现 Reactor 模式的),更加贴近模式本身的含义,即 I/O 多路复用统一监听事件,收到事件后分配( Dispatch )给某个进程。Reactor 模式的核心组成部分包括 Reactor 和处理资源池(进程池或线程池),其中 Reactor 负责监听和分配事件,处理资源池负责处理事件。 Proactor Reactor 是非阻塞同步网络模型,因为真正的 read 和 send 操作都需要用户进程同步操作。这里的 “ 同步 ” 指用户进程在执行 read 和 send 这类 I/O 操作的时候是同步的,如果把 I/O 操作改为异步就能够进一步提升性能,这就是异步网络模型 Proactor 。Proactor 中文翻译为 “ 前摄器 ” 比较难理解,与其类似的单词是 proactive ,含义为 “ 主动的 ” ,因此我们照猫画虎翻译为 “ 主动器 ” 反而更好理解。 Reactor 可以理解为 “ 来了事件我通知你,你来处理”,而Proactor可以理解为“ 来了事件我来处理,处理完了我通知你 ”。这里的“我”就是操作系统内核,“事件”就是有新连接、有数据可读、有数据可写的这些I/O事件, “ 你 ” 就是我们的程序代码。 高性能负载均衡单服务器无论如何优化,无论采用多好的硬件,总会有一个性能天花板,当单服务器的性能无法满足业务需求时,就需要设计高性能集群来提升系统整体的处理性能。高性能集群的本质很简单,通过增加更多的服务器来提升系统整体的计算能力。由于计算本身存在一个特点:同样的输入数据和逻辑,无论在哪台服务器上执行,都应该得到相同的输出。因此高性能集群设计的复杂度主要体现在任务分配这部分,需要设计合理的任务分配策略,将计算任务分配到多台服务器上执行。高性能集群的复杂性主要体现在需要增加一个任务分配器,以及为任务选择一个合适的任务分配算法 。对于任务分配器,现在更流行的通用叫法是“负载均衡器”。但这个名称有一定的误导性,会让人潜意识里认为任务分配的目的是要保持各个计算单元的负载达到均衡状态。而实际上任务分配并不只是考虑计算单元的负载均衡,不同的任务分配算法目标是不一样的,有的基于负载考虑,有的基于性能(吞吐量、响应时间)考虑,有的基于业务考虑。考虑到 “ 负载均衡 ” 已经成为了事实上的标准术语,这里我也用 “ 负载均衡 ” 来代替 “ 任务分配 ” ,但请你时刻记住, 负载均衡不只是为了计算单元的负载达到均衡状态 。 分类及架构常见的负载均衡系统包括3种：DNS负载均衡、硬件负载均衡和软件负载均衡。 DNS负载均衡 DNS 是最简单也是最常见的负载均衡方式,一般用来实现地理级别的均衡。例如,北方的用户访问北京的机房,南方的用户访问深圳的机房。 DNS 负载均衡的本质是 DNS 解析同一个域名可以返回不同的 IP 地址。例如,同样是 www.baidu.com ,北方用户解析后获取的地址是 61.135.165.224 (这是北京机房的 IP ),南方用户解析后获取的地址是 14.215.177.38 (这是深圳机房的 IP )。 硬件负载均衡 硬件负载均衡是通过单独的硬件设备来实现负载均衡功能,这类设备和路由器、交换机类似,可以理解为一个用于负载均衡的基础网络设备。目前业界典型的硬件负载均衡设备有两款: F5 和 A10 。这类设备性能强劲、功能强大,但价格都不便宜,一般只有 “ 土豪 ” 公司才会考虑使用此类设备。普通业务量级的公司一是负担不起,二是业务量没那么大,用这些设备也是浪费。 软件负载均衡 软件负载均衡通过负载均衡软件来实现负载均衡功能,常见的有Nginx和LVS,其中Nginx是软件的7层负载均衡,LVS是Linux内核的4层负载均衡。4层和7层的区别就在于 协议 和 灵活性 ,Nginx支持HTTP、E-mail协议;而LVS是4层负载均衡,和协议无关,几乎所有应用都可以做,例如,聊天、数据库等。 算法负载均衡算法数量较多,而且可以根据一些业务特性进行定制开发,抛开细节上的差异,根据算法期望达到的目的,大体上可以分为下面几类。 任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理,这里的“平均”可以是绝对数量的平均,也可以是比例或者权重上的平均。 轮询 加权轮询 负载均衡类：负载均衡系统根据服务器的负载来进行分配,这里的负载并不一定是通常意义上我们说的“CPU负载”,而是系统当前的压力,可以用CPU负载来衡量,也可以用连接数、 I/O 使用率、网卡吞吐量等来衡量系统的压力。 负载最低优先 性能最优类：负载最低优先类算法是站在服务器的角度来进行分配的,而性能最优优先类算法则是站在客户端的角度来进行分配的,优先将任务分配给处理速度最快的服务器,通过这种方式达到最快响应客户端的目的。 Hash类：负载均衡系统根据任务中的某些关键信息进行 Hash 运算,将相同 Hash 值的请求分配到同一台服务器上,这样做的目的主要是为了满足特定的业务需求。 源地址Hash ID Hash 高可用架构模式高可用存储架构存储高可用方案的本质都是通过将数据复制到多个存储设备,通过数据冗余的方式来实现高可用,其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题。 双机架构常见的高可用存储架构有主备、主从、主主、集群、分区,每一种又可以根据业务的需求进行一些特殊的定制化功能,由此衍生出更多的变种。 主备复制 主备复制是最常见也是最简单的一种存储高可用方案,几乎所有的存储系统都提供了主备复制的功能,例如 MySQL 、Redis 、 MongoDB 等。 主从复制 主从复制和主备复制只有一字之差, “ 从 ” 意思是 “ 随从、仆从 ” , “ 备 ” 的意思是备份。我们可以理解为仆从是要帮主人干活的,这里的干活就是承担 “ 读 ” 的操作。也就是说,主机负责读写操作,从机只负责读操作,不负责写操作。 双机切换 主备复制和主从复制方案存在两个共性的问题： 主机故障后，无法进行写操作 如果主机无法恢复，需要人工指定新的主机角色 双机切换就是为了解决这两个问题而产生的,包括主备切换和主从切换两种方案。简单来说,这两个方案就是在原有方案的基础上增加 “ 切换 ” 功能,即系统自动决定主机角色,并完成角色切换。 主主复制 主主复制指的是两台机器都是主机,互相将数据复制给对方,客户端可以任意挑选其中一台机器进行读写操作, 集群和分区数据集群 主备、主从、主主架构本质上都有一个隐含的假设:主机能够存储所有数据,但主机本身的存储和处理能力肯定是有极限的。 简单来说,集群就是多台机器组合在一起形成一个统一的系统,这里的 “ 多台 ” ,数量上至少是 3 台;相比而言,主备、主从都是 2 台机器。根据集群中机器承担的不同角色来划分,集群可以分为两类:数据集中集群、数据分散集群。 数据集中集群 数据集中集群与主备、主从这类架构相似,我们也可以称数据集中集群为 1 主多备或者 1 主多从。无论是 1 主 1 从、 1 主 1 备,还是 1 主多备、 1 主多从,数据都只能往主机中写,而读操作可以参考主备、主从架构进行灵活多变。 数据分散集群 数据分散集群指多个服务器组成一个集群,每台服务器都会负责存储一部分数据;同时,为了提升硬件利用率,每台服务器又会备份一部分数据。 数据分区 前面我们讨论的存储高可用架构都是基于硬件故障的场景去考虑和设计的,主要考虑当部分硬件可能损坏的情况下系统应该如何处理,但对于一些影响非常大的灾难或者事故来说,有可能所有的硬件全部故障。例如,新奥尔良水灾、美加大停电、洛杉矶大地震等这些极端灾害或者事故,可能会导致一个城市甚至一个地区的所有基础设施瘫痪,这种情况下基于硬件故障而设计的高可用架构不再适用,我们需要基于地理级别的故障来设计高可用架构,这就是数据分区架构产生的背景。 数据分区指将数据按照一定的规则进行分区,不同分区分布在不同的地理位置上,每个分区存储一部分数据,通过这种方式来规避地理级别的故障所造成的巨大影响。采用了数据分区的架构后,即使某个地区发生严重的自然灾害或者事故,受影响的也只是一部分数据,而不是全部数据都不可用;当故障恢复后,其他地区备份的数据也可以帮助故障地区快速恢复业务。 设计一个良好的数据分区架构，需要从多个方面去考虑。 数据量 分区规则 复制规则 业务高可用的保障：异地多活架构无论是高可用计算架构,还是高可用存储架构,其本质的设计目的都是为了解决部分服务器故障的场景下,如何保证系统能够继续提供服务。但在一些极端场景下,有可能所有服务器都出现故障。例如,典型的有机房断电、机房火灾、地震、水灾 …… 这些极端情况会导致某个系统所有服务器都故障,或者业务整体瘫痪,而且即使有其他地区的备份,把备份业务系统全部恢复到能够正常提供业务,花费的时间也比较长,可能是半小时,也可能是 12 小时。因为备份系统平时不对外提供服务,可能会存在很多隐藏的问题没有发现。如果业务期望达到即使在此类灾难性故障的情况下,业务也不受影响,或者在几分钟内就能够很快恢复,那么就需要设计异地多活架构。 应用场景 顾名思义,异地多活架构的关键点就是异地、多活,其中异地就是指地理位置上不同的地方,类似于 “ 不要把鸡蛋都放在同一篮子里 ” ;多活就是指不同地理位置上的系统都能够提供业务服务,这里的 “ 活 ” 是活动、活跃的意思。判断一个系统是否符合异地多活,需要满足两个标准: 正常情况下，用户无论访问哪一个地点的业务系统，都能够得到正确的业务服务。 某个地方业务异常的时候，用户访问其他地方正常的业务系统，能够得到正确的业务服务。 架构模式 同城异区 跨城异地 跨国异地 可扩展架构模式软件系统与硬件和建筑系统最大的差异在于软件是可扩展的,一个硬件生产出来后就不会再进行改变、一个建筑完工后也不会再改变其整体结构。例如,一颗 CPU 生产出来后装到一台 PC 机上,不会再返回工厂进行加工以增加新的功能;金字塔矗立千年历经风吹雨打,但其现在的结构和当时建成完工时的结构并无两样。相比之下,软件系统就完全相反,如果一个软件系统开发出来后,再也没有任何更新和调整,反而说明了这套软件系统没有发展、没有生命力。真正有生命力的软件系统,都是在不断迭代和发展的,典型的如 Windows 操作系统,从 Windows 3.0 到 Windows 95 到 Windows XP ,直到现在的 Windows 10 ,一直在跟着技术的发展而不断地发展。 可扩展架构的基本思想和模式可扩展的基本思想 可扩展性架构的设计方法很多，但万变不离其宗，所有的可扩展性架构设计，背后的基本思想都可以总结为一个字：拆 拆，就是将原来大一统的系统拆分成多个规模小的部分，扩展时只修改其中一个部分即可，无须整个系统到处都改，通过这种方式来减少改动范围，降低改动风险。 按照不同的思路来拆分软件系统，就会得到不同的架构。常见的拆分思路有如下三种： 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分 理解这三种思路的关键就在于如何理解“流程”、“服务”、“功能”三者的联系和区别。从范围上来看，从大到小依次为：流程&gt;服务&gt;功能。 不同的拆分方式，本质上决定了系统的扩展方式。不同的拆分方式，将得到不同的系统架构，典型的可扩展系统架构有： 面向流程拆分：分层架构 面向服务拆分：SOA、微服务 面向功能拆分：微内核架构 传统的可扩展架构模式：分层架构和SOA分层架构 分层架构是很常见的架构模式，也加N层架构，通常情况下，N至少是2层。例如，C/S架构、B/S脚骨。常见的是3层架构（例如，MVC、MVP架构），4层架构，5层脚骨的比较少见，一般是比较复杂的系统才会达到或者超过5层，比如操作系统内核架构。 按照分层架构进行设计时，根据不同的划分维度和对象，可以得到多种不同的分层架构。 C/S架构、B/S架构 划分的对象是整个业务系统,划分的维度是用户交互,即将和用户交互的部分独立为一层,支撑用户交互的后台作为另外一层 MVC架构、MVP架构 划分的对象是单个业务子系统,划分的维度是职责,将不同的职责划分到独立层,但各层的依赖关系比较灵活。 逻辑分层架构 划分的对象可以是单个业务子系统,也可以是整个业务系统,划分的维度也是职责。虽然都是基于职责划分,但逻辑分层架构和 MVC 架构、 MVP 架构的不同点在于,逻辑分层架构中的层是自定向下依赖的。典型的有操作系统内核架构、TCP/IP架构。 无论采取何种分层维度，分层架构设计最核心的一点就是需要保证各层之间的差异足够清晰，边界足够明显，让人看到架构图后就能看懂整个架构，这也是分层不能太多的原因。 分层架构之所以能够较好地支撑系统扩展，本质在于隔离关注点，即每个层中的组件只会处理本层的逻辑。但是，分层时要保证层与层之间的依赖是稳定的，才能真正支撑快速扩展。 分层结构的另外一个特点就是层层传递，也就是说一旦分层确定，整个业务流程是按照层进行依次传递的，不能 在层之间进行跳跃。这种约束的好处在于强制将分层依赖限定为两两依赖，降低了整体系统复杂度，但代价就是冗余，也就是说，不管这个业务多么简单，每层都必须要参与处理。langfei 分层架构另外一个典型的缺点就是性能，因为每一次l业务请求都需要穿越所有的架构分层，有一些事情是多余的，多少都会有一些性能的浪费。 SOA SOA的全称是 Service Oriented Architecture，中文翻译为“面向服务的架构”。 SOA提出了3个关键概念 服务 所有业务功能都是一项服务，服务就意味着要对外提供开放的能力，当其他系统需要使用这项功能时，无须定制化开发。 ESB ESB的全称是 Enterprise Service Bus，中文翻译为“企业服务总线”。从名字就可以看出，ESB参考了计算机总线的概念。ESB将企业中各个不同的服务连接在一起。 松耦合 松耦合的目的是减少各个服务间的依赖和互相影响。 微服务架构微服务是一种和SOA相似但本质上不同架构理念。 对比维度 SOA 微服务 服务粒度 粗 细 服务通信 重量级，ESB 轻量级，例如，HTTP RESTful RPC 服务交付 慢 快 应用场景 企业级 互联网 Martin Fowle在他的微服务文章中，做了很好地提炼 In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. 微服务的陷阱 服务划分过膝，服务间关系复杂 服务数量太多，团队效率急剧下降 调用链太长，性能下降 调用链太长，问题定位困难 没有自动化支撑，无法快速交付 没有服务治理，微服务数量多了后台管理混乱 微内核架构微内核脚骨（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构，通常用于实现基于产品的应用。例如Eclipse这类IDE软件、UNIX这类操作系统、淘宝APP这类客户端软件。 基本架构 微内核架构包含两类组件：核心系统（core system）和插件模块（plug-in modules）。核心系统负责和具体业务功能无关的通用功能，例如模块加载、模块间通信等；插件模块负责实现具体的业务逻辑。 微内核的基本架构示意图如下：","categories":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"编程范式","slug":"编程范式","date":"2019-02-24T16:00:00.000Z","updated":"2019-07-06T09:39:05.187Z","comments":true,"path":"2019/02/25/编程范式/","link":"","permalink":"http://yoursite.com/2019/02/25/编程范式/","excerpt":"","text":"编程范式的英语是 programming paradigm，范即模范之意，范式即模式、方法，是一类典型的编程风格，是指从事软件工程的一类典型的风格。 编程语言发展到今天，出现了好多不同的代码编写方式，但不同的方式解决的都是同一个问题，那就是如何写出更为通用、更具可重用性的代码或模块。 下面给一张表格说明以下世界上四大编程范式的类别，它们的特性和主要的编程语言。 泛型编程为了讲清楚这个问题，需要从C语言开始讲起。因为C语言历史悠久，而几乎现在看到的所有编程语言都是以C语言为基础来拓展的，不管是C++、Java、C#、Go、Python、PHP、JavaScript，还会Shell。 自C语言问世40多年来，其影响了太多太多的编程语言，到现在还一直被广泛使用，不得不佩服它的生命力。但是，我们也要清楚地直到，大多数C Like编程语言其实都是在改善C语言带来的问题。 C语言特性： C语言是一个静态弱类型语言，在使用变量时需要声明变量类型，但是类型间可以有隐式转换。 不同的变量类型可以用结构体（struct）组合在一起，以此来生命新的数据类型。 C语言可以用typedef关键字来定义类型的别名，以此来达到变量类型的抽象。 C语言是一个结构化程序设计、具有变量作用域以及递归功能的过程式语言。 C语言传递参数一般是以值传递，也可以传递指针。 用过指针，C语言可以容易地对内存进行低级控制，然而这引入了非常大的贬称复杂度。 编译预处理让C语言的编译更具有弹性，比如跨平台。 C语言的这些特性，可以让程序员在微观层面写出非常惊喜和精确的编程操作,让程序员可以在底层和系统细节上非常自由、灵活和精准地控制代码。 然而，在代码组织和功能编程上，C语言的上述特性，却不那么美妙。 12345void swap(int* x, int* y)&#123; int temp = *x; *x = *y; *y = temp;&#125; 数据类型与现实世界类比（后续补充） 可以看到，无论是传统世界，还是编程世界，我们都在干一件事情——那就是通过使用一种更为通用的方式，用另外的话说就是抽象和隔离，让复杂的“世界”变得简单一些。（好好琢磨这句话) 要做到抽象，对于C语言这样的类型来说，首当其冲的就是抽象类型（这是个动词），这就是所谓的——泛型编程。 虽然对于C语言来说，类型可以转换，编译器会使用一切方式来做类型转换，这让相近的类型可以做到一点点的泛型，但这样的类型转换会出很多问题。 C语言的泛型C语言的类型泛型基本上来说就是使用void *关键字或是使用宏定义。 void *泛型版本的swap函数 1234567void swap(void* x, void* y, size_t size)&#123; char tmp[size]; memcpy(tmp, y, size); memcpy(y, x, size); memcpy(x, tmp, size);&#125; 这个实现方式有三个重点： 函数接口中增加了一个size参数。使用了void *后，类型被“抽象”掉了，编译器不能通过类型得到类型的尺寸了，所以，需要人为地加上一个类型长度的标识。 函数的实现中使用了memcpy()函数。因为类型被“抽象”掉了，所以不能用赋值表达式了，很有可能传进来的参数类型还是一个结构体。因此，为了要交换这些负责类型的值，只能使用内存复制的方法。 函数的实现中使用了一个temp[size]数组。这就是交换数据时需要用的buffer，用buffer来做临时的空间存储。 新增的size参数，使用memcpy内存拷贝以及一个buffer，这增加了编程的复杂度。这就是C语言的类型抽象所带来的复杂度的提升。 除了使用void *来做泛型，在C语言中，还可以用宏定义来做泛型。 123456#define swap(x, y, size) &#123;\\ char temp[size]; \\ memcpy(temp, &amp;y, size); \\ memcpy(&amp;y, &amp;x, size); \\ memcpy(&amp;x, temp, size); \\&#125; 使用宏带来的问题就是编译器做字符串替换，因为宏是做字符串替换的，所以会导致代码膨胀，导致编译出的执行文件比较大。 除此之外，还有一个最大的问题就是有可能会有重复执行的问题。如： 1#define min(foo(), bar()) （foo()&gt;bar() ? foo() : bar()） 本意是比较foo() 和 bar()函数的返回值，然而，经过宏替换后，foo()和bar()会被调用两次，这回带来很多问题。 另外，这种“泛型”太过宽松，完全不做类型检查， 就是在内存上对拷，直接操作内存，是比较危险的。 C语言的这种泛型，让我们根本没有办法检查传入的参数size，导致我们只能增加接口复杂度，加入一个size参数，然后把这个问题抛给调用者了。 一个更为复杂的泛型示例-Search函数写一个search函数，传入一个int数组，搜索target，搜到返回数组下标，搜不到返回-1 12345678int search(int* a, size_t size, int target) &#123; for(int i=0; i&lt;size; i++) &#123; if (a[i] == target) &#123; return i; &#125; &#125; return -1;&#125; 泛型化： 需要在函数接口上增及挨个element size，也就是数组里每个元素的size。这样遍历时，可以通过这个size正确地移动指针到下一个数组元素。 加个cmpFn。因为不同的数据类型的比较的实现不一样，所以，必须要自定义一个比较函数。 123456789101112int search(void* a, size_t size, void* target, size_t elem_size, int(*cmpFn)(void*, void*) )&#123; for(int i=0; i&lt;size; i++) &#123; // why not use memcmp() // use unsigned char * to calculate the address if ( cmpFn ((unsigned char *)a + elem_size * i, target) == 0 ) &#123; return i; &#125; &#125; return -1;&#125; 虽说看上去还行，但是，上面的这个search函数只能用于数组这样的顺序型的数据容器（数据结构）。如果这个search函数能支持一些非顺序型的数据容器，比如：堆、栈、哈希表、树、图。那么C语言来干基本上干不下去。对于像search（）这样的算法来说，数据类型的自适应问题就已经把事情搞得很复杂了。然而，数据结构的自适应就会把这个事的复杂度搞得上几个数量级。 小结 如果说，程序 = 算法 + 数据 ，那么C语言会有这么几个问题。 一个通用的算法，需要对所处理的数据的数据类型进行适配。但在适配数据类型的过程中，C语言只能使用void *或宏替换的方式，这两种方式导致了类型过于宽松，并带来很多其他问题。 适配数据类型，需要C语言在泛型中加入一个类型的size。识别不了被泛型后的数据类型，而C语言没有运行时的类型识别，所以只能将这个工作抛给调用泛型算法的程序员来做。 算法其实实在操作数据结构，而数据则是放到数据结构中的。所以，真正的泛型除了适配数据类型外，还要适配数据结构。最后这个事情导致泛型算法的复杂度急剧上升。比如容器内存的分配和释放、对象之间的复制。 总结来说，C语言设计目标是提供一种能以简易的方式编译、处理底层内存、产生少量的机器码以及不需要任何运行环境支持便能运行的编程语言。C语言也很适合搭配汇编语言来使用。 C语言把非常底层的控制权交给了程序员，它设计的理念是： 相信程序员； 不会阻止程序员做任何底层的事； 保持语言的最小和最箭的特性； 保证C语言的最快运行速度，哪怕牺牲移植性。 从某种角度上来说，C语言的伟大之处在于——使用C语言的程序员在高级语言的特性之上还能简单地做任何底层上的微观控制。这是C语言的强大和优雅之处，也有人说，C语言是高级语言中的汇编语言。 不过，这只是在针对底层指令控制和过程式的编程方式。而对于更高阶更为抽象的编程模型来说，C语言这种基于过程和底层的初衷设计方式就会称为它的短板。因为，在编程世界中，更多的编程工作是解决业务上的问题，而不是计算机的问题。所以，我们需要更为贴近业务更为抽象的语言。 编程范式其实就是程序的指导思想，它代表了这门语言的设计方向，我们并不能说哪种范式更为超前，只能说各有千秋。 比如C语言就是过程是的编程语言，像C语言这样的过程式编程语言优点是底层灵活而且高j效，特别适合开发运行较快且对系统资源利用率要求较高的程序，但在上述的问题上它在后来也没有试图去解决，因为编程范式的选择基本已经决定了它的”命运“。 C++语言作为一门高级语言，C语言绝对是编程语言历史发展中的一个重要里程碑，但随着认知的升级，面向过程的C语言已经无法满足更高层次的编程需要。于是，C++出现了。它既可以全面兼容C语言，又巧妙揉和了一些面向对象的编程理念。 从语言角度来说，实际上早期C++的许多工作是对C的强化和净化，并把完全兼容C作为强制性要求（这也是C++复杂晦涩的原因，这点java就干得比C++彻底得多）。 C++很大程度就是用来解决C语言中的各种问题和各种不方便的。比如： 用引用来解决指针的问题 用namespace来解决名字空间冲突的问题 通过try-catch来解决检查返回值编程的问题 用class来解决对象的创建、复制、销毁的问题，从而可以达到在结构体嵌套时可以深度复制的内存安全问题。 通过重载操作符来达到操作上的泛型。 通过模板template和虚函数的多态以及运行时识别来达到更高层次的泛型和多态 用RALL、智能指针的方式，解决了C语言中因为需要释放资源而出现的那些非常ugly也很容易出错的代码的问题 用STL解决了C语言中算法和数据结构中的N多种坑。 C++泛型编程C++是支持编程范式最多的一门语言。 理想情况下，算法应是和数据结构和类型无关的，各种特殊的数据类型理应做好自己分内的工作。算法只关心一个标准的实现。而对于泛型的抽象，我们需要回答的问题是，如果我们的数据类型符合通用算法，那么对数据类型的最小需求又是什么呢？ C++是如何有效解决程序泛型问题的，有三点是关键： 第一，它通过类的方式来解决 类里面会有构造函数、析构函数表示这个类的分配和释放 还有它的拷贝构造函数，表示了对内存的复制 重载操作符 这样可以让一个用户自定义的数据类型和内建的那些数据类型就很一致了。 第二，通过模板达到类型和算法的妥协 模板有点像DSL，模板的特化会根据使用者的类型在编译时期生成那个模板的代码。 模板可以通过一个虚拟类型来做类型绑定，这样不会导致类型转换的问题。 模板很好地取代了C时代宏定义带来的问题 第三，通过虚函数和运行时类型识别 虚函数带来的多态在语义上可以支持”同一类”的类型泛型 运行时类型识别技术可以做到在泛型时对具体类型的特殊处理 这样一来，就可以写出基于抽象接口的泛型。 C++泛型编程示例-Search函数就像C中的search()函数，只能适用于顺序性的数据结构，并不适用于非顺序型的数据结构。所以，如果找不到一个泛型的数据结构的操作方式（如遍历、查找、增加、删除、修改等），那么，任何的算法或是程序都不可能做到真正意义上的泛型。 除了“遍历操作之外”，还有search函数的返回值也应该做得泛型和通用一些。如果找到，返回找到的这个元素的一个指针（地址）会更靠谱一些。 所以，为了解决泛型的问题，需要动用以下几个C++的技术。 使用模板技术来抽象类型，这样可以写出类型无关的数据结构（数据容器）。 使用一个迭代器来遍历或是操作数据结构内的元素。 123456789template&lt;typename T, typename Iter&gt;Iter search(Iter pStart, Iter pEnd, T target) &#123; for(Iter p = pStart; p != pEnd; p++) &#123; if ( *p == target ) return p; &#125; return NULL;&#125; 在C++的泛型版本中，可以看到： 使用typename T抽象了数据结构中存储数据的类型 使用typename Iter，这是不同的数据结构需要自己实现的”迭代器“，这样也就抽象掉了不同类型的数据结构 然后，对数据结构的遍历使用了Iter中的++方法，这是数据容器需要重载的操作符，这样通过操作符重载也就泛型掉了遍历 在函数的入参上使用了pStart和pEnd来表示遍历的起止。 使用Iter来取得这个”指针“的内容。这也是通过重载 取值操作符来达到的泛型 所谓的Iter，在实际代码中，就是像vector::iterator或map&lt;int, string&gt;::iterator这样得到东西。这是由相应的数据容器来实现和提供的。 C++泛型编程的重要技术 - 迭代器这里，先看以下sum()函数。 12345678template&lt;typename T, typename Iter&gt;T sum(Iter pStart, Iter pEnd) &#123; T result = 0; for(Iter p=pStart; p!=pEnd; p++) &#123; result += *p; &#125; return result; &#125; 以上代 码是有问题的。代码中最大的问题就是 T result = 0;这条语句： 0假设了类型是int T 假设了Iter中出来的类型是T 我们知道Iter在实际调用者那会是一个具体的像vertor::iterator这样的东西。在这个声明中，int已经被传入Iter中。所以，定义result的T应该可以从Iter中来。这样就可以保证类型的一样的，而且不会有被转型的问题。 所以，需要实现一个”迭代器”，以下为一个“精简版”的迭代器： 123456789101112131415161718192021222324252627template &lt;class T&gt;class container &#123;public: class iterator &#123; public: typedef iterator self_type; typedef T value_type; typedef T* pointer; typedef T&amp; reference; reference operator*(); pointer operator-&gt;(); bool operator==(const self_type&amp; rhs)； bool operator!=(const self_type&amp; rhs)； self_type operator++() &#123; self_type i = *this; ptr_++; return i; &#125; self_type operator++(int junk) &#123; ptr_++; return *this; &#125; ... ... private: pointer _ptr; &#125;; iterator begin(); iterator end(); ... ...&#125;; 有了这个迭代器，还要解决 T result = 0 后面这个 0 的问题。这个算法没办法搞定，最好由用户传入。于是出现了下面最终泛型的 sum() 函数。 12345678910template &lt;class Iter&gt;typename Iter::value_typesum(Iter start, Iter end, T init) &#123; typename Iter::value_type result = init; while (start != end) &#123; result = result + *start; start++; &#125; return result;&#125; typename Iter::value_type result = init 这条语句是关键。它解决了所有的问题。 更为复杂的需求——需要更多的抽象还能不能做到更为泛型呢。我门可能还会有别的需求：求平均值average，最小值min，求中位数mean等等。然而，我们会发现，算法写出来基本上是一样，只是其中的“累加”操作变成了另外一个操作而已。那么面对这么多的需求，我们如何解决呢？ 要解决这个问题，我们需要明确：这个算法只管遍历，具体要干什么，那是业务逻辑，由外面的调用方来定义就好了，和算法无关。这样一来，代码的重用度就更高了。 因此，我们需要更高维度的抽象，这个版本不再叫sum了，这个版本应该是reduce——用于把一个数组reduce成一个值。 123456789101112131415161718template&lt;class Iter, class T, class Op&gt;T reduce (Iter start, Iter end, T init, Op op) &#123; T result = init; while ( start != end ) &#123; result = op( result, *start ); start++; &#125; return result;&#125;// 使用示例double sum_salaries = reduce( staff.begin(), staff.end(), 0.0, &#123;return s + e.salary;&#125; );double max_salary = reduce( staff.begin(), staff.end(), 0.0, &#123;return s &gt; e.salary? s: e.salary; &#125; ); 上面的代码中，需要传入一个函数。在STL中，它是个函数对象，result不像前面那样去加，而是把整个迭代器值给你一个operation，然后由它来做。可以很清楚地看到，reduce这个函数更通用了。具体要干什么样的事情？放在匿名函数里，它会定义如何做，算法本身只做一个reduce。 在C++STL中，与这个reduce函数对应的函数名叫accumulate()。 类型系统在计算机科学中，类型系统用于定义如何将编程语言中的数值和表达式归类为许多不同的类型，以及如何操作这些类型，还有这些类型如何互相作用。类型可以确认一个值或者一组具有特定的意义和目的。 一般来说，编程语言还有两种类型，一种是内建类型，如int、float和char等，一种是抽象类型，如struct、class和function等。抽象类型在程序运行中，可能不表示为值。类型系统在各种语言之间有非常大的不同也许，最主要的差异在于编译时期的语法，以及运行时期的操作实现方式。 程序语言的类型系统主要提供如下的功能： 程序语言的安全性。使用类型可以让编译器侦测一些代码的错误。强类型语言提供更多的安全性，但是并不能保证绝对的安全。 利于编译器的优化。静态类型语言的类型生命，可以让编译器明确地知道程序员的意图。因此，编译器就可以利用这一信息做很多代码优化工作。 代码的可读性。有类型的编程语言，可以让代码更易读和更易维护。代码的语义也更清楚，代码模块的接口（如函数）也更丰富和清楚。 抽象化。类型允许程序设计者对程序以较高层次的方式思考，而不是烦人的低层次实现。 但是，正如前面所讨论的，类型带来的问题就是作用于不同类型的代码，虽然长得非常相似，但是由于类型的问题需要根据不同版本写出不同的算法，如果要做到泛型，就需要涉及比较底层的玩法。 对此，这个世界出现了两类语言，一类是静态类型语言，如C、C++、Java，一类是动态类型语言，如Python、PHP、JavaScript等。 看一段动态类型语言的代码： 12x = 5x = \"hello\" 如果在静态类型的语言中写出这样的代码，那么就会在编译器出错。而在动态类型的语言中，会以类型标记维持程序所有数值的“标记”，并在运算任何数值之前检查标记。所以，一个变量的类型是由运行时的解释器来动态标记的，这样就可以动态地和底层的计算机指令或内存布局对应起来。 再看一段代码，在弱类型或是动态类型的语言中，下面得到代码的执行会有不确定的结结果。 123x = 5y = \"37\"z = x + y 在Visual Basic语言中结果是42 在JavaScript语言中结果是“537” 在Python中则会产生一个运行时错误 我们需要清楚地知道，无论那种程序语言，都避免不了一个特定的类型系统。哪怕是可随意改变变量类型的动态类型的语言，我们在读代码的过程中也需要脑补某个变量在运行时的类型。 所以，每个语言都需要一个类型检查系统。 静态类型检查是在编译器进行语义分析时进行的。如果一个语言强制实行类型规则（即通常只允许以不丢失信息为前期的自动类型转换），那么称此处理为强类型，反之称为弱类型 动态类型检查系统更多地是在运行时期做动态类型标记和相关检查。所以，动态类型的语言必然要给出一堆诸如：is_array()，is_int()，is_string()或是typeof()这样额运行时类型检查函数。 总之，“类型”有时候是一个有用的东西，有时候又是一个很讨厌的事情。因为类型会对底层内存布局的一个抽象，会让我们的代码要关注于这些非业务逻辑上的东西。而且，我们的代码需要在不同类型的数据间做处理。 我们需要清楚地明白，任何语言都有类型系统，只是动态类型语言在运行时做类型检查。动态语言的代码复杂度较低，并可以更容易地关注业务，在某些场景下是对的，但有些情况却不见得。 泛型的本质要了解泛型的本质，就需要了解类型的本质。 类型是对内存的一种抽象。不同的类型，会有不同内存布局和内存分配的策略。 不同的类型，有不同的操作。所以，对于特定的类型，也有特定的一组操作。 所以，要做到泛型，需要做下面的事情。 标准化掉类型的内存分配、释放和访问。 标准化掉类型的操作。比如：比较操作、I/O操作、复制操作… 标准化点数据容器的操作。比如：查找算法、过滤算法、聚合算法….. 标准化掉类型上特有的操作。需要有标准化的接口来回调不同类型的具体操作。 所以，C++动用了非常繁多和复杂的技术来达到泛型编程的目标。 通过类中的构造、析构、拷贝构造、重载赋值操作符，标准化（隐藏）了类型的内存分配、释放和复制的操作。 通过重载操作符，可标准化类型的比较等操作。 通过isotream，标准化类型的输入输出控制 通过模板技术（包括模板的特化），来为不同的类型生成类型专属的代码。 通过迭代器来标准化数据容器的遍历操作。 通过面向对象的接口依赖（虚函数技术），来标准化特定类型在特定算法上的操作。 通过函数式（函数对象），来标准化不同类型的特定操作。 通过学习C++，我们可以看到一个比较完整的泛型编程里所涉及的编程范式。 泛型编程于1985年在论文 Generic Programming中被这样定义： Generic programming centers around the idea of abstractingfrom concee,efficient algorithms to obtiain generic algorithms that can be combined with different data representations to produce a wide variety of useful software —Musser, David R.;Stepanov,Alexander A., Generic Programming 其本质就是——屏蔽掉数据和操作数据的细节，让算法更为通用，让编程者更多地关注算法的结构，而不是在算法中处理不同的数据类型。 小结： 我们需要明白，编程语言本质上帮助程序员屏蔽底层机器代码的实现，而让我们可以更为关注于业务逻辑代码。但是因为，编程语言作为机器代码和业务逻辑的粘合层，实在让程序员可以更多底层的灵活性，还是屏蔽底层细节，让程序员可以更多地关注于业务逻辑，这是很难两全的，是需要trade-off的事。 所以，不同的语言在设计上都会做相应的取舍。比如：C语言偏向于让程序眼可以控制更多的底层细节，而Java和Python则让程序员更多地关注业务功能的实现。而C++则是两者都想要，导致语言在设计上非常复杂。 函数式编程C++ 很大程度上解决了C语言中的各种问题和不便，尤其是通过类、模板、虚函数和运行时识别解决了C语言的泛型编程问题。然而，如何做更为抽象的泛型呢？答案就是函数式编程（Functional Programming）。 相对于计算机的历史而言，函数式编程其实是一个非常古老的概念。它是由Alonzo Church和 Stephen Cole Kleene在20世纪30年代引入的一套研究函数定义、函数应用和递归的形式系统。 如Alonzo所说，像booleans、integers或其他的数据结构都可以被函数取代掉。 它的理念来自于数学中的代数。 123f(x) = 5x^2+4x+3g(x) = 2f(x)+5 = 10x^2+8x+11h(x) = f(x) + g(x) = 15x^2+12x+14 假设f(x)是一个函数，g(x)是第二个函数，把f(x)这个函数套下来，并展开。 对于函数式编程来说，它只关心定义输入数据和输出数据相关的关心，数学表达式里面其实是在做一种映射（mapping），输入的数据和输出的数据关系是什么样的，使用函数来定义的。 函数式编程有以下特点。 特征 stateless：函数不维护任何状态。函数式编程的核心精神是stateless，简而言之就是它不能存在状态，打个比方，，你给我数据我处理完扔出来，里面的数据是不变的。 immutable：输入数据是不能动的，动了输入数据就与危险，所以要返回新的数据集。 优势 没有状态就灭有伤害 并行执行无伤害 Copy-Paste重构代码无伤害 函数的执行没有顺序上的问题 函数式编程还带来了以下一些好处。 惰性求值。这需要编译器的支持。表达式不在它被绑定到变量之后就立即求职，而是在该值被取用的时候求值 确定性。所谓确定性，就是像在数学中那样，f(x) = y 这个函数无论在什么场景下，都会得到同样的结果，而不是像程序中的很多函数那样，同一个参数，在不同的场景下会计算出不同的结果，这个我们称之为函数的确定性。 劣势 数据复制比较严重 函数式编程用到的技术 first class function（头等函数）：这个技术可以让你的函数就像变量一样来使用。也就是说，函数可以像变量一样被创建、修改，并当成变量一样传递、返回，或是在函数中嵌套函数。 tail recursion optimization（尾递归优化）：每次递归时都会重用stack，这样能够提升性能。当然，这需要语言或编译器的支持。 map &amp; reduce：函数式编程最常见的技术就是对一个集合做Map和Reduce操作。 pipeline（管道）：将函数实例成一个一个的action，然后将一组action放到一个数组或是列表中，再把数据传给这个action list，数据就像一个pipeline一样顺序地被各个函数所操作，最终得到我们想要的结果。 recursing（递归）：递归最大额好处就是简化代码。注意：递归的精髓是描述问题，而这正式函数式编程的精髓。 currying（柯里化）：将一个函数的多个参数分解成多个函数，然后将函数多层封装起来，每层函数都返回一个函数去接收下一个参数。 higer order function（高阶函数）：所谓高阶函数就是函数当参数，把传入的函数做一个封装，然后返回这个封装函数。 下面以代码做讲解： 12345// 非函数式，不是 pure funciton，有状态int cnt;void increment()&#123; cnt++;&#125; 这里有个全局变量，调这个全局函数变量++，这里面是有状态的，这个状态在外部。所以，如果是多线程的话，这里面的代码是不安全的。 写成纯函数式： 1234// 函数式，pure function， 无状态int increment(int cnt)&#123; return cnt+1;&#125; 这个代码可以随便拷，而且与线程无关，代码在并行时不用锁，因为是复制了原有的数据，并返回了新的数据。 再看另一个例子： 12345678910def inc(x): def incx(y): return x+y return incx inc2 = inc(2)inc5 = inc(5) print inc2(5) # 输出 7print inc5(5) # 输出 10 上面这段Python代码，开始有点复杂了。可以看到上面的例子中 inc() 函数返回了另一个函数 incx() ，于是可以用 inc() 函数来构造各种版本的inc() 函数。这个技术其实就是上面所说的currying技术。从这个技术山，可以体会到函数式编程的理念。 把函数当成变量来用，关注描述问题而不是怎么实现，这样可以让代码更易读 因为函数返回里面的这个函数，所以函数关注的是表达式，关注的是描述这个问题，而不是怎么实现这个事情。 函数式编程的思维方式函数式编程关注的是：describe what to do，rather than how to do it。于是，我们把以前的过程式编程范式叫作 Imperative Programming - 指令式编程，而把函数式编程范式叫作 Declarative Programming - 声明式编程。 传统方式的写法 下面我们看一下相关的示例。比如问题：有3辆车比赛，简单起见，分别给这3辆车70 %的概率让它们可以往前走一步，一共有5次机会，然后打出每一次这3辆车的前行状态。 对于 Imperative Programming来说，代码如下（Python）： 1234567891011121314151617181920212223242526from random import random def move_cars(): for i, _ in enumerate(car_positions): if random() &gt; 0.3: car_positions[i] += 1 def draw_car(car_position): print '-' * car_position def run_step_of_race(): global time time -= 1 move_cars() def draw(): print '' for car_position in car_positions: draw_car(car_position) time = 5car_positions = [1, 1, 1] while time: run_step_of_race() draw() 上面的代码，从主循环开始，我们可以很清楚地看到程序的主干，因为我们把程序的逻辑分成了几个函数。这样一来，代码逻辑就会变成几个小碎片，于是我们读代码时要考虑的上下文就少了很多，阅读代码也会更容易。 但是，我们发现，封装成函数后，这些函数都会依赖于共享的变量来同步其状态。也就是说，这些函数必须直到其他函数是怎么修改它们之间的共享变量的，所以，这些函数是有状态的。 函数式写法 我们知道，有状态并不是一件很好的事情，无论是对代码重用，还是对代码的并行来说，都是有副作用的。为了把这些状态搞掉，于是出现了函数式编程的编程范式。 123456789101112131415161718192021222324from random import random def move_cars(car_positions): return map(lambda x: x + 1 if random() &gt; 0.3 else x, car_positions) def output_car(car_position): return '-' * car_position def run_step_of_race(state): return &#123;'time': state['time'] - 1, 'car_positions': move_cars(state['car_positions'])&#125; def draw(state): print '' print '\\n'.join(map(output_car, state['car_positions'])) def race(state): draw(state) if state['time']: race(run_step_of_race(state)) race(&#123;'time': 5, 'car_positions': [1, 1, 1]&#125;) 上面的代码依然把程序的逻辑分成了函数。不过这些函数都是函数式，它们有三个特点：1）它们之间没有共享的变量；2）函数间通过参数和返回值来传递数据；3）在函数里没有临时变量。 我们还可以看到，for循环被递归取代了——递归是函数式编程中常用到的技术，正如前面所说的，递归的本质是描述问题是什么。 函数式语言的三套件函数式语言有三套件，Map、Reduce 和 Filter。 Map示例： 对于需求：把一个字符串数组中的字符串都转成小写。 用常规的面向过程的方式，代码如下： 12345# 传统的非函数式upname =['HAO', 'CHEN', 'COOLSHELL']lowname =[] for i in range(len(upname)): lowname.append( upname[i].lower() ) 写成函数式，用map() 函数： 12345678# 函数式def toUpper(item): return item.upper() upper_name = map(toUpper, [\"hao\", \"chen\", \"coolshell\"])print upper_name# 输出 ['HAO', 'CHEN', 'COOLSHELL'] 在函数式版本中，我们定义了一个函数 toUpper，这个函数没有改变传进来的值，只是把传进来的值做个简单的操作，然后返回。（？？？）然后，把它用在map函数中，就尅很清楚地描述出我们想要干什么，而不是去理解一个在循环中怎么实现的代码，最终在读了很多循环的逻辑才发现是什么意思。 Reduce 和 Filter示例 需求：计算数组平均值 非函数式： 12345678910111213# 计算数组中正数的平均值num = [2, -5, 9, 7, -2, 5, 3, 1, 0, -3, 8]positive_num_cnt = 0positive_num_sum = 0for i in range(len(num)): if num[i] &gt; 0: positive_num_cnt += 1 positive_num_sum += num[i] if positive_num_cnt &gt; 0: average = positive_num_sum / positive_num_cnt print average 函数式下使用 filter/reduce 函数的玩法： 123# 计算数组中正数的平均值positive_num = filter(lambda x: x&gt;0, num)average = reduce(lambda x,y: x+y, positive_num) / len( positive_num ) 首先，使用filter函数把整数过滤出来，保存在一个新的数组中——positive_num。然后，使用reduce函数对数组positive_num求和后，再除以其个数，就得到正数的平均值了。 可以看到， 隐藏了数组遍历并过滤数组控制流程的 filter和reduce，不仅让代码更为简洁，因为代码里只有业务逻辑了，而且让我们更容易地理解代码。。 感觉代码更亲切了，因为： 数据集、对数据的操作和返回值都放在了一起。 没有了循环体，皆可以少了些临时用来控制程序执行逻辑的变量，也少了把数据倒来倒去的控制逻辑。 代码变成了在描述你要干什么，而不是怎么干。 对于函数式编程的思路，下图是一个比较形象的例子，面包和蔬菜 map 到切碎的操作上，在把结果给 reduce 成汉堡。 在这个图中，我们可以看到 map 和 reduce 不关心源输入数据，它们只是控制，并不是业务。控制是描述怎么干，而业务是描述要干什么。 函数式的 pipeline 模式pipeline（管道）借鉴于 Unix Shell 的管道操作——把若干个命令串起来，前面的命令的输出称为后面命令的输入，如此完成一个流式计算。 接下来，用一个简单的示例来看一下如何实现 pipeline。 程序的 process() 有三个步骤： 1.找出偶数；2.乘以3; 3.转成字符串返回。 传统的非函数式的实现如下： 123456789101112131415161718192021222324def process(num): # filter out non-evens if num % 2 != 0: return num = num * 3 num = 'The Number: %s' % num return num nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] for num in nums: print process(num) # 输出：# None# The Number: 6# None# The Number: 12# None# The Number: 18# None# The Number: 24# None# The Number: 30 pipeline版本如下： 123456789101112131415161718192021def even_filter(nums): for num in nums: if num % 2 == 0: yield numdef multiply_by_three(nums): for num in nums: yield num * 3def convert_to_string(nums): for num in nums: yield 'The Number: %s' % numnums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]pipeline = convert_to_string(multiply_by_three(even_filter(nums)))for num in pipeline: print num# 输出：# The Number: 6# The Number: 12# The Number: 18# The Number: 24# The Number: 30 上面，我们动用了 Python 的关键字 yield，它是一个类似 return 的关键字，只是这个函数返回的是 Generator（生成器）。所谓生成器，指的是 yield 返回的是一个可迭代的对象，并没有真正的执行函数。也就是说，只有其返回的迭代对象被迭代时，yield函数才会真正运行。运行到 yield 语句时就会挺住，然后等下一次迭代。这就是 lazy evluation （懒惰加载）。 使用 Map &amp; Reduce 版本： 1234567891011121314151617def even_filter(nums): return filter(lambda x: x%2==0, nums) def multiply_by_three(nums): return map(lambda x: x*3, nums) def convert_to_string(nums): return map(lambda x: 'The Number: %s' % x, nums) nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]pipeline = convert_to_string( multiply_by_three( even_filter(nums) ) )for num in pipeline: print num 小结 函数式编程是个非常古老的概念，它的核心思想是键运算过程尽量写成一系列嵌套的函数调用，关注的是做什么而不是怎么做，因而被称为声明式编程。以 Stateless（无状态）和 lmmutable（不可变）为主要特点，代码简洁，抑郁理解，能便于进行并行执行，易于做代码重构，函数执行没有顺序上的问题，支持惰性求值，具有函数的确定性——无论在什么场景下都会得到同样的结果。 面向对象编程面向对象的编程有三大特性：封装、继承和多态。 面向对象编程是一种具有对象概念的程序编程发型，同时也是一种程序开发的抽象方针。它可能包含数据、属性、代码与方法。对象则指的是类的实例。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的可重用性、灵活性和可扩展性，对象里的程序可以访问及修改对象相关联的数据。在面向对象编程里，计算机程序会被设计成彼此相关的对象。 面向对象程序设计可以看作一种在程序中包含各种队里而又互相调用的对象的思想，这与传统的思想刚好相反：传统的程序设计主张将程序看作一系列函数的集合，或者是直接就是一系列对计算机下达的指令。面向对象程序设计中的每一个对象都应该能够接受数据、处理数据并将数据传达给其他对象，因此它们都可以被看作一个小型的“机器”，即对象。 鉴于对面向对象比较熟悉，这里不再详述。 小结 优点 能和真实的世界交相辉映，符合人的直觉 面向对象和数据库模型设计类型，更多地关注对象间的模型设计 强调于“名词”而不是“动词”，更多地关注对象和对象间的接口 根据业务的特征形成一个个高内聚的对象，有效地分离了抽象和具体实现，增加了可重用性和可扩展性。 拥有大量非常优秀的设计原则和设计模式 缺点 代码都需要附着在一个类上，从另一个角度来说，其鼓励了类型。 代码需要通过对象来达到抽象的效果，导致了相当厚重的“代码粘合层”。 因为太多的封装以及对状态的鼓励，导致了大量不透明并在并发下出现了很多问题。 基于原型的编程范式基于原型（prototype）的编程其实也是面向对象编程的一种方式。没有class化，直接使用对象。又叫，基于实例的编程。其主流的语言是 JavaScript。 与传统的面向对象编程的比较如下： 在基于类的编程中，对象总共有两种类型。类定义了对象基本布局和函数特性，而接口是可以使用的对象，它基于特定类的样式。在此模型中，类表现行为和结构的集合，对所有接口来说这些类的行为和结构都是相同的。 原型编程提倡程序员关注一系列对象实例的行为，而之后才关心如何将这些对象划分到最近的使用方式相似的原型对象，而不是分类。 在基于原型的系统中构造对象有两种方法，通过复制已有的对象或者通过扩展对象创建。 JavaScipt的原型概念先看一段代码： 123var foo = &#123;name: \"foo\", one: 1, two: 2&#125;;var bar = &#123;three: 3&#125;; 每个对象都有一个 _ proto 的属性，这个就是“原型”。对于上面的两个对象，如果我们把foo赋值给bar.__proto _,那就意味着，bar的原型就成了foo的。 1bar.__proto__ = foo; // foo is now the prototype of bar. 于是，我们就可以在 bar 里面访问 foo 的属性了。 1234567891011// If we try to access foo's properties from bar // from now on, we'll succeed. bar.one // Resolves to 1.// The child object's properties are also accessible.bar.three // Resolves to 3.// Own properties shadow prototype propertiesbar.name = \"bar\";foo.name; // unaffected, resolves to \"foo\"bar.name; // Resolves to \"bar\" 再来看一段代码： 1234567891011121314151617181920// 一种构造函数写法function Foo(y) &#123; this.y = y;&#125; // 修改 Foo 的 prototype，加入一个成员变量 xFoo.prototype.x = 10; // 修改 Foo 的 prototype，加入一个成员函数 calculateFoo.prototype.calculate = function (z) &#123; return this.x + this.y + z;&#125;; // 现在，我们用 Foo 这个原型来创建 b 和 cvar b = new Foo(20);var c = new Foo(30); // 调用原型中的方法，可以得到正确的值b.calculate(30); // 60c.calculate(40); // 80 那么，在内存中的布局大概是下面这个样子。 上述就是基于原型的面向对象编程的玩法了。 小结 可以看到，这种玩法就是一种委托的方式。在使用委托的基于原型的语言中，运行时语言可以“仅仅通过序列的指针找到匹配”这样的方式来定位属性或者寻找正确的数据。所有的这些创建行为共享的行为需要的是委托指针。 不像是基于类的面向对象语言中类和接口的关系，原型和它的分支之间的关系并不要求对象有相似的内存结构，因为如此，子对象可以继续修改而无需像基于类的系统那样整理结构。 这种在对象里直接修改的玩法，虽然这个特性可以带来运行时的灵活性，我们可以在运行时修改一个 prototype，给它增加甚至删除属性和方法。但是其带来了执行的不确定性，也有安全性的问题，而代码还变得不可预测，这就有点黑科技的味道了。因为这些不想静态类型系统，没有一个不可变的契约对代码的确定性有保证，所以，需要使用者来自己保证。 编程本质编程的本质两篇论文 1976年，瑞士计算机科学家，Algol W，Wodula，Oberaon和Pascal语言的设计师NiklausEmil Wirth写了一本非常经典的书《Algorithms + Data Structures = Programs》，即算法 + 数据结构 = 程序。 1979年，英国逻辑学家和计算机学家Robert Kowalski发表论文 Alogrithm = Logic + Control，并且主要开发“逻辑编程”相关的工作。 Robert Kowalski在这篇论文里提到： An algorithm can be egarded as consisting of a logic componnent . which specifies the knowledge to be used in solving problems, and a control component, which determines the problem-solving strategies by means of which that knowledge is used. The logic component determines the meaning of the algorithm whereas the control component only affects its efficiency. The efficiency of an algorithm can often be imporved by improving the control component without changing the logic of the algorithm. We argue that computer programs would be more often correct and more easily improved and modified if their logic and control aspects were identified and separated in the program text. 翻译过来的意思大概就是： 任何算法都会有两个部分，一个是Logic部分，这是用来解决实际问题的。另一个是Control部分，这是用来决定用什么策略来解决问题。Logic部分是真正意义上的解决问题的算法，而Control部分只是影响解决这个问题的效率。程序运行的效率问题和程序的逻辑其实是没有关系的。我们认为，如果将Logic和Control部分有效地分开，那么代码就会变得更容易改进和维护。 注意，最后一句话是重点——如果将Logic和Control部分有效地分开，那么代码就会变得更容易改进和维护。 编程的本质 两位老先生的两个表达式： Programs = Algorithms + Data Structures Algorithm = Logic + Control 第一个表达式倾向于数据结构和算法，它是想把这两个拆分，早起都在走这条路。它们认为，如果数据结构设计的好，算法也会变得简单，而且一个好的通用算法应该可以用在不同的数据结构上。 第二个表达式则想表达的是数据结构不复杂，复杂的是算法，也就是我们的业务逻辑是复杂的。我们的算法由两个逻辑组成，一个是真正的业务逻辑，另外一种是控制逻辑。程序中有两种代码，一种是真正的业务逻辑代码，另一种是控制我们程序的代码，叫控制代码，这根本不是业务逻辑，业务逻辑不关心这个事情。 算法的效率往往可以通过提高控制部分的效率来实现，而无需改变逻辑部分，也就无需改变算法的意义。举个阶乘的例子：X(n)! = X(n) X(n-1) X(n-2) … 2 1。逻辑部分用来定义阶乘： 1) 1是0的阶乘；2) 如果v是x的阶乘，且u=v(x+1)，那么u是x+1的阶乘。 用这个定义，既可以从上往下将x+1的阶乘缩小为先计算x的阶乘，再将结果乘以x+1（recursive，递归），也可以由下而上逐个计算一系列阶乘的结果（iteration，遍历）。 How控制部分用来描述如何使用逻辑。最粗略的看法可疑人物“控制”是解决问题额策略，而不会改变算法的意义，因为算法的意义是由逻辑决定的。对用一个逻辑，使用不同控制，所得到的算法，本质是等价的，因为它们解决同样的问题，并得到同样的结果。 因此，我们可以用过逻辑分析，来提高算法的效率，保持它的逻辑，而更好地使用这一逻辑。比如，有时用自上而下的控制代替自下而上，，能提高效率。而将自上而下的顺序执行改为并行执行，也会提高效率。 总之，通过这两个表达式，我们可以得出： Program = Logic + Control + Data Structure 前面讲了这么多的编程范式，其实，都是在围绕着这三件事来做。比如： 就像函数编程中的Map/Reduce/Filter，它们都是一种控制。而传给这些控制模块的那个Lambda表达式才是我们要解决问题的逻辑，它们共同组成了一个算法、最后，再把数据放在数据结构了进行处理，最终就成为了我们的程序。 就像面向对象中依赖于接口而不是实现一样，接口是对逻辑的抽象，真正的逻辑放在不同的具体类中，通过多态或是依赖注入这样的控制来完成对数据在不同情况下的不同处理。 仔细地结合之前的各式各样的编程范式来思考上述这些概念，我们会发现，所有的语言或编程范式都在解决上面的这些问题。也就下面的这几个事。 Control是可以标准化的。比如：遍历数据、查找数据、多线程、并发、异步等，都是可以标准化的。 因为Control需要处理数据，所以标准化Control，需要标准化Data Structure，我们可以通过泛型编程来解决这个事 而Control还要处理用户的业务逻辑，即Logic。所以，我们可以通过标准化接口/协议来实现，我们的Control模式可以适配与任何的Logic。 上述三点，就是编程范式的本质。 有效地分离 Logic、Control 和 Data 是写出好程序的关键所在！ 有效地分离 Logic、Control 和 Data 是写出好程序的关键所在！ 有效地分离 Logic、Control 和 Data 是写出好程序的关键所在！ 控制一个程序流转的方式，即程序执行的方式，并行还是串行，同步还是异步，以及调度不同执行路径或模块，数据之间的存储关系，这些和业务逻辑没有关系。 那些混乱不堪的代码，你会发现其中最大的问题是我们把Logic和Control纠缠在一起了，所以导致代码很混乱，难以维护，Bug很多。绝大多数程序复杂的原因就是这个问题。 小结： 代码复杂度的原因： 业务逻辑的复杂度据定了代码的复杂度； 控制逻辑的复杂度 + 业务逻辑的复杂度 ==&gt; 程序代码的混乱不堪； 绝大多数程序复杂混乱的根本原因：业务逻辑与控制逻辑的耦合。 如何分离 control 和 logic呢》使用下面的这些技术来解耦： State Machine 状态定义 状态变迁条件 状态的action DSL - Domain Specific Language HTML，SQL，Unix shell Script，AWK，正则表达式 编程范式 面向对象：委托、策略、桥接、修饰、Ioc/DIP、MVC 函数式编程：修饰、管道、拼接 逻辑推导式编程：Prolog 这就是编程的本质： Logic 部分才是真正有意义的（What） Control 部分只是影响Logic部分的效率（How）","categories":[{"name":"编程","slug":"编程","permalink":"http://yoursite.com/categories/编程/"}],"tags":[{"name":"编程","slug":"编程","permalink":"http://yoursite.com/tags/编程/"}]}]}